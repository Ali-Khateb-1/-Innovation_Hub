{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31e08156",
   "metadata": {},
   "source": [
    " # ğŸ“Œ Dev Structure Manager - Ø¥Ø¯Ø§Ø±Ø© Ù‡ÙŠÙƒÙ„ÙŠØ© Ø§Ù„ØªØ·ÙˆÙŠØ±\n",
    "\n",
    "## ğŸŒ Ù†Ø¸Ø±Ø© Ø¹Ø§Ù…Ø©\n",
    "ÙŠÙ‡Ø¯Ù Ù‡Ø°Ø§ Ø§Ù„Ø¯ÙØªØ± Ø¥Ù„Ù‰ Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ù‡ÙŠÙƒÙ„ÙŠØ© Ø§Ù„Ø¨Ø±Ù…Ø¬ÙŠØ© Ù„Ù„Ù…Ø´Ø±ÙˆØ¹ Ø¯Ø§Ø®Ù„ `Full_Stack_Framework`.  \n",
    "ÙŠØªØ¶Ù…Ù† Ø£Ø¯ÙˆØ§Øª Ù„ØªÙ†Ø¸ÙŠÙ… ÙˆØ­Ø¯Ø§Øª Ø§Ù„ÙƒÙˆØ¯ØŒ ØªØ­Ø³ÙŠÙ† Ø¨Ù†Ø§Ø¡ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ØŒ ÙˆØ¶Ø¨Ø· Ø¨ÙŠØ¦Ø© Ø§Ù„ØªØ·ÙˆÙŠØ± ÙˆÙÙ‚Ù‹Ø§ Ù„Ù…Ø±Ø§Ø­Ù„ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹.\n",
    "\n",
    "## ğŸ—ï¸ Ø§Ù„Ù…Ù‡Ø§Ù… Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©:\n",
    "- **ØªÙ†Ø¸ÙŠÙ… Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª ÙˆØ§Ù„Ù…Ø³Ø§Ø±Ø§Øª Ø§Ù„Ø¨Ø±Ù…Ø¬ÙŠØ© Ø¯Ø§Ø®Ù„ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹.**\n",
    "- **Ø¥Ø¯Ø§Ø±Ø© Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ§Øª Ø§Ù„ØªØ­Ø³ÙŠÙ† ÙˆØ§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙƒÙØ§Ø¡Ø© Ø§Ù„Ù†Ù…Ø§Ø°Ø¬.**\n",
    "- **ØªÙˆØ¬ÙŠÙ‡ Ù…Ø±Ø§Ø­Ù„ Ø§Ù„ØªØ·ÙˆÙŠØ± ÙˆÙÙ‚Ù‹Ø§ Ù„Ù„Ø¨Ù†ÙŠØ© Ø§Ù„Ø´Ø§Ù…Ù„Ø© Ù„Ù€ `Innovation_Hub_New`.**\n",
    "\n",
    "ğŸ“Œ **Ù‡Ø°Ø§ Ø§Ù„Ø¯ÙØªØ± Ù‡Ùˆ Ù†Ù‚Ø·Ø© Ø§Ù„ØªØ­ÙƒÙ… Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© ÙÙŠ Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ù‡ÙŠÙƒÙ„ÙŠØ© Ø§Ù„Ø¨Ø±Ù…Ø¬ÙŠØ© Ù„Ù„Ù…Ø´Ø±ÙˆØ¹.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a664684c",
   "metadata": {},
   "source": [
    " 1ï¸âƒ£ Dev Structure Manager.ipynb â€“ Ø¥Ø¯Ø§Ø±Ø© Ù‡ÙŠÙƒÙ„ÙŠØ© Ø§Ù„ØªØ·ÙˆÙŠØ±\n",
    "ğŸŒ Ù†Ø¸Ø±Ø© Ø¹Ø§Ù…Ø©:\n",
    "ÙŠØ¹Ø¯ Dev_Structure_Manager.ipynb Ù†Ù‚Ø·Ø© Ø§Ù„ØªØ­ÙƒÙ… Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© Ø¯Ø§Ø®Ù„ Full_Stack_Framework.\n",
    "ÙŠÙ‡Ø¯Ù Ø¥Ù„Ù‰ Ø¥Ø¯Ø§Ø±Ø© Ø¨Ù†ÙŠØ© Ø§Ù„Ù…Ø´Ø±ÙˆØ¹ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø¨Ø±Ù…Ø¬ÙŠØŒ ØªÙ†Ø¸ÙŠÙ… ÙˆØ­Ø¯Ø§Øª Ø§Ù„ÙƒÙˆØ¯ØŒ ÙˆØ¶Ø¨Ø· Ø¨ÙŠØ¦Ø© Ø§Ù„ØªØ·ÙˆÙŠØ±.\n",
    "ÙŠØ¹ØªØ¨Ø± Ù‡Ø°Ø§ Ø§Ù„Ø¯ÙØªØ± Ø§Ù„Ø£Ø³Ø§Ø³ Ø§Ù„Ø°ÙŠ ÙŠØªÙ… Ù…Ù† Ø®Ù„Ø§Ù„Ù‡ Ø¶Ø¨Ø· Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª Ø§Ù„Ø¨Ø±Ù…Ø¬ÙŠØ©ØŒ Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† ÙƒÙØ§Ø¡Ø© Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ØŒ ÙˆØ¥Ø¯Ø§Ø±Ø© Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ§Øª ØªØ­Ø³ÙŠÙ† Ø§Ù„ÙƒÙˆØ¯.\n",
    "ğŸ—ï¸ Ø§Ù„Ù…Ù‡Ø§Ù… Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©:\n",
    "- Ø¥Ø¯Ø§Ø±Ø© Ø¨Ù†ÙŠØ© Ø§Ù„Ù…Ù„ÙØ§Øª ÙˆØ§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª Ø¯Ø§Ø®Ù„ Ø§Ù„Ù…Ø³ØªÙˆØ¯Ø¹.\n",
    "- ØªØ­Ø³ÙŠÙ† ØªÙ†Ø¸ÙŠÙ… Ø§Ù„Ø£ÙƒÙˆØ§Ø¯ Ø¨Ù…Ø§ ÙŠØ¶Ù…Ù† Ø³Ù‡ÙˆÙ„Ø© ØµÙŠØ§Ù†ØªÙ‡Ø§ ÙˆØªÙˆØ³ÙŠØ¹Ù‡Ø§.\n",
    "- ØªÙ†ÙÙŠØ° Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ§Øª ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø£Ø¯Ø§Ø¡ Ù„ØªØ³Ø±ÙŠØ¹ ØªÙ†ÙÙŠØ° Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª.\n",
    "- ØªØ­Ø¯ÙŠØ¯ Ù…Ø¹Ø§ÙŠÙŠØ± Ø¶Ø¨Ø· Ø§Ù„Ø¨ÙŠØ¦Ø© Ø§Ù„ØªØ·ÙˆÙŠØ±ÙŠØ© Ù…Ø«Ù„ Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¹Ø§Ù„Ù…ÙŠØ©ØŒ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠØŒ ÙˆÙ…Ø³Ø§Ø±Ø§Øª Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª.\n",
    "ğŸ“Œ Ù‡Ø°Ø§ Ø§Ù„Ø¯ÙØªØ± Ø¶Ø±ÙˆØ±ÙŠ Ù„Ø¶Ù…Ø§Ù† Ø£Ù† Ø¨ÙŠØ¦Ø© Ø§Ù„ØªØ·ÙˆÙŠØ± ØªØ¹Ù…Ù„ Ø¨Ø³Ù„Ø§Ø³Ø© ÙˆØªØ®Ø¯Ù… Ø§Ù„Ø£Ù‡Ø¯Ø§Ù Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© Ù„Ù„Ù…Ø´Ø±ÙˆØ¹.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc5ae31",
   "metadata": {},
   "source": [
    " \n",
    " \n",
    "\n",
    "### ğŸ“œ **`Dev_Structure_Manager.ipynb` - Ø¥Ø¯Ø§Ø±Ø© Ù‡ÙŠÙƒÙ„ÙŠØ© Ø§Ù„ØªØ·ÙˆÙŠØ±**\n",
    "\n",
    "# ğŸš€ **Dev Structure Manager - Ø¥Ø¯Ø§Ø±Ø© Ù‡ÙŠÙƒÙ„ÙŠØ© Ø§Ù„ØªØ·ÙˆÙŠØ±**\n",
    "ğŸ”¹ **Ø¥Ø·Ø§Ø± Ø§Ù„Ø¹Ù…Ù„ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ Ù„ØªÙ†Ø¸ÙŠÙ… Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª Ø§Ù„Ø¨Ø±Ù…Ø¬ÙŠØ© Ø¯Ø§Ø®Ù„** `Full_Stack_Framework`\n",
    " \n",
    "\n",
    "## ğŸŒ **Ù†Ø¸Ø±Ø© Ø¹Ø§Ù…Ø©**\n",
    "ÙŠØ¹Ø¯ `Dev_Structure_Manager.ipynb` Ø§Ù„Ù†Ù‚Ø·Ø© Ø§Ù„Ù…Ø±ÙƒØ²ÙŠØ© Ù„Ø¶Ø¨Ø· Ø¨ÙŠØ¦Ø© Ø§Ù„ØªØ·ÙˆÙŠØ± Ø¯Ø§Ø®Ù„ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹ØŒ Ø­ÙŠØ« ÙŠØªÙ… ØªÙ†Ø¸ÙŠÙ… Ø§Ù„ÙƒÙˆØ¯ØŒ Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ù…Ø³Ø§Ø±Ø§ØªØŒ ÙˆØªØ­Ø³ÙŠÙ† Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬.  \n",
    "âš™ï¸ **Ù‡Ø°Ø§ Ø§Ù„Ø¯ÙØªØ± Ø¶Ø±ÙˆØ±ÙŠ Ù„Ø¶Ù…Ø§Ù† Ø£Ù† Ø¨Ù†ÙŠØ© Ø§Ù„Ù…Ø´Ø±ÙˆØ¹ ØªØ¸Ù„ Ù‚Ø§Ø¨Ù„Ø© Ù„Ù„ØªÙˆØ³Ø¹Ø© ÙˆØ§Ù„ØªØ·ÙˆÙŠØ± Ø§Ù„Ù…Ø³ØªÙ…Ø±.**\n",
    "\n",
    "### ğŸ”‘ **Ø§Ù„Ù…ÙƒÙˆÙ†Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©**\n",
    "| ğŸ—ï¸ Ø§Ù„Ù‚Ø³Ù… | ğŸ” Ø§Ù„ÙˆØµÙ |\n",
    "|----------|---------|\n",
    "| **ğŸ“‚ ØªÙ†Ø¸ÙŠÙ… Ø§Ù„Ù…Ù„ÙØ§Øª** | Ø¶Ø¨Ø· Ø¨Ù†ÙŠØ© Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª Ø¯Ø§Ø®Ù„ `Full_Stack_Framework` Ù„Ø¶Ù…Ø§Ù† Ø³Ù‡ÙˆÙ„Ø© Ø§Ù„ÙˆØµÙˆÙ„ Ø¥Ù„Ù‰ Ø§Ù„Ø£ÙƒÙˆØ§Ø¯ ÙˆØ§Ù„Ù…Ø´Ø§Ø±ÙŠØ¹ Ø§Ù„ÙØ±Ø¹ÙŠØ©. |\n",
    "| **âš™ï¸ ØªØ­Ø³ÙŠÙ† Ø§Ù„ÙƒÙˆØ¯** | ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø¯Ø§Ø¡ ÙˆØ§Ù‚ØªØ±Ø§Ø­ ØªØ¹Ø¯ÙŠÙ„Ø§Øª Ù„ØªØ­Ø³ÙŠÙ† Ø³Ø±Ø¹Ø© ÙˆÙƒÙØ§Ø¡Ø© Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ø¨Ø±Ù…Ø¬ÙŠØ©. |\n",
    "| **ğŸ› ï¸ Ø¥Ø¯Ø§Ø±Ø© Ø¨ÙŠØ¦Ø© Ø§Ù„ØªØ·ÙˆÙŠØ±** | ØªØ¹Ø±ÙŠÙ Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¹Ø§Ù„Ù…ÙŠØ©ØŒ Ø¶Ø¨Ø· `Conda environments`ØŒ ÙˆØ¶Ù…Ø§Ù† Ø§Ù„ØªÙƒØ§Ù…Ù„ Ù…Ø¹ `WSL2`. |\n",
    "| **ğŸ”„ Ø¶Ø¨Ø· Ù…Ø³Ø§Ø±Ø§Øª Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª** | Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØªØ¯ÙÙ‚Ø§Øª Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨ÙŠÙ† ÙˆØ­Ø¯Ø§Øª Ø§Ù„Ù…Ø´Ø±ÙˆØ¹ ÙˆØªØ­Ø¯ÙŠØ« Ù…Ø³Ø§Ø±Ø§Øª Ø§Ù„Ù…Ù„ÙØ§Øª ØªÙ„Ù‚Ø§Ø¦ÙŠÙ‹Ø§. |\n",
    " \n",
    "\n",
    "## ğŸ—ï¸ **Ù…Ù‡Ø§Ù… Ø±Ø¦ÙŠØ³ÙŠØ© Ø¯Ø§Ø®Ù„ Ù‡Ø°Ø§ Ø§Ù„Ø¯ÙØªØ±**\n",
    "âœ… **ØªÙ†Ø¸ÙŠÙ… Ù‡ÙŠÙƒÙ„ÙŠØ© `Full_Stack_Framework`** Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ§Øª Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª.  \n",
    "âœ… **ØªØ­Ù„ÙŠÙ„ Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø£ÙƒÙˆØ§Ø¯ ÙˆØ§Ù„Ù†Ù…Ø§Ø°Ø¬** ÙˆØªÙ‚Ø¯ÙŠÙ… ØªÙˆØµÙŠØ§Øª Ù„ØªØ­Ø³ÙŠÙ† Ø§Ù„ØªÙ†ÙÙŠØ°.  \n",
    "âœ… **Ø¯Ù…Ø¬ Ø£Ø¯ÙˆØ§Øª Ø§Ù„ØªØ·ÙˆÙŠØ± Ù…Ø¹ Ø¨ÙŠØ¦Ø§Øª Ù…Ø®ØªÙ„ÙØ©** Ù…Ø«Ù„ `WSL2` Ùˆ `GitHub`.  \n",
    "âœ… **Ø¶Ø¨Ø· Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ø¯Ø§Ø®Ù„ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹** Ù„Ø¶Ù…Ø§Ù† Ø§Ù„ØªÙˆØ§ÙÙ‚ ÙˆØ§Ù„Ù…Ø±ÙˆÙ†Ø© ÙÙŠ Ø¨ÙŠØ¦Ø© Ø§Ù„Ø¹Ù…Ù„.  \n",
    " \n",
    "\n",
    "## ğŸ”§ **ØªØ´ØºÙŠÙ„ Ø§Ù„ØªØ¹Ù„ÙŠÙ…Ø§Øª Ø§Ù„Ø¨Ø±Ù…Ø¬ÙŠØ© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©**\n",
    "```python\n",
    "import os\n",
    "\n",
    "# ØªØ¹Ø±ÙŠÙ Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª Ø§Ù„Ø¨Ø±Ù…Ø¬ÙŠØ©\n",
    "base_path = \"/mnt/c/Users/ali/Desktop/Innovation_Hub_New/Full_Stack_Framework\"\n",
    "\n",
    "# Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© Ø¯Ø§Ø®Ù„ Ø§Ù„Ù‡ÙŠÙƒÙ„ÙŠØ©\n",
    "folders = [\n",
    "    \"Core_System_Framework\",\n",
    "    \"User_Interaction_Flow\",\n",
    "    \"Data_Processing_Engine\",\n",
    "    \"Deployment_Strategies\",\n",
    "    \"Project_Growth_Framework\"\n",
    "]\n",
    "\n",
    "for folder in folders:\n",
    "    os.makedirs(os.path.join(base_path, folder), exist_ok=True)\n",
    "\n",
    "print(\"âœ… ØªÙ… ØªÙ†Ø¸ÙŠÙ… Ù‡ÙŠÙƒÙ„ÙŠØ© Full_Stack_Framework Ø¨Ù†Ø¬Ø§Ø­!\")\n",
    "```\n",
    " \n",
    "\n",
    "## ğŸ¯ **Ø£Ù‡Ù…ÙŠØ© `Dev_Structure_Manager.ipynb` ÙÙŠ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹**\n",
    "ğŸ”¹ **ÙŠÙØ³ØªØ®Ø¯Ù… Ù„Ø¶Ø¨Ø· Ø¨ÙŠØ¦Ø© Ø§Ù„ØªØ·ÙˆÙŠØ± ÙˆØªØ­Ø³ÙŠÙ† Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø£ÙƒÙˆØ§Ø¯ ÙˆØ§Ù„Ù…Ø´Ø§Ø±ÙŠØ¹ Ø¯Ø§Ø®Ù„ `Full_Stack_Framework`**.  \n",
    "ğŸ”¹ **ÙŠØ³Ø§Ø¹Ø¯ Ø¹Ù„Ù‰ Ø¶Ù…Ø§Ù† Ø³Ù‡ÙˆÙ„Ø© Ø§Ù„ØªÙ†Ù‚Ù„ Ø¨ÙŠÙ† Ø§Ù„Ù…Ù„ÙØ§ØªØŒ Ø³Ø±Ø¹Ø© ØªÙ†ÙÙŠØ° Ø§Ù„Ø¹Ù…Ù„ÙŠØ§ØªØŒ ÙˆØªØ­Ø³ÙŠÙ† ØªÙƒØ§Ù…Ù„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª**.  \n",
    "ğŸ”¹ **ÙŠØ³Ø§Ù‡Ù… ÙÙŠ ØªØ¨Ø³ÙŠØ· ØµÙŠØ§Ù†Ø© Ø§Ù„Ù…Ø´Ø±ÙˆØ¹ Ø¹Ø¨Ø± ØªÙ‚Ø³ÙŠÙ…Ù‡ Ø¥Ù„Ù‰ ÙˆØ­Ø¯Ø§Øª Ù…Ø³ØªÙ‚Ù„Ø© Ù„ÙƒÙ†Ù‡Ø§ Ù…ØªÙƒØ§Ù…Ù„Ø©**.  \n",
    "\n",
    "ğŸ”¥ **Ø¨Ø¹Ø¯ ØªÙ†ÙÙŠØ° Ù…Ø­ØªÙˆÙ‰ Ù‡Ø°Ø§ Ø§Ù„Ø¯ÙØªØ±ØŒ Ø³ÙŠÙƒÙˆÙ† Ù„Ø¯ÙŠÙƒ Ø¨ÙŠØ¦Ø© ØªØ·ÙˆÙŠØ± Ù…Ù†Ø¸Ù…Ø© ÙˆÙ…Ù‡ÙŠÙƒÙ„Ø© Ø¨Ø´ÙƒÙ„ Ø§Ø­ØªØ±Ø§ÙÙŠ!** ğŸš€  \n",
    "\n",
    " \n",
    "\n",
    "ğŸ¯  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52e635db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ØªÙ… ØªÙ†Ø¸ÙŠÙ… Ù‡ÙŠÙƒÙ„ÙŠØ© Full_Stack_Framework Ø¨Ù†Ø¬Ø§Ø­!\n"
     ]
    }
   ],
   "source": [
    " import os\n",
    "\n",
    "# ØªØ¹Ø±ÙŠÙ Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª Ø§Ù„Ø¨Ø±Ù…Ø¬ÙŠØ©\n",
    "base_path = \"/mnt/c/Users/ali/Desktop/Innovation_Hub_New/Full_Stack_Framework\"\n",
    "\n",
    "# Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© Ø¯Ø§Ø®Ù„ Ø§Ù„Ù‡ÙŠÙƒÙ„ÙŠØ©\n",
    "folders = [\n",
    "    \"Core_System_Framework\",\n",
    "    \"User_Interaction_Flow\",\n",
    "    \"Data_Processing_Engine\",\n",
    "    \"Deployment_Strategies\",\n",
    "    \"Project_Growth_Framework\"\n",
    "]\n",
    "\n",
    "for folder in folders:\n",
    "    os.makedirs(os.path.join(base_path, folder), exist_ok=True)\n",
    "\n",
    "print(\"âœ… ØªÙ… ØªÙ†Ø¸ÙŠÙ… Ù‡ÙŠÙƒÙ„ÙŠØ© Full_Stack_Framework Ø¨Ù†Ø¬Ø§Ø­!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20e2039a",
   "metadata": {},
   "outputs": [],
   "source": [
    "open(\"/mnt/c/Users/ali/Desktop/Innovation_Hub_New/Full_Stack_Framework/Flower_Classification_Foundation_V1/README.md\", \"w\").close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e5bebc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/mnt/c/Users/ali/Desktop/Innovation_Hub_New/Full_Stack_Framework/Flower_Classification_Foundation_V1/README.md\", \"w\") as f:\n",
    "    f.write(\"# Flower Classification Foundation - Version 1\\n\\n\")\n",
    "    f.write(\"Ù‡Ø°Ø§ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹ ÙŠØ¹ØªÙ…Ø¯ Ø¹Ù„Ù‰ Ù†Ù…ÙˆØ°Ø¬ Ø°ÙƒØ§Ø¡ Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ù„ØªØµÙ†ÙŠÙ ØµÙˆØ± Ø§Ù„Ø²Ù‡ÙˆØ± Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… TensorFlow.\\n\")\n",
    "    f.write(\"ÙŠØªÙ… ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Oxford Flowers 102 Dataset Ù„ØªØ­Ù„ÙŠÙ„ ÙˆØªØµÙ†ÙŠÙ Ø§Ù„ØµÙˆØ± Ø¨Ø´ÙƒÙ„ Ø¯Ù‚ÙŠÙ‚.\\n\")\n",
    "    f.write(\"\\n## ÙƒÙŠÙÙŠØ© ØªØ´ØºÙŠÙ„ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹:\\n\")\n",
    "    f.write(\"1. Ù‚Ù… Ø¨ØªØ«Ø¨ÙŠØª Ø§Ù„Ù…ØªØ·Ù„Ø¨Ø§Øª Ø¹Ø¨Ø± `pip install -r requirements.txt`\\n\")\n",
    "    f.write(\"2. Ù†ÙÙ‘Ø° `run_model.sh` Ù„ØªØ´ØºÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙˆØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "27a17b8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ `environment.yaml` Ø¨Ù†Ø¬Ø§Ø­!\n"
     ]
    }
   ],
   "source": [
    "env_file = \"/mnt/c/Users/ali/Desktop/Innovation_Hub_New/Full_Stack_Framework/Flower_Classification_Foundation_V1/environment.yaml\"\n",
    "\n",
    "# Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ù„Ù ÙØ§Ø±ØºÙ‹Ø§\n",
    "open(env_file, \"w\").close()\n",
    "\n",
    "print(\"âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ `environment.yaml` Ø¨Ù†Ø¬Ø§Ø­!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "63d25123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized empty Git repository in /mnt/c/Users/ali/Desktop/Innovation_Hub_New/Full_Stack_Framework/.git/\n",
      "\n",
      "âœ… ØªÙ… ØªÙ‡ÙŠØ¦Ø© Ù…Ø³ØªÙˆØ¯Ø¹ Git Ø¨Ù†Ø¬Ø§Ø­ Ø¯Ø§Ø®Ù„ `Full_Stack_Framework`!\n"
     ]
    }
   ],
   "source": [
    " import subprocess\n",
    "\n",
    "repo_path = \"/mnt/c/Users/ali/Desktop/Innovation_Hub_New/Full_Stack_Framework\"\n",
    "\n",
    "try:\n",
    "    result = subprocess.run([\"git\", \"init\"], cwd=repo_path, capture_output=True, text=True)\n",
    "    print(result.stdout)\n",
    "    print(\"âœ… ØªÙ… ØªÙ‡ÙŠØ¦Ø© Ù…Ø³ØªÙˆØ¯Ø¹ Git Ø¨Ù†Ø¬Ø§Ø­ Ø¯Ø§Ø®Ù„ `Full_Stack_Framework`!\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ ØªÙ†ÙÙŠØ° `git init`: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cd5accd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ØªÙ… Ø¥Ø¹Ø¯Ø§Ø¯ `pre-commit hook` Ø¨Ù†Ø¬Ø§Ø­!\n"
     ]
    }
   ],
   "source": [
    "git_hook_path = \"/mnt/c/Users/ali/Desktop/Innovation_Hub_New/Full_Stack_Framework/.git/hooks/pre-commit\"\n",
    "\n",
    "hook_script = \"\"\"#!/bin/bash\n",
    "if git diff --cached --name-only | grep -q 'requirements.txt'; then\n",
    "    echo \"ğŸ”„ ØªØ­Ø¯ÙŠØ« environment.yaml Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ ØªØºÙŠÙŠØ±Ø§Øª requirements.txt...\"\n",
    "    python /mnt/c/Users/ali/Desktop/Innovation_Hub_New/Full_Stack_Framework/Flower_Classification_Foundation_V1/update_yaml.py\n",
    "    git add /mnt/c/Users/ali/Desktop/Innovation_Hub_New/Full_Stack_Framework/Flower_Classification_Foundation_V1/environment.yaml\n",
    "fi\n",
    "\"\"\"\n",
    "\n",
    "# Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ù hook ÙˆØ¥Ø¶Ø§ÙØ© Ø§Ù„ÙƒÙˆØ¯\n",
    "with open(git_hook_path, \"w\") as f:\n",
    "    f.write(hook_script)\n",
    "\n",
    "# Ø¬Ø¹Ù„ Ø§Ù„Ù…Ù„Ù Ù‚Ø§Ø¨Ù„Ø§Ù‹ Ù„Ù„ØªÙ†ÙÙŠØ°\n",
    "import os\n",
    "os.chmod(git_hook_path, 0o755)\n",
    "\n",
    "print(\"âœ… ØªÙ… Ø¥Ø¹Ø¯Ø§Ø¯ `pre-commit hook` Ø¨Ù†Ø¬Ø§Ø­!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9266ded6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âŒ Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…ØµØ¯Ø± `requirements.txt` ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ØŒ ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù…Ø³Ø§Ø±.\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "# Ù…Ø³Ø§Ø± Ø§Ù„Ù…Ù„Ù Ø¯Ø§Ø®Ù„ Windows\n",
    "src = \"C:/Users/ali/Desktop/intro-to-ml-tensorflow/requirements.txt\"\n",
    "\n",
    "# Ø§Ù„Ù…Ø³Ø§Ø± Ø§Ù„Ù‡Ø¯Ù Ø¯Ø§Ø®Ù„ WSL2\n",
    "dst = \"/mnt/c/Users/ali/Desktop/Innovation_Hub_New/Full_Stack_Framework/Flower_Classification_Foundation_V1/requirements.txt\"\n",
    "\n",
    "try:\n",
    "    shutil.copy(src, dst)\n",
    "    print(\"âœ… ØªÙ… Ù†Ø³Ø® `requirements.txt` Ø¨Ù†Ø¬Ø§Ø­ Ø¥Ù„Ù‰ `Flower_Classification_Foundation_V1`!\")\n",
    "except FileNotFoundError:\n",
    "    print(\"âŒ Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…ØµØ¯Ø± `requirements.txt` ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ØŒ ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù…Ø³Ø§Ø±.\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ù†Ø³Ø®: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6c3a012f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ØªÙ… Ù†Ø³Ø® `requirements.txt` Ø¨Ù†Ø¬Ø§Ø­ Ø¥Ù„Ù‰ `Flower_Classification_Foundation_V1`!\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "# Ø§Ù„Ù…Ø³Ø§Ø± Ø§Ù„ØµØ­ÙŠØ­ Ø¯Ø§Ø®Ù„ WSL2\n",
    "src = \"/mnt/c/Users/ali/Desktop/intro-to-ml-tensorflow/requirements.txt\"\n",
    "dst = \"/mnt/c/Users/ali/Desktop/Innovation_Hub_New/Full_Stack_Framework/Flower_Classification_Foundation_V1/requirements.txt\"\n",
    "\n",
    "try:\n",
    "    shutil.copy(src, dst)\n",
    "    print(\"âœ… ØªÙ… Ù†Ø³Ø® `requirements.txt` Ø¨Ù†Ø¬Ø§Ø­ Ø¥Ù„Ù‰ `Flower_Classification_Foundation_V1`!\")\n",
    "except FileNotFoundError:\n",
    "    print(\"âŒ Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…ØµØ¯Ø± `requirements.txt` ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ØŒ ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù…Ø³Ø§Ø±.\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ù†Ø³Ø®: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "88cff62a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow-datasets==4.9.4\n",
      "tensorflow-hub==0.16.1\n",
      "scipy==1.12.0\n",
      "tf-keras==2.16.0  # https://github.com/tensorflow/tensorflow/issues/63849#issuecomment-2002501172 \n",
      "\n",
      "âœ… ØªÙ… Ø¹Ø±Ø¶ Ù…Ø­ØªÙˆÙ‰ `requirements.txt` Ø¨Ù†Ø¬Ø§Ø­!\n"
     ]
    }
   ],
   "source": [
    "req_file = \"/mnt/c/Users/ali/Desktop/Innovation_Hub_New/Full_Stack_Framework/Flower_Classification_Foundation_V1/requirements.txt\"\n",
    "\n",
    "try:\n",
    "    with open(req_file, \"r\") as f:\n",
    "        print(f.read())\n",
    "    print(\"âœ… ØªÙ… Ø¹Ø±Ø¶ Ù…Ø­ØªÙˆÙ‰ `requirements.txt` Ø¨Ù†Ø¬Ø§Ø­!\")\n",
    "except FileNotFoundError:\n",
    "    print(\"âŒ Ø§Ù„Ù…Ù„Ù `requirements.txt` ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ØŒ ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† Ø§Ù„Ù…Ø³Ø§Ø± ØµØ­ÙŠØ­.\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ù‚Ø±Ø§Ø¡Ø© `requirements.txt`: {e}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a9dc5a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ `environment.yaml` Ø¨Ù†Ø¬Ø§Ø­ ÙˆÙÙ‚Ù‹Ø§ Ù„Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„ØªØ«Ø¨ÙŠØª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©!\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "import subprocess\n",
    "\n",
    "# ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª Ø¯Ø§Ø®Ù„ WSL2\n",
    "req_file = \"/mnt/c/Users/ali/Desktop/Innovation_Hub_New/Full_Stack_Framework/Flower_Classification_Foundation_V1/requirements.txt\"\n",
    "env_file = \"/mnt/c/Users/ali/Desktop/Innovation_Hub_New/Full_Stack_Framework/Flower_Classification_Foundation_V1/environment.yaml\"\n",
    "log_file = \"/mnt/c/Users/ali/Desktop/Innovation_Hub_New/Full_Stack_Framework/Flower_Classification_Foundation_V1/dependency_log.txt\"\n",
    "\n",
    "# ÙˆØ¸ÙŠÙØ© Ù„Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØªÙˆÙØ± Ø§Ù„Ù…ÙƒØªØ¨Ø© Ø¯Ø§Ø®Ù„ Conda Forge\n",
    "def is_available_in_conda(package_name):\n",
    "    try:\n",
    "        result = subprocess.run([\"conda\", \"search\", package_name, \"-c\", \"conda-forge\"], capture_output=True, text=True)\n",
    "        return package_name in result.stdout\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† {package_name} ÙÙŠ `conda-forge`: {e}\")\n",
    "        return False  # Ø¥Ø°Ø§ Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ø¨Ø­Ø«ØŒ Ù†ÙØªØ±Ø¶ Ø£Ù† Ø§Ù„Ù…ÙƒØªØ¨Ø© ØºÙŠØ± Ù…ØªØ§Ø­Ø©\n",
    "\n",
    "# Ù‚Ø±Ø§Ø¡Ø© Ù…Ù„Ù Ø§Ù„Ù…ØªØ·Ù„Ø¨Ø§Øª ÙˆÙ…Ø¹Ø§Ù„Ø¬ØªÙ‡\n",
    "try:\n",
    "    with open(req_file, \"r\") as f:\n",
    "        requirements = [line.strip().split(\"==\")[0] for line in f.readlines() if line.strip()]\n",
    "\n",
    "    conda_dependencies = []\n",
    "    pip_dependencies = []\n",
    "\n",
    "    # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØªÙˆÙØ± Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª Ø¯Ø§Ø®Ù„ `conda-forge`\n",
    "    log_messages = []\n",
    "    for pkg in requirements:\n",
    "        if is_available_in_conda(pkg):\n",
    "            conda_dependencies.append(pkg)\n",
    "        else:\n",
    "            pip_dependencies.append(pkg)\n",
    "            log_messages.append(f\"âš ï¸ Ø§Ù„Ù…ÙƒØªØ¨Ø© `{pkg}` ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø© ÙÙŠ `conda-forge`, Ø³ÙŠØªÙ… ØªØ«Ø¨ÙŠØªÙ‡Ø§ Ø¹Ø¨Ø± `pip`.\")\n",
    "\n",
    "    # Ø¥Ù†Ø´Ø§Ø¡ `environment.yaml`\n",
    "    yaml_data = {\n",
    "        \"name\": \"flower_classification_env\",\n",
    "        \"channels\": [\"conda-forge\"],\n",
    "        \"dependencies\": [\"python=3.8\"] + conda_dependencies + [\"pip\", {\"pip\": pip_dependencies}]\n",
    "    }\n",
    "\n",
    "    with open(env_file, \"w\") as f:\n",
    "        yaml.dump(yaml_data, f, default_flow_style=False)\n",
    "\n",
    "    print(\"âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ `environment.yaml` Ø¨Ù†Ø¬Ø§Ø­ ÙˆÙÙ‚Ù‹Ø§ Ù„Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„ØªØ«Ø¨ÙŠØª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©!\")\n",
    "\n",
    "    # Ø­ÙØ¸ Ø³Ø¬Ù„ Ø§Ù„ØªØ¹Ø¯ÙŠÙ„Ø§Øª Ø¯Ø§Ø®Ù„ `dependency_log.txt`\n",
    "    if log_messages:\n",
    "        with open(log_file, \"w\") as log_f:\n",
    "            log_f.write(\"\\n\".join(log_messages))\n",
    "        print(f\"ğŸ“œ ØªÙ… Ø­ÙØ¸ Ø³Ø¬Ù„ Ø§Ù„ØªØ­Ø°ÙŠØ±Ø§Øª Ø¯Ø§Ø®Ù„ `{log_file}`!\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"âŒ `requirements.txt` ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ØŒ ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù…Ø³Ø§Ø±.\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø¥Ù†Ø´Ø§Ø¡ `environment.yaml`: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "96450b20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ØªÙ… Ø­ÙØ¸ Ø§Ù„Ø³ÙƒØ±Ø¨Øª Ø¯Ø§Ø®Ù„ `/mnt/c/Users/ali/Desktop/Innovation_Hub_New/Full_Stack_Framework/Flower_Classification_Foundation_V1/update_yaml.py`!\n"
     ]
    }
   ],
   "source": [
    "script_path = \"/mnt/c/Users/ali/Desktop/Innovation_Hub_New/Full_Stack_Framework/Flower_Classification_Foundation_V1/update_yaml.py\"\n",
    "\n",
    "script_content = \"\"\"<Ø¶Ø¹ Ù‡Ù†Ø§ ÙƒÙˆØ¯ Ø§Ù„Ø³ÙƒØ±Ø¨Øª ÙƒØ§Ù…Ù„Ø§Ù‹>\"\"\"\n",
    "\n",
    "with open(script_path, \"w\") as f:\n",
    "    f.write(script_content)\n",
    "\n",
    "print(f\"âœ… ØªÙ… Ø­ÙØ¸ Ø§Ù„Ø³ÙƒØ±Ø¨Øª Ø¯Ø§Ø®Ù„ `{script_path}`!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9ce9a254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ØªÙ… Ø­ÙØ¸ Ø§Ù„Ø³ÙƒØ±Ø¨Øª Ø¯Ø§Ø®Ù„ `/mnt/c/Users/ali/Desktop/Innovation_Hub_New/Full_Stack_Framework/Flower_Classification_Foundation_V1/update_yaml.py`!\n"
     ]
    }
   ],
   "source": [
    "script_path = \"/mnt/c/Users/ali/Desktop/Innovation_Hub_New/Full_Stack_Framework/Flower_Classification_Foundation_V1/update_yaml.py\"\n",
    "\n",
    "script_content = \"\"\"import yaml\n",
    "import subprocess\n",
    "\n",
    "# ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª Ø¯Ø§Ø®Ù„ WSL2\n",
    "req_file = \"/mnt/c/Users/ali/Desktop/Innovation_Hub_New/Full_Stack_Framework/Flower_Classification_Foundation_V1/requirements.txt\"\n",
    "env_file = \"/mnt/c/Users/ali/Desktop/Innovation_Hub_New/Full_Stack_Framework/Flower_Classification_Foundation_V1/environment.yaml\"\n",
    "log_file = \"/mnt/c/Users/ali/Desktop/Innovation_Hub_New/Full_Stack_Framework/Flower_Classification_Foundation_V1/dependency_log.txt\"\n",
    "\n",
    "# ÙˆØ¸ÙŠÙØ© Ù„Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØªÙˆÙØ± Ø§Ù„Ù…ÙƒØªØ¨Ø© Ø¯Ø§Ø®Ù„ Conda Forge\n",
    "def is_available_in_conda(package_name):\n",
    "    try:\n",
    "        result = subprocess.run([\"conda\", \"search\", package_name, \"-c\", \"conda-forge\"], capture_output=True, text=True)\n",
    "        return package_name in result.stdout\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† {package_name} ÙÙŠ `conda-forge`: {e}\")\n",
    "        return False\n",
    "\n",
    "# Ù‚Ø±Ø§Ø¡Ø© Ù…Ù„Ù Ø§Ù„Ù…ØªØ·Ù„Ø¨Ø§Øª ÙˆÙ…Ø¹Ø§Ù„Ø¬ØªÙ‡\n",
    "try:\n",
    "    with open(req_file, \"r\") as f:\n",
    "        requirements = [line.strip().split(\"==\")[0] for line in f.readlines() if line.strip()]\n",
    "\n",
    "    conda_dependencies = []\n",
    "    pip_dependencies = []\n",
    "\n",
    "    log_messages = []\n",
    "    for pkg in requirements:\n",
    "        if pkg.startswith(\"python\"):\n",
    "            continue  # ØªØ¬Ø§Ù‡Ù„ Ø¥ØµØ¯Ø§Ø± Ø¨Ø§ÙŠØ«ÙˆÙ† Ù„Ø£Ù†Ù‡ Ø³ÙŠØªÙ… Ø§Ù„ØªØ­ÙƒÙ… ÙÙŠÙ‡ Ù…Ù† `requirements.txt`\n",
    "        if is_available_in_conda(pkg):\n",
    "            conda_dependencies.append(pkg)\n",
    "        else:\n",
    "            pip_dependencies.append(pkg)\n",
    "            log_messages.append(f\"âš ï¸ Ø§Ù„Ù…ÙƒØªØ¨Ø© `{pkg}` ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø© ÙÙŠ `conda-forge`, Ø³ÙŠØªÙ… ØªØ«Ø¨ÙŠØªÙ‡Ø§ Ø¹Ø¨Ø± `pip`.\")\n",
    "\n",
    "    # Ø¥Ù†Ø´Ø§Ø¡ `environment.yaml` Ø¨Ø¯ÙˆÙ† ØªØ­Ø¯ÙŠØ¯ Ø¥ØµØ¯Ø§Ø± Ø¨Ø§ÙŠØ«ÙˆÙ†\n",
    "    yaml_data = {\n",
    "        \"name\": \"flower_classification_env\",\n",
    "        \"channels\": [\"conda-forge\"],\n",
    "        \"dependencies\": conda_dependencies + [\"pip\", {\"pip\": pip_dependencies}]\n",
    "    }\n",
    "\n",
    "    with open(env_file, \"w\") as f:\n",
    "        yaml.dump(yaml_data, f, default_flow_style=False)\n",
    "\n",
    "    print(\"âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ `environment.yaml` Ø¨Ø¯ÙˆÙ† Ø¥ØµØ¯Ø§Ø± Ø¨Ø§ÙŠØ«ÙˆÙ†ØŒ Ø¨Ø­ÙŠØ« ÙŠØªÙ… ØªØ­Ø¯ÙŠØ¯Ù‡ Ø¹Ø¨Ø± `requirements.txt`!\")\n",
    "\n",
    "    # Ø­ÙØ¸ Ø³Ø¬Ù„ Ø§Ù„ØªØ­Ø°ÙŠØ±Ø§Øª\n",
    "    if log_messages:\n",
    "        with open(log_file, \"w\") as log_f:\n",
    "            log_f.write(\"\\n\".join(log_messages))\n",
    "        print(f\"ğŸ“œ ØªÙ… Ø­ÙØ¸ Ø³Ø¬Ù„ Ø§Ù„ØªØ­Ø°ÙŠØ±Ø§Øª Ø¯Ø§Ø®Ù„ `{log_file}`!\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"âŒ `requirements.txt` ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ØŒ ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù…Ø³Ø§Ø±.\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø¥Ù†Ø´Ø§Ø¡ `environment.yaml`: {e}\")\n",
    "\"\"\"\n",
    "\n",
    "# Ø­ÙØ¸ Ø§Ù„Ø³ÙƒØ±Ø¨Øª Ø¯Ø§Ø®Ù„ Ù…Ø¬Ù„Ø¯ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹\n",
    "with open(script_path, \"w\") as f:\n",
    "    f.write(script_content)\n",
    "\n",
    "print(f\"âœ… ØªÙ… Ø­ÙØ¸ Ø§Ù„Ø³ÙƒØ±Ø¨Øª Ø¯Ø§Ø®Ù„ `{script_path}`!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cc9cd971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“œ Ù…Ø­ØªÙˆÙ‰ `requirements.txt`:\n",
      "tensorflow-datasets==4.9.4\n",
      "tensorflow-hub==0.16.1\n",
      "scipy==1.12.0\n",
      "tf-keras==2.16.0  # https://github.com/tensorflow/tensorflow/issues/63849#issuecomment-2002501172 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "req_file = \"/mnt/c/Users/ali/Desktop/Innovation_Hub_New/Full_Stack_Framework/Flower_Classification_Foundation_V1/requirements.txt\"\n",
    "\n",
    "try:\n",
    "    with open(req_file, \"r\") as f:\n",
    "        print(\"ğŸ“œ Ù…Ø­ØªÙˆÙ‰ `requirements.txt`:\")\n",
    "        print(f.read())\n",
    "except FileNotFoundError:\n",
    "    print(\"âŒ Ø§Ù„Ù…Ù„Ù ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ØŒ ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù…Ø³Ø§Ø±.\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ù‚Ø±Ø§Ø¡Ø© `requirements.txt`: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "348d69f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ØªÙ… Ø­ÙØ¸ Ø§Ù„Ø³ÙƒØ±Ø¨Øª Ø¯Ø§Ø®Ù„ `/mnt/c/Users/ali/Desktop/Innovation_Hub_New/Full_Stack_Framework/Flower_Classification_Foundation_V1/watch_requirements.py`!\n"
     ]
    }
   ],
   "source": [
    "script_path = \"/mnt/c/Users/ali/Desktop/Innovation_Hub_New/Full_Stack_Framework/Flower_Classification_Foundation_V1/watch_requirements.py\"\n",
    "\n",
    "script_content = \"\"\"from watchdog.observers import Observer\n",
    "from watchdog.events import FileSystemEventHandler\n",
    "import time\n",
    "\n",
    "# ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù…Ø³Ø§Ø± Ø¥Ù„Ù‰ Ù…Ù„Ù `requirements.txt`\n",
    "req_file = \"/mnt/c/Users/ali/Desktop/Innovation_Hub_New/Full_Stack_Framework/Flower_Classification_Foundation_V1/requirements.txt\"\n",
    "\n",
    "# ÙˆØ¸ÙŠÙØ© Ø¹Ø±Ø¶ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø¹Ù†Ø¯ Ø£ÙŠ ØªØ¹Ø¯ÙŠÙ„\n",
    "def show_requirements():\n",
    "    try:\n",
    "        with open(req_file, \"r\") as f:\n",
    "            print(\"\\\\nğŸ“œ Ù…Ø­ØªÙˆÙ‰ `requirements.txt` ØªÙ… ØªØ­Ø¯ÙŠØ«Ù‡:\")\n",
    "            print(f.read())\n",
    "    except FileNotFoundError:\n",
    "        print(\"âŒ Ø§Ù„Ù…Ù„Ù ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ØŒ ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù…Ø³Ø§Ø±.\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ù‚Ø±Ø§Ø¡Ø© `requirements.txt`: {e}\")\n",
    "\n",
    "# Ø¥Ù†Ø´Ø§Ø¡ Ø­Ø¯Ø« Ù„Ù…Ø±Ø§Ù‚Ø¨Ø© Ø§Ù„ØªØ¹Ø¯ÙŠÙ„Ø§Øª\n",
    "class RequirementsHandler(FileSystemEventHandler):\n",
    "    def on_modified(self, event):\n",
    "        if event.src_path == req_file:\n",
    "            show_requirements()\n",
    "\n",
    "# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨\n",
    "observer = Observer()\n",
    "event_handler = RequirementsHandler()\n",
    "observer.schedule(event_handler, path=req_file, recursive=False)\n",
    "\n",
    "# ØªØ´ØºÙŠÙ„ Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨Ø©\n",
    "observer.start()\n",
    "print(\"ğŸ” ÙŠØªÙ… Ø§Ù„Ø¢Ù† Ù…Ø±Ø§Ù‚Ø¨Ø© `requirements.txt`...\")\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        time.sleep(1)\n",
    "except KeyboardInterrupt:\n",
    "    observer.stop()\n",
    "    print(\"ğŸ›‘ ØªÙ… Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨Ø©.\")\n",
    "\n",
    "observer.join()\n",
    "\"\"\"\n",
    "\n",
    "# Ø­ÙØ¸ Ø§Ù„Ø³ÙƒØ±Ø¨Øª Ø¯Ø§Ø®Ù„ Ù…Ø¬Ù„Ø¯ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹\n",
    "with open(script_path, \"w\") as f:\n",
    "    f.write(script_content)\n",
    "\n",
    "print(f\"âœ… ØªÙ… Ø­ÙØ¸ Ø§Ù„Ø³ÙƒØ±Ø¨Øª Ø¯Ø§Ø®Ù„ `{script_path}`!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aeaeeba3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'python' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpython\u001b[49m \u001b[38;5;241m/\u001b[39mmnt\u001b[38;5;241m/\u001b[39mc\u001b[38;5;241m/\u001b[39mUsers\u001b[38;5;241m/\u001b[39mali\u001b[38;5;241m/\u001b[39mDesktop\u001b[38;5;241m/\u001b[39mInnovation_Hub_New\u001b[38;5;241m/\u001b[39mFull_Stack_Framework\u001b[38;5;241m/\u001b[39mFlower_Classification_Foundation_V1\u001b[38;5;241m/\u001b[39mwatch_requirements\u001b[38;5;241m.\u001b[39mpy\n",
      "\u001b[0;31mNameError\u001b[0m: name 'python' is not defined"
     ]
    }
   ],
   "source": [
    "python /mnt/c/Users/ali/Desktop/Innovation_Hub_New/Full_Stack_Framework/Flower_Classification_Foundation_V1/watch_requirements.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "06201fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” ÙŠØªÙ… Ø§Ù„Ø¢Ù† Ù…Ø±Ø§Ù‚Ø¨Ø© `requirements.txt`...\n",
      "^C\n",
      "ğŸ›‘ ØªÙ… Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨Ø©.\n"
     ]
    }
   ],
   "source": [
    "!python /mnt/c/Users/ali/Desktop/Innovation_Hub_New/Full_Stack_Framework/Flower_Classification_Foundation_V1/watch_requirements.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "42ab7c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ØªÙ… ØªØ­Ø¯ÙŠØ« `requirements.txt` Ø¨Ø¥Ø¶Ø§ÙØ© Python 3.10!\n"
     ]
    }
   ],
   "source": [
    "req_file = \"/mnt/c/Users/ali/Desktop/Innovation_Hub_New/Full_Stack_Framework/Flower_Classification_Foundation_V1/requirements.txt\"\n",
    "\n",
    "# Ø¥Ø¶Ø§ÙØ© Ø¥ØµØ¯Ø§Ø± Ø¨Ø§ÙŠØ«ÙˆÙ† Ø¥Ù„Ù‰ Ø§Ù„Ù…Ù„Ù\n",
    "python_version = \"python==3.10\\n\"\n",
    "\n",
    "try:\n",
    "    with open(req_file, \"r+\") as f:\n",
    "        content = f.read()\n",
    "        if \"python==\" not in content:\n",
    "            f.seek(0, 0)\n",
    "            f.write(python_version + content)\n",
    "            print(\"âœ… ØªÙ… ØªØ­Ø¯ÙŠØ« `requirements.txt` Ø¨Ø¥Ø¶Ø§ÙØ© Python 3.10!\")\n",
    "        else:\n",
    "            print(\"âš ï¸ Ø¥ØµØ¯Ø§Ø± Python Ù…ÙˆØ¬ÙˆØ¯ Ø¨Ø§Ù„ÙØ¹Ù„ ÙÙŠ Ø§Ù„Ù…Ù„Ù.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"âŒ Ø§Ù„Ù…Ù„Ù ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ØŒ ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù…Ø³Ø§Ø±.\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ ØªØ­Ø¯ÙŠØ« `requirements.txt`: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "52573f9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python==3.10\r\n",
      "tensorflow-datasets==4.9.4\r\n",
      "tensorflow-hub==0.16.1\r\n",
      "scipy==1.12.0\r\n",
      "tf-keras==2.16.0  # https://github.com/tensorflow/tensorflow/issues/63849#issuecomment-2002501172 \r\n"
     ]
    }
   ],
   "source": [
    "cat /mnt/c/Users/ali/Desktop/Innovation_Hub_New/Full_Stack_Framework/Flower_Classification_Foundation_V1/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1c115f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;32mREADME.md\u001b[0m*         \u001b[01;32mrequirements.txt\u001b[0m*  \u001b[01;32mwatch_requirements.py\u001b[0m*\r\n",
      "\u001b[01;32menvironment.yaml\u001b[0m*  \u001b[01;32mupdate_yaml.py\u001b[0m*\r\n"
     ]
    }
   ],
   "source": [
    "ls /mnt/c/Users/ali/Desktop/Innovation_Hub_New/Full_Stack_Framework/Flower_Classification_Foundation_V1/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b9deca32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ØªÙ… Ø¥Ø²Ø§Ù„Ø© Ø¥ØµØ¯Ø§Ø± Ø¨Ø§ÙŠØ«ÙˆÙ† Ù…Ù† `requirements.txt`!\n"
     ]
    }
   ],
   "source": [
    "req_file = \"/mnt/c/Users/ali/Desktop/Innovation_Hub_New/Full_Stack_Framework/Flower_Classification_Foundation_V1/requirements.txt\"\n",
    "\n",
    "try:\n",
    "    with open(req_file, \"r\") as f:\n",
    "        lines = [line for line in f.readlines() if not line.startswith(\"python==\")]\n",
    "\n",
    "    with open(req_file, \"w\") as f:\n",
    "        f.writelines(lines)\n",
    "\n",
    "    print(\"âœ… ØªÙ… Ø¥Ø²Ø§Ù„Ø© Ø¥ØµØ¯Ø§Ø± Ø¨Ø§ÙŠØ«ÙˆÙ† Ù…Ù† `requirements.txt`!\")\n",
    "except FileNotFoundError:\n",
    "    print(\"âŒ Ø§Ù„Ù…Ù„Ù ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ØŒ ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù…Ø³Ø§Ø±.\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ ØªØ¹Ø¯ÙŠÙ„ `requirements.txt`: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ba78da9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” ÙŠØªÙ… Ø§Ù„Ø¢Ù† Ù…Ø±Ø§Ù‚Ø¨Ø© `requirements.txt`...\n",
      "ğŸ›‘ ØªÙ… Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨Ø©.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "cannot join thread before it is started",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 47\u001b[0m\n\u001b[1;32m     44\u001b[0m     observer\u001b[38;5;241m.\u001b[39mstop()\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mğŸ›‘ ØªÙ… Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨Ø©.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 47\u001b[0m \u001b[43mobserver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.12/threading.py:1142\u001b[0m, in \u001b[0;36mThread.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1140\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThread.__init__() not called\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_started\u001b[38;5;241m.\u001b[39mis_set():\n\u001b[0;32m-> 1142\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot join thread before it is started\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m current_thread():\n\u001b[1;32m   1144\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot join current thread\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cannot join thread before it is started"
     ]
    }
   ],
   "source": [
    "from watchdog.observers import Observer\n",
    "from watchdog.events import FileSystemEventHandler\n",
    "import time\n",
    "\n",
    "# ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù…Ø³Ø§Ø± Ø¥Ù„Ù‰ `requirements.txt` Ùˆ `log.txt`\n",
    "req_file = \"/mnt/c/Users/ali/Desktop/Innovation_Hub_New/Full_Stack_Framework/Flower_Classification_Foundation_V1/requirements.txt\"\n",
    "log_file = \"/mnt/c/Users/ali/Desktop/Innovation_Hub_New/Full_Stack_Framework/Flower_Classification_Foundation_V1/log.txt\"\n",
    "\n",
    "# ÙˆØ¸ÙŠÙØ© Ø¹Ø±Ø¶ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ ÙˆØªØ³Ø¬ÙŠÙ„ Ø§Ù„ØªØ¹Ø¯ÙŠÙ„Ø§Øª\n",
    "def show_requirements():\n",
    "    try:\n",
    "        with open(req_file, \"r\") as f:\n",
    "            content = f.read()\n",
    "            print(\"\\nğŸ“œ Ù…Ø­ØªÙˆÙ‰ `requirements.txt` ØªÙ… ØªØ­Ø¯ÙŠØ«Ù‡:\")\n",
    "            print(content)\n",
    "\n",
    "        # ØªØ³Ø¬ÙŠÙ„ Ø§Ù„ØªØºÙŠÙŠØ± ÙÙŠ `log.txt`\n",
    "        with open(log_file, \"a\") as log:\n",
    "            log.write(f\"\\nğŸ•’ ØªØ­Ø¯ÙŠØ« ÙÙŠ {time.strftime('%Y-%m-%d %H:%M:%S')}:\\n\")\n",
    "            log.write(content)\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(\"âŒ Ø§Ù„Ù…Ù„Ù ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ØŒ ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù…Ø³Ø§Ø±.\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ù‚Ø±Ø§Ø¡Ø© `requirements.txt`: {e}\")\n",
    "\n",
    "# Ø¥Ù†Ø´Ø§Ø¡ Ø­Ø¯Ø« Ù„Ù…Ø±Ø§Ù‚Ø¨Ø© Ø§Ù„ØªØ¹Ø¯ÙŠÙ„Ø§Øª\n",
    "class RequirementsHandler(FileSystemEventHandler):\n",
    "    def on_modified(self, event):\n",
    "        if event.src_path == req_file:\n",
    "            show_requirements()\n",
    "\n",
    "# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨\n",
    "observer = Observer()\n",
    "event_handler = RequirementsHandler()\n",
    "observer.schedule(event_handler, path=req_file, recursive=False)\n",
    "\n",
    "# ØªØ´ØºÙŠÙ„ Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨Ø© Ø¯Ø§Ø®Ù„ Jupyter\n",
    "print(\"ğŸ” ÙŠØªÙ… Ø§Ù„Ø¢Ù† Ù…Ø±Ø§Ù‚Ø¨Ø© `requirements.txt`...\")\n",
    "try:\n",
    "    while True:\n",
    "        time.sleep(1)\n",
    "except KeyboardInterrupt:\n",
    "    observer.stop()\n",
    "    print(\"ğŸ›‘ ØªÙ… Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨Ø©.\")\n",
    "\n",
    "observer.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ef27f380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” ÙŠØªÙ… Ø§Ù„Ø¢Ù† Ù…Ø±Ø§Ù‚Ø¨Ø© `requirements.txt`...\n",
      "ğŸ›‘ ØªÙ… Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨Ø©.\n"
     ]
    }
   ],
   "source": [
    "observer.start()\n",
    "print(\"ğŸ” ÙŠØªÙ… Ø§Ù„Ø¢Ù† Ù…Ø±Ø§Ù‚Ø¨Ø© `requirements.txt`...\")\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        time.sleep(1)\n",
    "except KeyboardInterrupt:\n",
    "    print(\"ğŸ›‘ ØªÙ… Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨Ø©.\")\n",
    "    observer.stop()\n",
    "    observer.join()  # ÙŠØªÙ… ØªÙ†ÙÙŠØ° `join()` ÙÙ‚Ø· Ø¨Ø¹Ø¯ Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨Ø©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "77b215fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” ÙŠØªÙ… Ø§Ù„Ø¢Ù† Ù…Ø±Ø§Ù‚Ø¨Ø© `requirements.txt`...\n",
      "ğŸ›‘ ØªÙ… Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨Ø©.\n"
     ]
    }
   ],
   "source": [
    "from watchdog.observers import Observer\n",
    "from watchdog.events import FileSystemEventHandler\n",
    "import time\n",
    "import sys\n",
    "\n",
    "# ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù…Ø³Ø§Ø± Ø¥Ù„Ù‰ `requirements.txt`\n",
    "req_file = \"/mnt/c/Users/ali/Desktop/Innovation_Hub_New/Full_Stack_Framework/Flower_Classification_Foundation_V1/requirements.txt\"\n",
    "\n",
    "# Ø¹Ø±Ø¶ Ø±Ø³Ø§Ù„Ø© Ø¨Ø¯Ø¡ Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨Ø© ÙÙˆØ±Ù‹Ø§\n",
    "print(\"ğŸ” ÙŠØªÙ… Ø§Ù„Ø¢Ù† Ù…Ø±Ø§Ù‚Ø¨Ø© `requirements.txt`...\", flush=True)\n",
    "sys.stdout.flush()  # ÙŠØ¶Ù…Ù† Ø¸Ù‡ÙˆØ± Ø§Ù„Ø±Ø³Ø§Ù„Ø© Ù…Ø¨Ø§Ø´Ø±Ø© Ø¯Ø§Ø®Ù„ Jupyter\n",
    "\n",
    "# ÙˆØ¸ÙŠÙØ© Ø¹Ø±Ø¶ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø¹Ù†Ø¯ Ø£ÙŠ ØªØ¹Ø¯ÙŠÙ„\n",
    "def show_requirements():\n",
    "    try:\n",
    "        with open(req_file, \"r\") as f:\n",
    "            content = f.read()\n",
    "            print(\"\\nğŸ“œ Ù…Ø­ØªÙˆÙ‰ `requirements.txt` ØªÙ… ØªØ­Ø¯ÙŠØ«Ù‡!\")\n",
    "            print(content, flush=True)  # Ø¹Ø±Ø¶ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ù…Ø¨Ø§Ø´Ø±Ø© Ø¨Ø¹Ø¯ Ø£ÙŠ ØªØ¹Ø¯ÙŠÙ„\n",
    "            sys.stdout.flush()\n",
    "    except FileNotFoundError:\n",
    "        print(\"âŒ Ø§Ù„Ù…Ù„Ù ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ØŒ ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù…Ø³Ø§Ø±.\", flush=True)\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ù‚Ø±Ø§Ø¡Ø© `requirements.txt`: {e}\", flush=True)\n",
    "\n",
    "# Ø¥Ù†Ø´Ø§Ø¡ Ø­Ø¯Ø« Ù„Ù…Ø±Ø§Ù‚Ø¨Ø© Ø§Ù„ØªØ¹Ø¯ÙŠÙ„Ø§Øª\n",
    "class RequirementsHandler(FileSystemEventHandler):\n",
    "    def on_modified(self, event):\n",
    "        if event.src_path == req_file:\n",
    "            print(f\"\\nâš¡ï¸ ØªØºÙŠÙŠØ± ØªÙ… Ø§ÙƒØªØ´Ø§ÙÙ‡ ÙÙŠ `{req_file}`! ğŸš€\", flush=True)\n",
    "            sys.stdout.flush()\n",
    "            show_requirements()\n",
    "\n",
    "# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨\n",
    "observer = Observer()\n",
    "event_handler = RequirementsHandler()\n",
    "observer.schedule(event_handler, path=req_file, recursive=False)\n",
    "\n",
    "observer.start()\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        time.sleep(1)\n",
    "except KeyboardInterrupt:\n",
    "    print(\"ğŸ›‘ ØªÙ… Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨Ø©.\", flush=True)\n",
    "    observer.stop()\n",
    "    observer.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f5e1cfe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ØªÙ… Ø¥Ø¹Ø§Ø¯Ø© Ø¥ØµØ¯Ø§Ø± Ø¨Ø§ÙŠØ«ÙˆÙ† Ø¯Ø§Ø®Ù„ `requirements.txt`!\n"
     ]
    }
   ],
   "source": [
    "req_file = \"/mnt/c/Users/ali/Desktop/Innovation_Hub_New/Full_Stack_Framework/Flower_Classification_Foundation_V1/requirements.txt\"\n",
    "\n",
    "python_version = \"python==3.10\\n\"\n",
    "\n",
    "try:\n",
    "    with open(req_file, \"r+\") as f:\n",
    "        content = f.read()\n",
    "        if \"python==\" not in content:\n",
    "            f.seek(0, 0)\n",
    "            f.write(python_version + content)\n",
    "            print(\"âœ… ØªÙ… Ø¥Ø¹Ø§Ø¯Ø© Ø¥ØµØ¯Ø§Ø± Ø¨Ø§ÙŠØ«ÙˆÙ† Ø¯Ø§Ø®Ù„ `requirements.txt`!\")\n",
    "        else:\n",
    "            print(\"âš ï¸ Ø¥ØµØ¯Ø§Ø± Python Ù…ÙˆØ¬ÙˆØ¯ Ø¨Ø§Ù„ÙØ¹Ù„ ÙÙŠ Ø§Ù„Ù…Ù„Ù.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"âŒ Ø§Ù„Ù…Ù„Ù ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ØŒ ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù…Ø³Ø§Ø±.\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ ØªØ¹Ø¯ÙŠÙ„ `requirements.txt`: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3daa29e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Ù…ÙƒØªØ¨Ø© `watchdog` Ù…Ø«Ø¨ØªØ© ÙˆØªØ¹Ù…Ù„!\n"
     ]
    }
   ],
   "source": [
    "import watchdog\n",
    "print(\"âœ… Ù…ÙƒØªØ¨Ø© `watchdog` Ù…Ø«Ø¨ØªØ© ÙˆØªØ¹Ù…Ù„!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "48200afb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rwxrwxrwx 1 ali ali 176 May 26 01:27 \u001b[0m\u001b[01;32m/mnt/c/Users/ali/Desktop/Innovation_Hub_New/Full_Stack_Framework/Flower_Classification_Foundation_V1/requirements.txt\u001b[0m\u001b[K*\r\n"
     ]
    }
   ],
   "source": [
    "ls -l /mnt/c/Users/ali/Desktop/Innovation_Hub_New/Full_Stack_Framework/Flower_Classification_Foundation_V1/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6b750a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ØªÙ… ØªØ­Ø¯ÙŠØ« `requirements.txt` Ø¨Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø¬Ø¯ÙŠØ¯!\n"
     ]
    }
   ],
   "source": [
    "req_file = \"/mnt/c/Users/ali/Desktop/Innovation_Hub_New/Full_Stack_Framework/Flower_Classification_Foundation_V1/requirements.txt\"\n",
    "\n",
    "requirements_content = \"\"\"\\\n",
    "python==3.10\n",
    "tensorflow-datasets==4.9.4\n",
    "tensorflow-hub==0.16.1\n",
    "scipy==1.12.0\n",
    "tf-keras==2.16.0  # https://github.com/tensorflow/tensorflow/issues/63849#issuecomment-2002501172\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    # Ø­Ø°Ù ÙƒÙ„ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø¯Ø§Ø®Ù„ `requirements.txt`\n",
    "    open(req_file, \"w\").close()\n",
    "\n",
    "    # Ø¥Ø¹Ø§Ø¯Ø© ÙƒØªØ§Ø¨Ø© Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø¬Ø¯ÙŠØ¯\n",
    "    with open(req_file, \"w\") as f:\n",
    "        f.write(requirements_content)\n",
    "\n",
    "    print(\"âœ… ØªÙ… ØªØ­Ø¯ÙŠØ« `requirements.txt` Ø¨Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø¬Ø¯ÙŠØ¯!\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"âŒ Ø§Ù„Ù…Ù„Ù ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ØŒ ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù…Ø³Ø§Ø±.\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ ØªØ¹Ø¯ÙŠÙ„ `requirements.txt`: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "48d88375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ØªÙ… ØªØ­Ø¯ÙŠØ« `environment.yaml` Ø¯Ø§Ø®Ù„ Ø¯ÙØªØ± Jupyter!\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "\n",
    "env_file = \"/mnt/c/Users/ali/Desktop/Innovation_Hub_New/Full_Stack_Framework/Flower_Classification_Foundation_V1/environment.yaml\"\n",
    "\n",
    "yaml_data = {\n",
    "    \"name\": \"flower_classification_env\",\n",
    "    \"channels\": [\"conda-forge\"],\n",
    "    \"dependencies\": [\n",
    "        \"python=3.10\",\n",
    "        \"tensorflow-datasets\",\n",
    "        \"tensorflow-hub\",\n",
    "        \"scipy\",\n",
    "        \"tf-keras\",\n",
    "        \"pip\",\n",
    "        {\"pip\": []}\n",
    "    ]\n",
    "}\n",
    "\n",
    "try:\n",
    "    with open(env_file, \"w\") as f:\n",
    "        yaml.dump(yaml_data, f, default_flow_style=False)\n",
    "\n",
    "    print(\"âœ… ØªÙ… ØªØ­Ø¯ÙŠØ« `environment.yaml` Ø¯Ø§Ø®Ù„ Ø¯ÙØªØ± Jupyter!\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"âŒ Ø§Ù„Ù…Ù„Ù ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ØŒ ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù…Ø³Ø§Ø±.\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ ØªØ­Ø¯ÙŠØ« `environment.yaml`: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4c92960f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "channels:\n",
      "- conda-forge\n",
      "dependencies:\n",
      "- python=3.10\n",
      "- tensorflow-datasets\n",
      "- tensorflow-hub\n",
      "- scipy\n",
      "- tf-keras\n",
      "- pip\n",
      "- pip: []\n",
      "name: flower_classification_env\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"/mnt/c/Users/ali/Desktop/Innovation_Hub_New/Full_Stack_Framework/Flower_Classification_Foundation_V1/environment.yaml\", \"r\") as f:\n",
    "    content = f.read()\n",
    "    print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3fd8be78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ØªÙ… Ø­Ø°Ù ÙˆØ¥Ø¹Ø§Ø¯Ø© Ø¥Ù†Ø´Ø§Ø¡ `environment.yaml` Ø¨ÙˆØ§Ø³Ø·Ø© Ø§Ù„Ø³ÙƒØ±Ø¨Øª!\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "\n",
    "env_file = \"/mnt/c/Users/ali/Desktop/Innovation_Hub_New/Full_Stack_Framework/Flower_Classification_Foundation_V1/environment.yaml\"\n",
    "\n",
    "yaml_data = {\n",
    "    \"name\": \"flower_classification_env\",\n",
    "    \"channels\": [\"conda-forge\"],\n",
    "    \"dependencies\": [\n",
    "        \"python=3.10\",\n",
    "        \"tensorflow-datasets\",\n",
    "        \"tensorflow-hub\",\n",
    "        \"scipy\",\n",
    "        \"tf-keras\",\n",
    "        \"pip\",\n",
    "        {\"pip\": []}\n",
    "    ]\n",
    "}\n",
    "\n",
    "try:\n",
    "    # ğŸ”¥ **Ø­Ø°Ù Ù…Ø­ØªÙˆÙ‰ `environment.yaml` Ø¨Ø§Ù„ÙƒØ§Ù…Ù„**\n",
    "    open(env_file, \"w\").close()\n",
    "\n",
    "    # âœ¨ **Ø¥Ø¹Ø§Ø¯Ø© ÙƒØªØ§Ø¨ØªÙ‡ Ø¨Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø¬Ø¯ÙŠØ¯**\n",
    "    with open(env_file, \"w\") as f:\n",
    "        yaml.dump(yaml_data, f, default_flow_style=False)\n",
    "\n",
    "    print(\"âœ… ØªÙ… Ø­Ø°Ù ÙˆØ¥Ø¹Ø§Ø¯Ø© Ø¥Ù†Ø´Ø§Ø¡ `environment.yaml` Ø¨ÙˆØ§Ø³Ø·Ø© Ø§Ù„Ø³ÙƒØ±Ø¨Øª!\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"âŒ Ø§Ù„Ù…Ù„Ù ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ØŒ ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù…Ø³Ø§Ø±.\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ ØªØ­Ø¯ÙŠØ« `environment.yaml`: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f61e87bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "channels:\n",
      "- conda-forge\n",
      "dependencies:\n",
      "- python=3.10\n",
      "- tensorflow-datasets\n",
      "- tensorflow-hub\n",
      "- scipy\n",
      "- tf-keras\n",
      "- pip\n",
      "- pip: []\n",
      "name: flower_classification_env\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"/mnt/c/Users/ali/Desktop/Innovation_Hub_New/Full_Stack_Framework/Flower_Classification_Foundation_V1/environment.yaml\", \"r\") as f:\n",
    "    content = f.read()\n",
    "    print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "511e9f35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    }
   ],
   "source": [
    " with open(\"/mnt/c/Users/ali/Desktop/Innovation_Hub_New/Full_Stack_Framework/Flower_Classification_Foundation_V1/environment.yaml\", \"r\") as f:\n",
    "    content = f.read()\n",
    "    print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9a73a507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ØªÙ… Ø­Ø°Ù ÙˆØ¥Ø¹Ø§Ø¯Ø© Ø¥Ù†Ø´Ø§Ø¡ `environment.yaml` Ø¨ÙˆØ§Ø³Ø·Ø© Ø§Ù„Ø³ÙƒØ±Ø¨Øª!\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "\n",
    "env_file = \"/mnt/c/Users/ali/Desktop/Innovation_Hub_New/Full_Stack_Framework/Flower_Classification_Foundation_V1/environment.yaml\"\n",
    "\n",
    "yaml_data = {\n",
    "    \"name\": \"flower_classification_env\",\n",
    "    \"channels\": [\"conda-forge\"],\n",
    "    \"dependencies\": [\n",
    "        \"python=3.10\",\n",
    "        \"tensorflow-datasets\",\n",
    "        \"tensorflow-hub\",\n",
    "        \"scipy\",\n",
    "        \"tf-keras\",\n",
    "        \"pip\",\n",
    "        {\"pip\": []}\n",
    "    ]\n",
    "}\n",
    "\n",
    "try:\n",
    "    # ğŸ”¥ **Ø­Ø°Ù Ù…Ø­ØªÙˆÙ‰ `environment.yaml` Ø¨Ø§Ù„ÙƒØ§Ù…Ù„**\n",
    "    open(env_file, \"w\").close()\n",
    "\n",
    "    # âœ¨ **Ø¥Ø¹Ø§Ø¯Ø© ÙƒØªØ§Ø¨ØªÙ‡ Ø¨Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø¬Ø¯ÙŠØ¯**\n",
    "    with open(env_file, \"w\") as f:\n",
    "        yaml.dump(yaml_data, f, default_flow_style=False)\n",
    "\n",
    "    print(\"âœ… ØªÙ… Ø­Ø°Ù ÙˆØ¥Ø¹Ø§Ø¯Ø© Ø¥Ù†Ø´Ø§Ø¡ `environment.yaml` Ø¨ÙˆØ§Ø³Ø·Ø© Ø§Ù„Ø³ÙƒØ±Ø¨Øª!\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"âŒ Ø§Ù„Ù…Ù„Ù ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ØŒ ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù…Ø³Ø§Ø±.\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ ØªØ­Ø¯ÙŠØ« `environment.yaml`: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "01d23186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "channels:\n",
      "- conda-forge\n",
      "dependencies:\n",
      "- python=3.10\n",
      "- tensorflow-datasets\n",
      "- tensorflow-hub\n",
      "- scipy\n",
      "- tf-keras\n",
      "- pip\n",
      "- pip: []\n",
      "name: flower_classification_env\n",
      "\n"
     ]
    }
   ],
   "source": [
    " with open(\"/mnt/c/Users/ali/Desktop/Innovation_Hub_New/Full_Stack_Framework/Flower_Classification_Foundation_V1/environment.yaml\", \"r\") as f:\n",
    "    content = f.read()\n",
    "    print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d94fb9cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading channels: done\n",
      "No match found for: edx-dl. Search: *edx-dl*\n",
      "\n",
      "PackagesNotFoundError: The following packages are not available from current channels:\n",
      "\n",
      "  - edx-dl\n",
      "\n",
      "Current channels:\n",
      "\n",
      "  - https://conda.anaconda.org/conda-forge/linux-64\n",
      "  - https://conda.anaconda.org/conda-forge/noarch\n",
      "  - https://repo.anaconda.com/pkgs/main/linux-64\n",
      "  - https://repo.anaconda.com/pkgs/main/noarch\n",
      "  - https://repo.anaconda.com/pkgs/r/linux-64\n",
      "  - https://repo.anaconda.com/pkgs/r/noarch\n",
      "\n",
      "To search for alternate channels that may provide the conda package you're\n",
      "looking for, navigate to\n",
      "\n",
      "    https://anaconda.org\n",
      "\n",
      "and use the search bar at the top of the page.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda search edx-dl -c conda-forge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b994690c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ØªÙ…Øª Ø¥Ø¶Ø§ÙØ© `edx-dl` Ø¥Ù„Ù‰ `requirements.txt`!\n"
     ]
    }
   ],
   "source": [
    "with open(\"/mnt/c/Users/ali/Desktop/Innovation_Hub_New/Full_Stack_Framework/requirements.txt\", \"a\") as f:\n",
    "    f.write(\"\\nedx-dl\")\n",
    "    print(\"âœ… ØªÙ…Øª Ø¥Ø¶Ø§ÙØ© `edx-dl` Ø¥Ù„Ù‰ `requirements.txt`!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6c896cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "edx-dl\n"
     ]
    }
   ],
   "source": [
    "with open(\"/mnt/c/Users/ali/Desktop/Innovation_Hub_New/Full_Stack_Framework/requirements.txt\", \"r\") as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f608e58b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/ali/Desktop/Innovation_Hub_New/Full_Stack_Framework\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())  # ØªØ£ÙƒÙŠØ¯ Ø£Ù†Ùƒ ÙÙŠ Ø§Ù„Ù…Ø³Ø§Ø± Ø§Ù„ØµØ­ÙŠØ­"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "919094a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "edx-dl\n"
     ]
    }
   ],
   "source": [
    "with open(\"/mnt/c/Users/ali/Desktop/Innovation_Hub_New/Full_Stack_Framework/requirements.txt\", \"r\") as f:\n",
    "    print(f.read())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ae9fade2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rwxrwxrwx 1 ali ali 7 May 26 02:01 \u001b[0m\u001b[01;32m/mnt/c/Users/ali/Desktop/Innovation_Hub_New/Full_Stack_Framework/requirements.txt\u001b[0m\u001b[K*\r\n"
     ]
    }
   ],
   "source": [
    "ls -l /mnt/c/Users/ali/Desktop/Innovation_Hub_New/Full_Stack_Framework/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "430a1f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "edx-dl\n"
     ]
    }
   ],
   "source": [
    "with open(\"/mnt/c/Users/ali/Desktop/Innovation_Hub_New/Full_Stack_Framework/requirements.txt\", \"r\") as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "276d4b44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/ali/Desktop/Innovation_Hub_New/Full_Stack_Framework\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())  # ØªØ­Ù‚Ù‚ Ù…Ù† Ø£Ù†Ùƒ ÙÙŠ Ø§Ù„Ù…Ø³Ø§Ø± Ø§Ù„ØµØ­ÙŠØ­"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d401b609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 8\r\n",
      "-rwxrwxrwx 1 ali ali  525 May 25 22:30 \u001b[0m\u001b[01;32mREADME.md\u001b[0m*\r\n",
      "-rwxrwxrwx 1 ali ali  158 May 26 01:43 \u001b[01;32menvironment.yaml\u001b[0m*\r\n",
      "-rwxrwxrwx 1 ali ali  175 May 26 01:35 \u001b[01;32mrequirements.txt\u001b[0m*\r\n",
      "-rwxrwxrwx 1 ali ali 2596 May 26 00:01 \u001b[01;32mupdate_yaml.py\u001b[0m*\r\n",
      "-rwxrwxrwx 1 ali ali 1387 May 26 00:55 \u001b[01;32mwatch_requirements.py\u001b[0m*\r\n"
     ]
    }
   ],
   "source": [
    "ls -l /mnt/c/Users/ali/Desktop/Innovation_Hub_New/Full_Stack_Framework/Flower_Classification_Foundation_V1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d70a90d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python==3.10\n",
      "tensorflow-datasets==4.9.4\n",
      "tensorflow-hub==0.16.1\n",
      "scipy==1.12.0\n",
      "tf-keras==2.16.0  # https://github.com/tensorflow/tensorflow/issues/63849#issuecomment-2002501172\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"/mnt/c/Users/ali/Desktop/Innovation_Hub_New/Full_Stack_Framework/Flower_Classification_Foundation_V1/requirements.txt\", \"r\") as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "139cdf02",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/mnt/c/Users/ali/Desktop/Innovation_Hub_New/Full_Stack_Framework/Flower_Classification_Foundation_V1/requirements.txt\", \"a\") as f:\n",
    "    f.write(\"\\nedx-dl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d62883af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\r\n"
     ]
    }
   ],
   "source": [
    "!python /mnt/c/Users/ali/Desktop/Innovation_Hub_New/Full_Stack_Framework/Flower_Classification_Foundation_V1/update_yaml.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3d6efe5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† `tensorflow-datasets` Ø§Ø³ØªØºØ±Ù‚ ÙˆÙ‚ØªÙ‹Ø§ Ø·ÙˆÙŠÙ„Ø§Ù‹ØŒ Ø³ÙŠØªÙ… Ø§Ø¹ØªØ¨Ø§Ø±Ù‡ ØºÙŠØ± Ù…ØªØ§Ø­ ÙÙŠ Conda.\n",
      "âš ï¸ Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† `tensorflow-hub` Ø§Ø³ØªØºØ±Ù‚ ÙˆÙ‚ØªÙ‹Ø§ Ø·ÙˆÙŠÙ„Ø§Ù‹ØŒ Ø³ÙŠØªÙ… Ø§Ø¹ØªØ¨Ø§Ø±Ù‡ ØºÙŠØ± Ù…ØªØ§Ø­ ÙÙŠ Conda.\n",
      "âš ï¸ Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† `scipy` Ø§Ø³ØªØºØ±Ù‚ ÙˆÙ‚ØªÙ‹Ø§ Ø·ÙˆÙŠÙ„Ø§Ù‹ØŒ Ø³ÙŠØªÙ… Ø§Ø¹ØªØ¨Ø§Ø±Ù‡ ØºÙŠØ± Ù…ØªØ§Ø­ ÙÙŠ Conda.\n",
      "âš ï¸ Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† `tf-keras` Ø§Ø³ØªØºØ±Ù‚ ÙˆÙ‚ØªÙ‹Ø§ Ø·ÙˆÙŠÙ„Ø§Ù‹ØŒ Ø³ÙŠØªÙ… Ø§Ø¹ØªØ¨Ø§Ø±Ù‡ ØºÙŠØ± Ù…ØªØ§Ø­ ÙÙŠ Conda.\n",
      "âš ï¸ Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† `edx-dl` Ø§Ø³ØªØºØ±Ù‚ ÙˆÙ‚ØªÙ‹Ø§ Ø·ÙˆÙŠÙ„Ø§Ù‹ØŒ Ø³ÙŠØªÙ… Ø§Ø¹ØªØ¨Ø§Ø±Ù‡ ØºÙŠØ± Ù…ØªØ§Ø­ ÙÙŠ Conda.\n",
      "âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ `environment.yaml` Ø¨Ø¯ÙˆÙ† Ø¥ØµØ¯Ø§Ø± Ø¨Ø§ÙŠØ«ÙˆÙ†ØŒ Ø¨Ø­ÙŠØ« ÙŠØªÙ… ØªØ­Ø¯ÙŠØ¯Ù‡ Ø¹Ø¨Ø± `requirements.txt`!\n",
      "ğŸ“œ ØªÙ… Ø­ÙØ¸ Ø³Ø¬Ù„ Ø§Ù„ØªØ­Ø°ÙŠØ±Ø§Øª Ø¯Ø§Ø®Ù„ `/mnt/c/Users/ali/Desktop/Innovation_Hub_New/Full_Stack_Framework/Flower_Classification_Foundation_V1/dependency_log.txt`!\n",
      "â³ Ø§Ù†ØªÙ‡Ù‰ Ø§Ù„ØªÙ†ÙÙŠØ° Ø®Ù„Ø§Ù„ 161.86 Ø«Ø§Ù†ÙŠØ©\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "import subprocess\n",
    "import time\n",
    "\n",
    "# ØªØ³Ø¬ÙŠÙ„ ÙˆÙ‚Øª Ø¨Ø¯Ø¡ Ø§Ù„ØªÙ†ÙÙŠØ°\n",
    "start_time = time.time()\n",
    "\n",
    "# ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª Ø¯Ø§Ø®Ù„ WSL2\n",
    "req_file = \"/mnt/c/Users/ali/Desktop/Innovation_Hub_New/Full_Stack_Framework/Flower_Classification_Foundation_V1/requirements.txt\"\n",
    "env_file = \"/mnt/c/Users/ali/Desktop/Innovation_Hub_New/Full_Stack_Framework/Flower_Classification_Foundation_V1/environment.yaml\"\n",
    "log_file = \"/mnt/c/Users/ali/Desktop/Innovation_Hub_New/Full_Stack_Framework/Flower_Classification_Foundation_V1/dependency_log.txt\"\n",
    "\n",
    "# ÙˆØ¸ÙŠÙØ© Ù„Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØªÙˆÙØ± Ø§Ù„Ù…ÙƒØªØ¨Ø© Ø¯Ø§Ø®Ù„ Conda Forge\n",
    "def is_available_in_conda(package_name):\n",
    "    try:\n",
    "        result = subprocess.run([\"conda\", \"search\", package_name, \"-c\", \"conda-forge\"], \n",
    "                                capture_output=True, text=True, timeout=30)  # â³ Ù…Ù‡Ù„Ø© Ø²Ù…Ù†ÙŠØ© Ù„ØªØ¬Ù†Ø¨ Ø§Ù„ØªØ£Ø®ÙŠØ± Ø§Ù„Ø·ÙˆÙŠÙ„\n",
    "        return package_name in result.stdout\n",
    "    except subprocess.TimeoutExpired:\n",
    "        print(f\"âš ï¸ Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† `{package_name}` Ø§Ø³ØªØºØ±Ù‚ ÙˆÙ‚ØªÙ‹Ø§ Ø·ÙˆÙŠÙ„Ø§Ù‹ØŒ Ø³ÙŠØªÙ… Ø§Ø¹ØªØ¨Ø§Ø±Ù‡ ØºÙŠØ± Ù…ØªØ§Ø­ ÙÙŠ Conda.\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† {package_name} ÙÙŠ `conda-forge`: {e}\")\n",
    "        return False\n",
    "\n",
    "# Ù‚Ø±Ø§Ø¡Ø© Ù…Ù„Ù Ø§Ù„Ù…ØªØ·Ù„Ø¨Ø§Øª ÙˆÙ…Ø¹Ø§Ù„Ø¬ØªÙ‡\n",
    "try:\n",
    "    with open(req_file, \"r\") as f:\n",
    "        requirements = [line.strip().split(\"==\")[0] for line in f.readlines() if line.strip()]\n",
    "\n",
    "    conda_dependencies = []\n",
    "    pip_dependencies = []\n",
    "\n",
    "    log_messages = []\n",
    "    for pkg in requirements:\n",
    "        if pkg.startswith(\"python\"):\n",
    "            continue  # ØªØ¬Ø§Ù‡Ù„ Ø¥ØµØ¯Ø§Ø± Ø¨Ø§ÙŠØ«ÙˆÙ† Ù„Ø£Ù†Ù‡ Ø³ÙŠØªÙ… Ø§Ù„ØªØ­ÙƒÙ… ÙÙŠÙ‡ Ù…Ù† `requirements.txt`\n",
    "        if is_available_in_conda(pkg):\n",
    "            conda_dependencies.append(pkg)\n",
    "        else:\n",
    "            pip_dependencies.append(pkg)\n",
    "            log_messages.append(f\"âš ï¸ `{pkg}` ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ `conda-forge`ØŒ Ø³ÙŠØªÙ… ØªØ«Ø¨ÙŠØªÙ‡ Ø¹Ø¨Ø± `pip`.\")\n",
    "\n",
    "    # Ø¥Ù†Ø´Ø§Ø¡ `environment.yaml` Ø¨Ø¯ÙˆÙ† ØªØ­Ø¯ÙŠØ¯ Ø¥ØµØ¯Ø§Ø± Ø¨Ø§ÙŠØ«ÙˆÙ†\n",
    "    yaml_data = {\n",
    "        \"name\": \"flower_classification_env\",\n",
    "        \"channels\": [\"conda-forge\"],\n",
    "        \"dependencies\": conda_dependencies + [\"pip\"] + ([{\"pip\": pip_dependencies}] if pip_dependencies else [])\n",
    "    }\n",
    "\n",
    "    with open(env_file, \"w\") as f:\n",
    "        yaml.dump(yaml_data, f, default_flow_style=False)\n",
    "\n",
    "    print(\"âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ `environment.yaml` Ø¨Ø¯ÙˆÙ† Ø¥ØµØ¯Ø§Ø± Ø¨Ø§ÙŠØ«ÙˆÙ†ØŒ Ø¨Ø­ÙŠØ« ÙŠØªÙ… ØªØ­Ø¯ÙŠØ¯Ù‡ Ø¹Ø¨Ø± `requirements.txt`!\")\n",
    "\n",
    "    # Ø­ÙØ¸ Ø³Ø¬Ù„ Ø§Ù„ØªØ­Ø°ÙŠØ±Ø§Øª\n",
    "    if log_messages:\n",
    "        with open(log_file, \"w\") as log_f:\n",
    "            log_f.write(\"\\n\".join(log_messages))  # âœ… Ø¥ØµÙ„Ø§Ø­ Ø§Ù„Ø®Ø·Ø£ Ø§Ù„Ø³Ø§Ø¨Ù‚\n",
    "        print(f\"ğŸ“œ ØªÙ… Ø­ÙØ¸ Ø³Ø¬Ù„ Ø§Ù„ØªØ­Ø°ÙŠØ±Ø§Øª Ø¯Ø§Ø®Ù„ `{log_file}`!\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"âŒ `requirements.txt` ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ØŒ ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù…Ø³Ø§Ø±.\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø¥Ù†Ø´Ø§Ø¡ `environment.yaml`: {e}\")\n",
    "\n",
    "# ØªØ³Ø¬ÙŠÙ„ ÙˆÙ‚Øª Ø§Ù†ØªÙ‡Ø§Ø¡ Ø§Ù„ØªÙ†ÙÙŠØ°\n",
    "print(f\"â³ Ø§Ù†ØªÙ‡Ù‰ Ø§Ù„ØªÙ†ÙÙŠØ° Ø®Ù„Ø§Ù„ {time.time() - start_time:.2f} Ø«Ø§Ù†ÙŠØ©\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e2d21299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /mnt/c/Users/ali/Desktop/Innovation_Hub_New/Full_Stack_Framework/Flower_Classification_Foundation_V1/update_yaml.py\n"
     ]
    }
   ],
   "source": [
    " %%writefile /mnt/c/Users/ali/Desktop/Innovation_Hub_New/Full_Stack_Framework/Flower_Classification_Foundation_V1/update_yaml.py\n",
    "import yaml\n",
    "import subprocess\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "req_file = \"/mnt/c/Users/ali/Desktop/Innovation_Hub_New/Full_Stack_Framework/Flower_Classification_Foundation_V1/requirements.txt\"\n",
    "env_file = \"/mnt/c/Users/ali/Desktop/Innovation_Hub_New/Full_Stack_Framework/Flower_Classification_Foundation_V1/environment.yaml\"\n",
    "log_file = \"/mnt/c/Users/ali/Desktop/Innovation_Hub_New/Full_Stack_Framework/Flower_Classification_Foundation_V1/dependency_log.txt\"\n",
    "\n",
    "def is_available_in_conda(package_name):\n",
    "    try:\n",
    "        result = subprocess.run([\"conda\", \"search\", package_name, \"-c\", \"conda-forge\"], \n",
    "                                capture_output=True, text=True, timeout=15)\n",
    "        return package_name in result.stdout\n",
    "    except subprocess.TimeoutExpired:\n",
    "        print(f\"Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† `{package_name}` Ø§Ø³ØªØºØ±Ù‚ ÙˆÙ‚ØªÙ‹Ø§ Ø·ÙˆÙŠÙ„Ø§Ù‹ØŒ Ø³ÙŠØªÙ… ØªØ«Ø¨ÙŠØªÙ‡ Ø¹Ø¨Ø± pip.\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† {package_name} ÙÙŠ conda-forge: {e}\")\n",
    "        return False\n",
    "\n",
    "try:\n",
    "    with open(req_file, \"r\") as f:\n",
    "        requirements = [line.strip().split(\"==\")[0] for line in f.readlines() if line.strip()]\n",
    "\n",
    "    conda_dependencies = []\n",
    "    pip_dependencies = []\n",
    "\n",
    "    log_messages = []\n",
    "    for pkg in requirements:\n",
    "        if pkg.startswith(\"python\"):\n",
    "            continue\n",
    "        if is_available_in_conda(pkg):\n",
    "            conda_dependencies.append(pkg)\n",
    "        else:\n",
    "            pip_dependencies.append(pkg)\n",
    "            log_messages.append(f\"{pkg} Ø³ÙŠØªÙ… ØªØ«Ø¨ÙŠØªÙ‡ Ø¹Ø¨Ø± pip.\")\n",
    "\n",
    "    yaml_data = {\n",
    "        \"name\": \"flower_classification_env\",\n",
    "        \"channels\": [\"conda-forge\"],\n",
    "        \"dependencies\": conda_dependencies + [\"pip\", {\"pip\": pip_dependencies}] if pip_dependencies else [\"pip\"]\n",
    "    }\n",
    "\n",
    "    with open(env_file, \"w\") as f:\n",
    "        yaml.dump(yaml_data, f, default_flow_style=False)\n",
    "\n",
    "    print(\"ØªÙ… ØªØ­Ø¯ÙŠØ« environment.yaml Ø¨Ù†Ø¬Ø§Ø­!\")\n",
    "\n",
    "    if log_messages:\n",
    "        with open(log_file, \"w\") as log_f:\n",
    "            log_f.write(\"\\n\".join(log_messages))\n",
    "        print(f\"ØªÙ… Ø­ÙØ¸ Ø³Ø¬Ù„ Ø§Ù„ØªØ­Ø°ÙŠØ±Ø§Øª ÙÙŠ {log_file}!\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"requirements.txt ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ØŒ ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù…Ø³Ø§Ø±.\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ ØªØ­Ø¯ÙŠØ« environment.yaml: {e}\")\n",
    "\n",
    "print(f\"â³ Ø§Ù†ØªÙ‡Ù‰ Ø§Ù„ØªÙ†ÙÙŠØ° Ø®Ù„Ø§Ù„ {time.time() - start_time:.2f} Ø«Ø§Ù†ÙŠØ©\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "61c37788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† tensorflow-datasets ÙÙŠ conda-forge: [Errno 2] No such file or directory: 'micromamba'\n",
      "Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† tensorflow-hub ÙÙŠ conda-forge: [Errno 2] No such file or directory: 'micromamba'\n",
      "Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† scipy ÙÙŠ conda-forge: [Errno 2] No such file or directory: 'micromamba'\n",
      "Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† tf-keras ÙÙŠ conda-forge: [Errno 2] No such file or directory: 'micromamba'\n",
      "Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† edx-dl ÙÙŠ conda-forge: [Errno 2] No such file or directory: 'micromamba'\n",
      "ØªÙ… ØªØ­Ø¯ÙŠØ« environment.yaml Ø¨Ù†Ø¬Ø§Ø­!\n",
      "ØªÙ… Ø­ÙØ¸ Ø³Ø¬Ù„ Ø§Ù„ØªØ­Ø°ÙŠØ±Ø§Øª ÙÙŠ /mnt/c/Users/ali/Desktop/Innovation_Hub_New/Full_Stack_Framework/Flower_Classification_Foundation_V1/dependency_log.txt!\n",
      "ğŸš€ ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ /mnt/c/Users/ali/Desktop/Innovation_Hub_New/Full_Stack_Framework/Flower_Classification_Foundation_V1/comparisons/comparison_1.txt Ù„Ø¹Ø±Ø¶ Ø§Ù„ÙØ±ÙˆÙ‚Ø§Øª Ø¨ÙŠÙ† Ø§Ù„Ù…Ù„ÙØ§Øª!\n",
      "â³ Ø§Ù†ØªÙ‡Ù‰ Ø§Ù„ØªÙ†ÙÙŠØ° Ø®Ù„Ø§Ù„ 0.45 Ø«Ø§Ù†ÙŠØ©\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "import subprocess\n",
    "import time\n",
    "import os\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "req_file = \"/mnt/c/Users/ali/Desktop/Innovation_Hub_New/Full_Stack_Framework/Flower_Classification_Foundation_V1/requirements.txt\"\n",
    "env_file = \"/mnt/c/Users/ali/Desktop/Innovation_Hub_New/Full_Stack_Framework/Flower_Classification_Foundation_V1/environment.yaml\"\n",
    "log_file = \"/mnt/c/Users/ali/Desktop/Innovation_Hub_New/Full_Stack_Framework/Flower_Classification_Foundation_V1/dependency_log.txt\"\n",
    "comp_dir = \"/mnt/c/Users/ali/Desktop/Innovation_Hub_New/Full_Stack_Framework/Flower_Classification_Foundation_V1/comparisons/\"\n",
    "\n",
    "# Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ø¬Ù„Ø¯ Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ù…ÙˆØ¬ÙˆØ¯Ù‹Ø§\n",
    "if not os.path.exists(comp_dir):\n",
    "    os.makedirs(comp_dir)\n",
    "\n",
    "# ØªØ­Ø¯ÙŠØ¯ Ø±Ù‚Ù… Ø§Ù„Ù…Ù„Ù Ø§Ù„Ø¬Ø¯ÙŠØ¯\n",
    "existing_files = [f for f in os.listdir(comp_dir) if f.startswith(\"comparison_\") and f.endswith(\".txt\")]\n",
    "file_numbers = [int(f.split(\"_\")[1].split(\".\")[0]) for f in existing_files if f.split(\"_\")[1].split(\".\")[0].isdigit()]\n",
    "next_file_number = max(file_numbers, default=0) + 1\n",
    "comp_file = f\"{comp_dir}comparison_{next_file_number}.txt\"\n",
    "\n",
    "def is_available_in_conda(package_name):\n",
    "    try:\n",
    "        result = subprocess.run([\"micromamba\", \"search\", package_name, \"-c\", \"conda-forge\"], \n",
    "                                capture_output=True, text=True, timeout=15)\n",
    "        return package_name in result.stdout\n",
    "    except subprocess.TimeoutExpired:\n",
    "        print(f\"Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† `{package_name}` Ø§Ø³ØªØºØ±Ù‚ ÙˆÙ‚ØªÙ‹Ø§ Ø·ÙˆÙŠÙ„Ø§Ù‹ØŒ Ø³ÙŠØªÙ… ØªØ«Ø¨ÙŠØªÙ‡ Ø¹Ø¨Ø± pip.\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† {package_name} ÙÙŠ conda-forge: {e}\")\n",
    "        return False\n",
    "\n",
    "try:\n",
    "    with open(req_file, \"r\") as f:\n",
    "        requirements = [line.strip().split(\"==\")[0] for line in f.readlines() if line.strip()]\n",
    "\n",
    "    conda_dependencies = []\n",
    "    pip_dependencies = []\n",
    "\n",
    "    log_messages = []\n",
    "    for pkg in requirements:\n",
    "        if pkg.startswith(\"python\"):\n",
    "            continue\n",
    "        if is_available_in_conda(pkg):\n",
    "            conda_dependencies.append(pkg)\n",
    "        else:\n",
    "            pip_dependencies.append(pkg)\n",
    "            log_messages.append(f\"{pkg} Ø³ÙŠØªÙ… ØªØ«Ø¨ÙŠØªÙ‡ Ø¹Ø¨Ø± pip.\")\n",
    "\n",
    "    yaml_data = {\n",
    "        \"name\": \"flower_classification_env\",\n",
    "        \"channels\": [\"conda-forge\"],\n",
    "        \"dependencies\": conda_dependencies + [\"pip\", {\"pip\": pip_dependencies}] if pip_dependencies else [\"pip\"]\n",
    "    }\n",
    "\n",
    "    with open(env_file, \"w\") as f:\n",
    "        yaml.dump(yaml_data, f, default_flow_style=False)\n",
    "\n",
    "    print(\"ØªÙ… ØªØ­Ø¯ÙŠØ« environment.yaml Ø¨Ù†Ø¬Ø§Ø­!\")\n",
    "\n",
    "    if log_messages:\n",
    "        with open(log_file, \"w\") as log_f:\n",
    "            log_f.write(\"\\n\".join(log_messages))\n",
    "        print(f\"ØªÙ… Ø­ÙØ¸ Ø³Ø¬Ù„ Ø§Ù„ØªØ­Ø°ÙŠØ±Ø§Øª ÙÙŠ {log_file}!\")\n",
    "\n",
    "    with open(comp_file, \"w\") as comp_f:\n",
    "        comp_f.write(f\"ğŸ”¹ Ù…Ù‚Ø§Ø±Ù†Ø© ØªØ´ØºÙŠÙ„ Ø±Ù‚Ù… {next_file_number}\\n\")\n",
    "        comp_f.write(f\"â³ ÙˆÙ‚Øª Ø§Ù„ØªÙ†ÙÙŠØ°: {time.time() - start_time:.2f} Ø«Ø§Ù†ÙŠØ©\\n\\n\")\n",
    "        comp_f.write(\"ğŸ“œ Ù…Ø­ØªÙˆÙ‰ requirements.txt:\\n\")\n",
    "        comp_f.write(\"\\n\".join(requirements) + \"\\n\\n\")\n",
    "        comp_f.write(\"ğŸ“œ Ù…Ø­ØªÙˆÙ‰ environment.yaml:\\n\")\n",
    "        comp_f.write(\"\\n\".join(conda_dependencies + pip_dependencies) + \"\\n\")\n",
    "\n",
    "    print(f\"ğŸš€ ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ {comp_file} Ù„Ø¹Ø±Ø¶ Ø§Ù„ÙØ±ÙˆÙ‚Ø§Øª Ø¨ÙŠÙ† Ø§Ù„Ù…Ù„ÙØ§Øª!\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"requirements.txt ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ØŒ ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù…Ø³Ø§Ø±.\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ ØªØ­Ø¯ÙŠØ« environment.yaml: {e}\")\n",
    "\n",
    "print(f\"â³ Ø§Ù†ØªÙ‡Ù‰ Ø§Ù„ØªÙ†ÙÙŠØ° Ø®Ù„Ø§Ù„ {time.time() - start_time:.2f} Ø«Ø§Ù†ÙŠØ©\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3a7edf64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Ø³ÙŠØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù…: micromamba\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "# Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù…Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù† micromamba Ù…Ø«Ø¨ØªÙ‹Ø§\n",
    "micromamba_available = shutil.which(\"micromamba\") is not None\n",
    "conda_command = \"micromamba\" if micromamba_available else \"conda\"\n",
    "\n",
    "# Ø¹Ø±Ø¶ Ø§Ù„Ø£Ø¯Ø§Ø© Ø§Ù„ØªÙŠ Ø³ÙŠØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù…Ù‡Ø§\n",
    "print(f\"ğŸ” Ø³ÙŠØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù…: {conda_command}\")\n",
    "\n",
    "def is_available_in_conda(package_name):\n",
    "    try:\n",
    "        result = subprocess.run([conda_command, \"search\", package_name, \"-c\", \"conda-forge\"], \n",
    "                                capture_output=True, text=True, timeout=15)\n",
    "        return package_name in result.stdout\n",
    "    except Exception as e:\n",
    "        print(f\"Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† {package_name} Ø¹Ø¨Ø± {conda_command}: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "13894bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† tensorflow-datasets Ø¹Ø¨Ø± micromamba: Command '['micromamba', 'search', 'tensorflow-datasets', '-c', 'conda-forge']' timed out after 15 seconds\n",
      "False\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b7904a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† tensorflow-datasets Ø¹Ø¨Ø± micromamba: Command '['micromamba', 'search', 'tensorflow-datasets', '-c', 'conda-forge']' timed out after 15 seconds\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(is_available_in_conda(\"tensorflow-datasets\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6ffbd629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† edx-dl Ø¹Ø¨Ø± micromamba: Command '['micromamba', 'search', 'edx-dl', '-c', 'conda-forge']' timed out after 15 seconds\n",
      "âœ… ØªÙ… ØªØ­Ø¯ÙŠØ« environment.yaml Ø¨Ù†Ø¬Ø§Ø­!\n",
      "ğŸ“œ ØªÙ… Ø­ÙØ¸ Ø³Ø¬Ù„ Ø§Ù„ØªØ­Ø°ÙŠØ±Ø§Øª ÙÙŠ dependency_log.txt!\n",
      "ğŸ“‚ ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ comparisons/comparison_1.txt Ù„Ø¹Ø±Ø¶ Ø§Ù„ÙØ±ÙˆÙ‚Ø§Øª Ø¨ÙŠÙ† Ø§Ù„Ù…Ù„ÙØ§Øª!\n",
      "â³ Ø§Ù†ØªÙ‡Ù‰ Ø§Ù„ØªÙ†ÙÙŠØ° Ø®Ù„Ø§Ù„ 18.40 Ø«Ø§Ù†ÙŠØ©\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "import subprocess\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "req_file = \"requirements.txt\"\n",
    "env_file = \"environment.yaml\"\n",
    "log_file = \"dependency_log.txt\"\n",
    "comp_dir = \"comparisons/\"\n",
    "\n",
    "# Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù…Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù† micromamba Ù…Ø«Ø¨ØªÙ‹Ø§\n",
    "micromamba_available = shutil.which(\"micromamba\") is not None\n",
    "conda_command = \"micromamba\" if micromamba_available else \"conda\"\n",
    "\n",
    "# Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¬Ù„Ø¯ Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø§Øª Ø¥Ù† Ù„Ù… ÙŠÙƒÙ† Ù…ÙˆØ¬ÙˆØ¯Ù‹Ø§\n",
    "if not os.path.exists(comp_dir):\n",
    "    os.makedirs(comp_dir)\n",
    "\n",
    "# ØªØ­Ø¯ÙŠØ¯ Ø±Ù‚Ù… Ù…Ù„Ù Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ø¬Ø¯ÙŠØ¯\n",
    "existing_files = [f for f in os.listdir(comp_dir) if f.startswith(\"comparison_\") and f.endswith(\".txt\")]\n",
    "file_numbers = [int(f.split(\"_\")[1].split(\".\")[0]) for f in existing_files if f.split(\"_\")[1].split(\".\")[0].isdigit()]\n",
    "next_file_number = max(file_numbers, default=0) + 1\n",
    "comp_file = f\"{comp_dir}comparison_{next_file_number}.txt\"\n",
    "\n",
    "def is_available_in_conda(package_name):\n",
    "    try:\n",
    "        result = subprocess.run([conda_command, \"search\", package_name, \"-c\", \"conda-forge\"], \n",
    "                                capture_output=True, text=True, timeout=15)\n",
    "        return package_name in result.stdout\n",
    "    except Exception as e:\n",
    "        print(f\"Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† {package_name} Ø¹Ø¨Ø± {conda_command}: {e}\")\n",
    "        return False\n",
    "\n",
    "try:\n",
    "    with open(req_file, \"r\") as f:\n",
    "        requirements = [line.strip() for line in f.readlines() if line.strip()]\n",
    "\n",
    "    conda_dependencies = []\n",
    "    pip_dependencies = []\n",
    "    python_version = None\n",
    "    log_messages = []\n",
    "\n",
    "    for line in requirements:\n",
    "        parts = line.split()\n",
    "        package = parts[0]\n",
    "        version = f\"=={parts[1]}\" if len(parts) > 1 and \"==\" in parts[1] else \"\"\n",
    "        method = parts[-1] if len(parts) > 1 and parts[-1] in [\"conda\", \"pip\"] else None\n",
    "\n",
    "        if package.startswith(\"python\"):\n",
    "            python_version = package + version\n",
    "            continue\n",
    "        \n",
    "        if method == \"conda\" or (not method and is_available_in_conda(package)):\n",
    "            conda_dependencies.append(f\"{package}{version}\")\n",
    "        else:\n",
    "            pip_dependencies.append(f\"{package}{version}\")\n",
    "            log_messages.append(f\"{package}{version} Ø³ÙŠØªÙ… ØªØ«Ø¨ÙŠØªÙ‡ Ø¹Ø¨Ø± pip.\")\n",
    "\n",
    "    yaml_data = {\n",
    "        \"name\": \"flower_classification_env\",\n",
    "        \"channels\": [\"conda-forge\"],\n",
    "        \"dependencies\": ([\"python\" + python_version] if python_version else []) + conda_dependencies + [\"pip\", {\"pip\": pip_dependencies}] if pip_dependencies else [\"pip\"]\n",
    "    }\n",
    "\n",
    "    with open(env_file, \"w\") as f:\n",
    "        yaml.dump(yaml_data, f, default_flow_style=False)\n",
    "\n",
    "    print(\"âœ… ØªÙ… ØªØ­Ø¯ÙŠØ« environment.yaml Ø¨Ù†Ø¬Ø§Ø­!\")\n",
    "\n",
    "    if log_messages:\n",
    "        with open(log_file, \"w\") as log_f:\n",
    "            log_f.write(\"\\n\".join(log_messages))\n",
    "        print(f\"ğŸ“œ ØªÙ… Ø­ÙØ¸ Ø³Ø¬Ù„ Ø§Ù„ØªØ­Ø°ÙŠØ±Ø§Øª ÙÙŠ {log_file}!\")\n",
    "\n",
    "    with open(comp_file, \"w\") as comp_f:\n",
    "        comp_f.write(f\"ğŸ”¹ Ù…Ù‚Ø§Ø±Ù†Ø© ØªØ´ØºÙŠÙ„ Ø±Ù‚Ù… {next_file_number}\\n\")\n",
    "        comp_f.write(f\"â³ ÙˆÙ‚Øª Ø§Ù„ØªÙ†ÙÙŠØ°: {time.time() - start_time:.2f} Ø«Ø§Ù†ÙŠØ©\\n\")\n",
    "        comp_f.write(f\"ğŸ› ï¸ Ø¥ØµØ¯Ø§Ø± Conda Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…: {subprocess.run(['conda', '--version'], capture_output=True, text=True).stdout.strip()}\\n\")\n",
    "        if micromamba_available:\n",
    "            comp_f.write(f\"ğŸ› ï¸ Ø¥ØµØ¯Ø§Ø± Micromamba Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…: {subprocess.run(['micromamba', '--version'], capture_output=True, text=True).stdout.strip()}\\n\")\n",
    "        comp_f.write(\"\\nğŸ“œ Ù…Ø­ØªÙˆÙ‰ requirements.txt:\\n\")\n",
    "        comp_f.write(\"\\n\".join(requirements) + \"\\n\\n\")\n",
    "        comp_f.write(\"ğŸ“œ Ù…Ø­ØªÙˆÙ‰ environment.yaml:\\n\")\n",
    "        comp_f.write(\"\\n\".join(conda_dependencies + pip_dependencies) + \"\\n\")\n",
    "\n",
    "    print(f\"ğŸ“‚ ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ {comp_file} Ù„Ø¹Ø±Ø¶ Ø§Ù„ÙØ±ÙˆÙ‚Ø§Øª Ø¨ÙŠÙ† Ø§Ù„Ù…Ù„ÙØ§Øª!\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"âŒ `requirements.txt` ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ØŒ ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù…Ø³Ø§Ø±.\")\n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ ØªØ­Ø¯ÙŠØ« environment.yaml: {e}\")\n",
    "\n",
    "print(f\"â³ Ø§Ù†ØªÙ‡Ù‰ Ø§Ù„ØªÙ†ÙÙŠØ° Ø®Ù„Ø§Ù„ {time.time() - start_time:.2f} Ø«Ø§Ù†ÙŠØ©\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7e1f5aae",
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "File `'update_yaml.py'` not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/IPython/core/magics/execution.py:716\u001b[0m, in \u001b[0;36mExecutionMagics.run\u001b[0;34m(self, parameter_s, runner, file_finder)\u001b[0m\n\u001b[1;32m    715\u001b[0m     fpath \u001b[38;5;241m=\u001b[39m arg_lst[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 716\u001b[0m     filename \u001b[38;5;241m=\u001b[39m \u001b[43mfile_finder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    717\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/IPython/utils/path.py:90\u001b[0m, in \u001b[0;36mget_py_filename\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m py_name\n\u001b[0;32m---> 90\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile `\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m` not found.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m name)\n",
      "\u001b[0;31mOSError\u001b[0m: File `'update_yaml.py'` not found.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[80], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_line_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrun\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mupdate_yaml.py\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/IPython/core/interactiveshell.py:2456\u001b[0m, in \u001b[0;36mInteractiveShell.run_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2454\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocal_ns\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_local_scope(stack_depth)\n\u001b[1;32m   2455\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[0;32m-> 2456\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2458\u001b[0m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[1;32m   2459\u001b[0m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[1;32m   2460\u001b[0m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[1;32m   2461\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic\u001b[38;5;241m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/IPython/core/magics/execution.py:727\u001b[0m, in \u001b[0;36mExecutionMagics.run\u001b[0;34m(self, parameter_s, runner, file_finder)\u001b[0m\n\u001b[1;32m    725\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnt\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m re\u001b[38;5;241m.\u001b[39mmatch(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m^\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.*\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m$\u001b[39m\u001b[38;5;124m\"\u001b[39m,fpath):\n\u001b[1;32m    726\u001b[0m         warn(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFor Windows, use double quotes to wrap a filename: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124mun \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmypath\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mmyfile.py\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 727\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    728\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    729\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m fpath \u001b[38;5;129;01min\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mmeta_path:\n",
      "\u001b[0;31mException\u001b[0m: File `'update_yaml.py'` not found."
     ]
    }
   ],
   "source": [
    "%run update_yaml.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "9bfab691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ØªÙ… ØªØ­Ø¯ÙŠØ« `environment.yaml` Ø¨Ù†Ø¬Ø§Ø­!\n",
      "ğŸ“‚ ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ `comparisons/comparison_2.txt` Ù„Ø¹Ø±Ø¶ Ø§Ù„ÙØ±ÙˆÙ‚Ø§Øª Ø¨ÙŠÙ† Ø§Ù„Ù…Ù„ÙØ§Øª!\n",
      "â³ Ø§Ù†ØªÙ‡Ù‰ Ø§Ù„ØªÙ†ÙÙŠØ° Ø®Ù„Ø§Ù„ 13.05 Ø«Ø§Ù†ÙŠØ©\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "import subprocess\n",
    "import shutil\n",
    "import os\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "req_file = \"requirements.txt\"\n",
    "env_file = \"environment.yaml\"\n",
    "comp_dir = \"comparisons/\"\n",
    "\n",
    "# Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù…Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù† micromamba Ù…Ø«Ø¨ØªÙ‹Ø§\n",
    "micromamba_available = shutil.which(\"micromamba\") is not None\n",
    "conda_command = \"micromamba\" if micromamba_available else \"conda\"\n",
    "\n",
    "# Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¬Ù„Ø¯ Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø§Øª Ø¥Ù† Ù„Ù… ÙŠÙƒÙ† Ù…ÙˆØ¬ÙˆØ¯Ù‹Ø§\n",
    "if not os.path.exists(comp_dir):\n",
    "    os.makedirs(comp_dir)\n",
    "\n",
    "# ØªØ­Ø¯ÙŠØ¯ Ø±Ù‚Ù… Ù…Ù„Ù Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ø¬Ø¯ÙŠØ¯\n",
    "existing_files = [f for f in os.listdir(comp_dir) if f.startswith(\"comparison_\") and f.endswith(\".txt\")]\n",
    "file_numbers = [int(f.split(\"_\")[1].split(\".\")[0]) for f in existing_files if f.split(\"_\")[1].split(\".\")[0].isdigit()]\n",
    "next_file_number = max(file_numbers, default=0) + 1\n",
    "comp_file = f\"{comp_dir}comparison_{next_file_number}.txt\"\n",
    "\n",
    "def is_available_in_conda(package_name):\n",
    "    try:\n",
    "        result = subprocess.run([conda_command, \"search\", package_name, \"-c\", \"conda-forge\"], \n",
    "                                capture_output=True, text=True, timeout=10)\n",
    "        return package_name in result.stdout\n",
    "    except Exception as e:\n",
    "        return False\n",
    "\n",
    "try:\n",
    "    with open(req_file, \"r\") as f:\n",
    "        requirements = [line.strip() for line in f.readlines() if line.strip()]\n",
    "\n",
    "    conda_dependencies = []\n",
    "    pip_dependencies = []\n",
    "    python_version = None\n",
    "\n",
    "    for line in requirements:\n",
    "        parts = line.split()\n",
    "        package = parts[0]\n",
    "        version = f\"=={parts[1]}\" if len(parts) > 1 and \"==\" in parts[1] else \"\"\n",
    "        method = parts[-1] if len(parts) > 1 and parts[-1] in [\"conda\", \"pip\"] else None\n",
    "\n",
    "        if package.startswith(\"python\"):\n",
    "            python_version = package + version\n",
    "            continue\n",
    "        \n",
    "        if method == \"conda\" or (not method and is_available_in_conda(package)):\n",
    "            conda_dependencies.append(f\"{package}{version}\")\n",
    "        else:\n",
    "            pip_dependencies.append(f\"{package}{version}\")\n",
    "\n",
    "    yaml_data = {\n",
    "        \"name\": \"project_env\",\n",
    "        \"channels\": [\"conda-forge\"],\n",
    "        \"dependencies\": ([\"python\" + python_version] if python_version else []) + conda_dependencies + [\"pip\", {\"pip\": pip_dependencies}] if pip_dependencies else [\"pip\"]\n",
    "    }\n",
    "\n",
    "    with open(env_file, \"w\") as f:\n",
    "        yaml.dump(yaml_data, f, default_flow_style=False)\n",
    "\n",
    "    with open(comp_file, \"w\") as comp_f:\n",
    "        comp_f.write(f\"ğŸ”¹ Ù…Ù‚Ø§Ø±Ù†Ø© ØªØ´ØºÙŠÙ„ Ø±Ù‚Ù… {next_file_number}\\n\")\n",
    "        comp_f.write(f\"â³ ÙˆÙ‚Øª Ø§Ù„ØªÙ†ÙÙŠØ°: {time.time() - start_time:.2f} Ø«Ø§Ù†ÙŠØ©\\n\")\n",
    "        comp_f.write(f\"ğŸ› ï¸ Ø¥ØµØ¯Ø§Ø± Conda Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…: {subprocess.run(['conda', '--version'], capture_output=True, text=True).stdout.strip()}\\n\")\n",
    "        if micromamba_available:\n",
    "            comp_f.write(f\"ğŸ› ï¸ Ø¥ØµØ¯Ø§Ø± Micromamba Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…: {subprocess.run(['micromamba', '--version'], capture_output=True, text=True).stdout.strip()}\\n\")\n",
    "        comp_f.write(\"\\nğŸ“œ Ù…Ø­ØªÙˆÙ‰ requirements.txt:\\n\")\n",
    "        comp_f.write(\"\\n\".join(requirements) + \"\\n\\n\")\n",
    "        comp_f.write(\"ğŸ“œ Ù…Ø­ØªÙˆÙ‰ environment.yaml:\\n\")\n",
    "        comp_f.write(\"\\n\".join(conda_dependencies + pip_dependencies) + \"\\n\")\n",
    "\n",
    "    print(f\"âœ… ØªÙ… ØªØ­Ø¯ÙŠØ« `environment.yaml` Ø¨Ù†Ø¬Ø§Ø­!\")\n",
    "    print(f\"ğŸ“‚ ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ `{comp_file}` Ù„Ø¹Ø±Ø¶ Ø§Ù„ÙØ±ÙˆÙ‚Ø§Øª Ø¨ÙŠÙ† Ø§Ù„Ù…Ù„ÙØ§Øª!\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"âŒ `requirements.txt` ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ØŒ ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù…Ø³Ø§Ø±.\")\n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ ØªØ­Ø¯ÙŠØ« environment.yaml: {e}\")\n",
    "\n",
    "print(f\"â³ Ø§Ù†ØªÙ‡Ù‰ Ø§Ù„ØªÙ†ÙÙŠØ° Ø®Ù„Ø§Ù„ {time.time() - start_time:.2f} Ø«Ø§Ù†ÙŠØ©\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4c6e8331",
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "File `'update_yaml.py'` not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/IPython/core/magics/execution.py:716\u001b[0m, in \u001b[0;36mExecutionMagics.run\u001b[0;34m(self, parameter_s, runner, file_finder)\u001b[0m\n\u001b[1;32m    715\u001b[0m     fpath \u001b[38;5;241m=\u001b[39m arg_lst[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 716\u001b[0m     filename \u001b[38;5;241m=\u001b[39m \u001b[43mfile_finder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    717\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/IPython/utils/path.py:90\u001b[0m, in \u001b[0;36mget_py_filename\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m py_name\n\u001b[0;32m---> 90\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile `\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m` not found.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m name)\n",
      "\u001b[0;31mOSError\u001b[0m: File `'update_yaml.py'` not found.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[82], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_line_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrun\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mupdate_yaml.py\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/IPython/core/interactiveshell.py:2456\u001b[0m, in \u001b[0;36mInteractiveShell.run_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2454\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocal_ns\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_local_scope(stack_depth)\n\u001b[1;32m   2455\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[0;32m-> 2456\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2458\u001b[0m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[1;32m   2459\u001b[0m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[1;32m   2460\u001b[0m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[1;32m   2461\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic\u001b[38;5;241m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/IPython/core/magics/execution.py:727\u001b[0m, in \u001b[0;36mExecutionMagics.run\u001b[0;34m(self, parameter_s, runner, file_finder)\u001b[0m\n\u001b[1;32m    725\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnt\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m re\u001b[38;5;241m.\u001b[39mmatch(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m^\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.*\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m$\u001b[39m\u001b[38;5;124m\"\u001b[39m,fpath):\n\u001b[1;32m    726\u001b[0m         warn(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFor Windows, use double quotes to wrap a filename: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124mun \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmypath\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mmyfile.py\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 727\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    728\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    729\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m fpath \u001b[38;5;129;01min\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mmeta_path:\n",
      "\u001b[0;31mException\u001b[0m: File `'update_yaml.py'` not found."
     ]
    }
   ],
   "source": [
    "%run update_yaml.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "70bfac70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.git', '.ipynb_checkpoints', 'AI_Model_Training.ipynb', 'Automation_Scripts.ipynb', 'comparisons', 'Core_System_Framework', 'Data_Integration.ipynb', 'Data_Processing_Engine', 'dependency_log.txt', 'Deployment_Strategies', 'Dev_Structure_Manager.ipynb', 'environment.yaml', 'Flower_Classification_Foundation_V1', 'Market_Expansion_Strategies.ipynb', 'Project Update Monitor.ipynb', 'Project_Growth_Framework', 'requirements.txt', 'Sustainability_Metrics.ipynb', 'Untitled.ipynb', 'User_Behavior_Insights.ipynb', 'User_Interaction_Flow']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.listdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9d9f8093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['comparisons', 'environment.yaml', 'README.md', 'requirements.txt', 'update_yaml.py', 'watch_requirements.py']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.listdir(\"Flower_Classification_Foundation_V1\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7a35da45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† `tensorflow-datasets` Ø§Ø³ØªØºØ±Ù‚ ÙˆÙ‚ØªÙ‹Ø§ Ø·ÙˆÙŠÙ„Ø§Ù‹ØŒ Ø³ÙŠØªÙ… ØªØ«Ø¨ÙŠØªÙ‡ Ø¹Ø¨Ø± pip.\n",
      "Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† `tensorflow-hub` Ø§Ø³ØªØºØ±Ù‚ ÙˆÙ‚ØªÙ‹Ø§ Ø·ÙˆÙŠÙ„Ø§Ù‹ØŒ Ø³ÙŠØªÙ… ØªØ«Ø¨ÙŠØªÙ‡ Ø¹Ø¨Ø± pip.\n",
      "Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† `scipy` Ø§Ø³ØªØºØ±Ù‚ ÙˆÙ‚ØªÙ‹Ø§ Ø·ÙˆÙŠÙ„Ø§Ù‹ØŒ Ø³ÙŠØªÙ… ØªØ«Ø¨ÙŠØªÙ‡ Ø¹Ø¨Ø± pip.\n",
      "Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† `tf-keras` Ø§Ø³ØªØºØ±Ù‚ ÙˆÙ‚ØªÙ‹Ø§ Ø·ÙˆÙŠÙ„Ø§Ù‹ØŒ Ø³ÙŠØªÙ… ØªØ«Ø¨ÙŠØªÙ‡ Ø¹Ø¨Ø± pip.\n",
      "Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† `edx-dl` Ø§Ø³ØªØºØ±Ù‚ ÙˆÙ‚ØªÙ‹Ø§ Ø·ÙˆÙŠÙ„Ø§Ù‹ØŒ Ø³ÙŠØªÙ… ØªØ«Ø¨ÙŠØªÙ‡ Ø¹Ø¨Ø± pip.\n",
      "ØªÙ… ØªØ­Ø¯ÙŠØ« environment.yaml Ø¨Ù†Ø¬Ø§Ø­!\n",
      "ØªÙ… Ø­ÙØ¸ Ø³Ø¬Ù„ Ø§Ù„ØªØ­Ø°ÙŠØ±Ø§Øª ÙÙŠ /mnt/c/Users/ali/Desktop/Innovation_Hub_New/Full_Stack_Framework/Flower_Classification_Foundation_V1/dependency_log.txt!\n",
      "â³ Ø§Ù†ØªÙ‡Ù‰ Ø§Ù„ØªÙ†ÙÙŠØ° Ø®Ù„Ø§Ù„ 77.75 Ø«Ø§Ù†ÙŠØ©\n"
     ]
    }
   ],
   "source": [
    "%run Flower_Classification_Foundation_V1/update_yaml.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "3eb37b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_available_in_conda(package_name):\n",
    "    try:\n",
    "        result = subprocess.run([conda_command, \"search\", package_name, \"-c\", \"conda-forge\"], \n",
    "                                capture_output=True, text=True, timeout=240)  # 4 Ø¯Ù‚Ø§Ø¦Ù‚ Ù…Ù‡Ù„Ø© Ø§Ù„Ø¨Ø­Ø«\n",
    "        if not result.stdout:\n",
    "            print(f\"âš ï¸ {package_name} ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ conda-forge.\")\n",
    "            return False\n",
    "        return package_name in result.stdout\n",
    "    except subprocess.TimeoutExpired:\n",
    "        print(f\"âŒ Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† {package_name} Ø§Ø³ØªØºØ±Ù‚ 4 Ø¯Ù‚Ø§Ø¦Ù‚ Ø¯ÙˆÙ† Ù†ØªÙŠØ¬Ø©. Ø³ÙŠØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù… pip Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† Ø°Ù„Ùƒ.\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e8e82e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ØªØ­Ø¯ÙŠØ« Ø¯Ø§Ù„Ø© Ø§Ù„Ø¨Ø­Ø« Ø¨Ø­ÙŠØ« ÙŠÙƒÙˆÙ† timeout = 240 Ø«Ø§Ù†ÙŠØ© (4 Ø¯Ù‚Ø§Ø¦Ù‚)\n",
    "def is_available_in_conda(package_name):\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            [conda_command, \"search\", package_name, \"-c\", \"conda-forge\"], \n",
    "            capture_output=True, text=True, timeout=240  # 4 Ø¯Ù‚Ø§Ø¦Ù‚ Ù…Ù‡Ù„Ø© Ø§Ù„Ø¨Ø­Ø«\n",
    "        )\n",
    "        if not result.stdout:\n",
    "            print(f\"âš ï¸ {package_name} ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ conda-forge.\")\n",
    "            return False\n",
    "        return package_name in result.stdout\n",
    "    except subprocess.TimeoutExpired:\n",
    "        print(f\"âŒ Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† {package_name} Ø§Ø³ØªØºØ±Ù‚ 4 Ø¯Ù‚Ø§Ø¦Ù‚ Ø¯ÙˆÙ† Ù†ØªÙŠØ¬Ø©. Ø³ÙŠØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù… pip Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† Ø°Ù„Ùƒ.\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c3a8f578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ØªÙ… ØªØ­Ø¯ÙŠØ« `environment.yaml` Ø¨Ù†Ø¬Ø§Ø­!\n",
      "ğŸ“‚ ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ `comparisons/comparison_3.txt` Ù„Ø¹Ø±Ø¶ Ø§Ù„ÙØ±ÙˆÙ‚Ø§Øª Ø¨ÙŠÙ† Ø§Ù„Ù…Ù„ÙØ§Øª!\n",
      "â³ Ø§Ù†ØªÙ‡Ù‰ Ø§Ù„ØªÙ†ÙÙŠØ° Ø®Ù„Ø§Ù„ 42.92 Ø«Ø§Ù†ÙŠØ©\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "import subprocess\n",
    "import shutil\n",
    "import os\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "req_file = \"requirements.txt\"\n",
    "env_file = \"environment.yaml\"\n",
    "comp_dir = \"comparisons/\"\n",
    "\n",
    "# Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù…Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù† micromamba Ù…Ø«Ø¨ØªÙ‹Ø§\n",
    "micromamba_available = shutil.which(\"micromamba\") is not None\n",
    "conda_command = \"micromamba\" if micromamba_available else \"conda\"\n",
    "\n",
    "# Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¬Ù„Ø¯ Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø§Øª Ø¥Ù† Ù„Ù… ÙŠÙƒÙ† Ù…ÙˆØ¬ÙˆØ¯Ù‹Ø§\n",
    "if not os.path.exists(comp_dir):\n",
    "    os.makedirs(comp_dir)\n",
    "\n",
    "# ØªØ­Ø¯ÙŠØ¯ Ø±Ù‚Ù… Ù…Ù„Ù Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ø¬Ø¯ÙŠØ¯\n",
    "existing_files = [f for f in os.listdir(comp_dir) if f.startswith(\"comparison_\") and f.endswith(\".txt\")]\n",
    "file_numbers = [int(f.split(\"_\")[1].split(\".\")[0]) for f in existing_files if f.split(\"_\")[1].split(\".\")[0].isdigit()]\n",
    "next_file_number = max(file_numbers, default=0) + 1\n",
    "comp_file = f\"{comp_dir}comparison_{next_file_number}.txt\"\n",
    "\n",
    "# Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ù…ÙƒØªØ¨Ø© Ø¯Ø§Ø®Ù„ conda-forge\n",
    "def is_available_in_conda(package_name):\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            [conda_command, \"search\", package_name, \"-c\", \"conda-forge\"], \n",
    "            capture_output=True, text=True, timeout=240  # 4 Ø¯Ù‚Ø§Ø¦Ù‚ Ù…Ù‡Ù„Ø© Ø§Ù„Ø¨Ø­Ø«\n",
    "        )\n",
    "        if not result.stdout:\n",
    "            print(f\"âš ï¸ {package_name} ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ conda-forge.\")\n",
    "            return False\n",
    "        return package_name in result.stdout\n",
    "    except subprocess.TimeoutExpired:\n",
    "        print(f\"âŒ Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† {package_name} Ø§Ø³ØªØºØ±Ù‚ 4 Ø¯Ù‚Ø§Ø¦Ù‚ Ø¯ÙˆÙ† Ù†ØªÙŠØ¬Ø©. Ø³ÙŠØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù… pip Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† Ø°Ù„Ùƒ.\")\n",
    "        return False\n",
    "\n",
    "try:\n",
    "    with open(req_file, \"r\") as f:\n",
    "        requirements = [line.strip() for line in f.readlines() if line.strip()]\n",
    "\n",
    "    conda_dependencies = []\n",
    "    pip_dependencies = []\n",
    "    python_version = None\n",
    "\n",
    "    for line in requirements:\n",
    "        parts = line.split()\n",
    "        package = parts[0]\n",
    "        version = f\"=={parts[1]}\" if len(parts) > 1 and \"==\" in parts[1] else \"\"\n",
    "        method = parts[-1] if len(parts) > 1 and parts[-1] in [\"conda\", \"pip\"] else None\n",
    "\n",
    "        if package.startswith(\"python\"):\n",
    "            python_version = package + version\n",
    "            continue\n",
    "        \n",
    "        if method == \"conda\" or (not method and is_available_in_conda(package)):\n",
    "            conda_dependencies.append(f\"{package}{version}\")\n",
    "        else:\n",
    "            pip_dependencies.append(f\"{package}{version}\")\n",
    "\n",
    "    yaml_data = {\n",
    "        \"name\": \"project_env\",\n",
    "        \"channels\": [\"conda-forge\"],\n",
    "        \"dependencies\": ([\"python\" + python_version] if python_version else []) + conda_dependencies + [\"pip\", {\"pip\": pip_dependencies}] if pip_dependencies else [\"pip\"]\n",
    "    }\n",
    "\n",
    "    with open(env_file, \"w\") as f:\n",
    "        yaml.dump(yaml_data, f, default_flow_style=False)\n",
    "\n",
    "    with open(comp_file, \"w\") as comp_f:\n",
    "        comp_f.write(f\"ğŸ”¹ Ù…Ù‚Ø§Ø±Ù†Ø© ØªØ´ØºÙŠÙ„ Ø±Ù‚Ù… {next_file_number}\\n\")\n",
    "        comp_f.write(f\"â³ ÙˆÙ‚Øª Ø§Ù„ØªÙ†ÙÙŠØ°: {time.time() - start_time:.2f} Ø«Ø§Ù†ÙŠØ©\\n\")\n",
    "        comp_f.write(f\"ğŸ› ï¸ Ø¥ØµØ¯Ø§Ø± Conda Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…: {subprocess.run(['conda', '--version'], capture_output=True, text=True).stdout.strip()}\\n\")\n",
    "        if micromamba_available:\n",
    "            comp_f.write(f\"ğŸ› ï¸ Ø¥ØµØ¯Ø§Ø± Micromamba Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…: {subprocess.run(['micromamba', '--version'], capture_output=True, text=True).stdout.strip()}\\n\")\n",
    "        comp_f.write(\"\\nğŸ“œ Ù…Ø­ØªÙˆÙ‰ requirements.txt:\\n\")\n",
    "        comp_f.write(\"\\n\".join(requirements) + \"\\n\\n\")\n",
    "        comp_f.write(\"ğŸ“œ Ù…Ø­ØªÙˆÙ‰ environment.yaml:\\n\")\n",
    "        comp_f.write(\"\\n\".join(conda_dependencies + pip_dependencies) + \"\\n\")\n",
    "\n",
    "    print(f\"âœ… ØªÙ… ØªØ­Ø¯ÙŠØ« `environment.yaml` Ø¨Ù†Ø¬Ø§Ø­!\")\n",
    "    print(f\"ğŸ“‚ ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ `{comp_file}` Ù„Ø¹Ø±Ø¶ Ø§Ù„ÙØ±ÙˆÙ‚Ø§Øª Ø¨ÙŠÙ† Ø§Ù„Ù…Ù„ÙØ§Øª!\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"âŒ `requirements.txt` ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ØŒ ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù…Ø³Ø§Ø±.\")\n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ ØªØ­Ø¯ÙŠØ« environment.yaml: {e}\")\n",
    "\n",
    "print(f\"â³ Ø§Ù†ØªÙ‡Ù‰ Ø§Ù„ØªÙ†ÙÙŠØ° Ø®Ù„Ø§Ù„ {time.time() - start_time:.2f} Ø«Ø§Ù†ÙŠØ©\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "844ee6b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† `tensorflow-datasets` Ø§Ø³ØªØºØ±Ù‚ ÙˆÙ‚ØªÙ‹Ø§ Ø·ÙˆÙŠÙ„Ø§Ù‹ØŒ Ø³ÙŠØªÙ… ØªØ«Ø¨ÙŠØªÙ‡ Ø¹Ø¨Ø± pip.\n",
      "Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† `tensorflow-hub` Ø§Ø³ØªØºØ±Ù‚ ÙˆÙ‚ØªÙ‹Ø§ Ø·ÙˆÙŠÙ„Ø§Ù‹ØŒ Ø³ÙŠØªÙ… ØªØ«Ø¨ÙŠØªÙ‡ Ø¹Ø¨Ø± pip.\n",
      "Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† `scipy` Ø§Ø³ØªØºØ±Ù‚ ÙˆÙ‚ØªÙ‹Ø§ Ø·ÙˆÙŠÙ„Ø§Ù‹ØŒ Ø³ÙŠØªÙ… ØªØ«Ø¨ÙŠØªÙ‡ Ø¹Ø¨Ø± pip.\n",
      "Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† `tf-keras` Ø§Ø³ØªØºØ±Ù‚ ÙˆÙ‚ØªÙ‹Ø§ Ø·ÙˆÙŠÙ„Ø§Ù‹ØŒ Ø³ÙŠØªÙ… ØªØ«Ø¨ÙŠØªÙ‡ Ø¹Ø¨Ø± pip.\n",
      "Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† `edx-dl` Ø§Ø³ØªØºØ±Ù‚ ÙˆÙ‚ØªÙ‹Ø§ Ø·ÙˆÙŠÙ„Ø§Ù‹ØŒ Ø³ÙŠØªÙ… ØªØ«Ø¨ÙŠØªÙ‡ Ø¹Ø¨Ø± pip.\n",
      "ØªÙ… ØªØ­Ø¯ÙŠØ« environment.yaml Ø¨Ù†Ø¬Ø§Ø­!\n",
      "ØªÙ… Ø­ÙØ¸ Ø³Ø¬Ù„ Ø§Ù„ØªØ­Ø°ÙŠØ±Ø§Øª ÙÙŠ /mnt/c/Users/ali/Desktop/Innovation_Hub_New/Full_Stack_Framework/Flower_Classification_Foundation_V1/dependency_log.txt!\n",
      "â³ Ø§Ù†ØªÙ‡Ù‰ Ø§Ù„ØªÙ†ÙÙŠØ° Ø®Ù„Ø§Ù„ 81.72 Ø«Ø§Ù†ÙŠØ©\n"
     ]
    }
   ],
   "source": [
    "%run Flower_Classification_Foundation_V1/update_yaml.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "abdcfd00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ØªÙ… ØªØ­Ø¯ÙŠØ« `environment.yaml` Ø¨Ù†Ø¬Ø§Ø­!\n",
      "ğŸ“‚ ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ `/mnt/c/Users/ali/Desktop/Innovation_Hub_New/Full_Stack_Framework/Flower_Classification_Foundation_V1/comparisons/comparison_2.txt` Ù„Ø¹Ø±Ø¶ Ø§Ù„ÙØ±ÙˆÙ‚Ø§Øª Ø¨ÙŠÙ† Ø§Ù„Ù…Ù„ÙØ§Øª!\n",
      "â³ Ø§Ù†ØªÙ‡Ù‰ Ø§Ù„ØªÙ†ÙÙŠØ° Ø®Ù„Ø§Ù„ 23.22 Ø«Ø§Ù†ÙŠØ©\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "import subprocess\n",
    "import shutil\n",
    "import os\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Ø¶Ø¨Ø· Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª\n",
    "base_path = \"/mnt/c/Users/ali/Desktop/Innovation_Hub_New/Full_Stack_Framework/Flower_Classification_Foundation_V1/\"\n",
    "req_file = os.path.join(base_path, \"requirements.txt\")\n",
    "env_file = os.path.join(base_path, \"environment.yaml\")\n",
    "comp_dir = os.path.join(base_path, \"comparisons\")\n",
    "\n",
    "# Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù…Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù† micromamba Ù…Ø«Ø¨ØªÙ‹Ø§\n",
    "micromamba_available = shutil.which(\"micromamba\") is not None\n",
    "conda_command = \"micromamba\" if micromamba_available else \"conda\"\n",
    "\n",
    "# Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¬Ù„Ø¯ Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø§Øª Ø¥Ù† Ù„Ù… ÙŠÙƒÙ† Ù…ÙˆØ¬ÙˆØ¯Ù‹Ø§\n",
    "if not os.path.exists(comp_dir):\n",
    "    os.makedirs(comp_dir)\n",
    "\n",
    "# ØªØ­Ø¯ÙŠØ¯ Ø±Ù‚Ù… Ù…Ù„Ù Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ø¬Ø¯ÙŠØ¯\n",
    "existing_files = [f for f in os.listdir(comp_dir) if f.startswith(\"comparison_\") and f.endswith(\".txt\")]\n",
    "file_numbers = [int(f.split(\"_\")[1].split(\".\")[0]) for f in existing_files if f.split(\"_\")[1].split(\".\")[0].isdigit()]\n",
    "next_file_number = max(file_numbers, default=0) + 1\n",
    "comp_file = os.path.join(comp_dir, f\"comparison_{next_file_number}.txt\")\n",
    "\n",
    "# Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ù…ÙƒØªØ¨Ø© Ø¯Ø§Ø®Ù„ conda-forge\n",
    "def is_available_in_conda(package_name):\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            [conda_command, \"search\", package_name, \"-c\", \"conda-forge\"], \n",
    "            capture_output=True, text=True, timeout=240  # 4 Ø¯Ù‚Ø§Ø¦Ù‚ Ù…Ù‡Ù„Ø© Ø§Ù„Ø¨Ø­Ø« Ù„ÙƒÙ„ Ù…ÙƒØªØ¨Ø©\n",
    "        )\n",
    "        if not result.stdout:\n",
    "            print(f\"âš ï¸ {package_name} ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ conda-forge.\")\n",
    "            return False\n",
    "        return package_name in result.stdout\n",
    "    except subprocess.TimeoutExpired:\n",
    "        print(f\"âŒ Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† {package_name} Ø§Ø³ØªØºØ±Ù‚ 4 Ø¯Ù‚Ø§Ø¦Ù‚ Ø¯ÙˆÙ† Ù†ØªÙŠØ¬Ø©. Ø³ÙŠØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù… pip Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† Ø°Ù„Ùƒ.\")\n",
    "        return False\n",
    "\n",
    "try:\n",
    "    with open(req_file, \"r\") as f:\n",
    "        requirements = [line.strip() for line in f.readlines() if line.strip()]\n",
    "\n",
    "    conda_dependencies = []\n",
    "    pip_dependencies = []\n",
    "    python_version = None\n",
    "\n",
    "    for line in requirements:\n",
    "        parts = line.split()\n",
    "        package = parts[0]\n",
    "        version = f\"=={parts[1]}\" if len(parts) > 1 and \"==\" in parts[1] else \"\"\n",
    "        method = parts[-1] if len(parts) > 1 and parts[-1] in [\"conda\", \"pip\"] else None\n",
    "\n",
    "        if package.startswith(\"python\"):\n",
    "            python_version = package + version\n",
    "            continue\n",
    "        \n",
    "        if method == \"conda\" or (not method and is_available_in_conda(package)):\n",
    "            conda_dependencies.append(f\"{package}{version}\")\n",
    "        else:\n",
    "            pip_dependencies.append(f\"{package}{version}\")\n",
    "\n",
    "    yaml_data = {\n",
    "        \"name\": \"project_env\",\n",
    "        \"channels\": [\"conda-forge\"],\n",
    "        \"dependencies\": ([\"python\" + python_version] if python_version else []) + conda_dependencies + [\"pip\", {\"pip\": pip_dependencies}] if pip_dependencies else [\"pip\"]\n",
    "    }\n",
    "\n",
    "    with open(env_file, \"w\") as f:\n",
    "        yaml.dump(yaml_data, f, default_flow_style=False)\n",
    "\n",
    "    with open(comp_file, \"w\") as comp_f:\n",
    "        comp_f.write(f\"ğŸ”¹ Ù…Ù‚Ø§Ø±Ù†Ø© ØªØ´ØºÙŠÙ„ Ø±Ù‚Ù… {next_file_number}\\n\")\n",
    "        comp_f.write(f\"â³ ÙˆÙ‚Øª Ø§Ù„ØªÙ†ÙÙŠØ°: {time.time() - start_time:.2f} Ø«Ø§Ù†ÙŠØ©\\n\")\n",
    "        comp_f.write(f\"ğŸ› ï¸ Ø¥ØµØ¯Ø§Ø± Conda Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…: {subprocess.run(['conda', '--version'], capture_output=True, text=True).stdout.strip()}\\n\")\n",
    "        if micromamba_available:\n",
    "            comp_f.write(f\"ğŸ› ï¸ Ø¥ØµØ¯Ø§Ø± Micromamba Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…: {subprocess.run(['micromamba', '--version'], capture_output=True, text=True).stdout.strip()}\\n\")\n",
    "        comp_f.write(\"\\nğŸ“œ Ù…Ø­ØªÙˆÙ‰ requirements.txt:\\n\")\n",
    "        comp_f.write(\"\\n\".join(requirements) + \"\\n\\n\")\n",
    "        comp_f.write(\"ğŸ“œ Ù…Ø­ØªÙˆÙ‰ environment.yaml:\\n\")\n",
    "        comp_f.write(\"\\n\".join(conda_dependencies + pip_dependencies) + \"\\n\")\n",
    "\n",
    "    print(f\"âœ… ØªÙ… ØªØ­Ø¯ÙŠØ« `environment.yaml` Ø¨Ù†Ø¬Ø§Ø­!\")\n",
    "    print(f\"ğŸ“‚ ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ `{comp_file}` Ù„Ø¹Ø±Ø¶ Ø§Ù„ÙØ±ÙˆÙ‚Ø§Øª Ø¨ÙŠÙ† Ø§Ù„Ù…Ù„ÙØ§Øª!\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"âŒ `{req_file}` ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ØŒ ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù…Ø³Ø§Ø±.\")\n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ ØªØ­Ø¯ÙŠØ« environment.yaml: {e}\")\n",
    "\n",
    "print(f\"â³ Ø§Ù†ØªÙ‡Ù‰ Ø§Ù„ØªÙ†ÙÙŠØ° Ø®Ù„Ø§Ù„ {time.time() - start_time:.2f} Ø«Ø§Ù†ÙŠØ©\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "8d5bd9ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ ØªØ­Ø¯ÙŠØ« environment.yaml: sequence item 4: expected str instance, dict found\n",
      "â³ Ø§Ù†ØªÙ‡Ù‰ Ø§Ù„ØªÙ†ÙÙŠØ° Ø®Ù„Ø§Ù„ 63.49 Ø«Ø§Ù†ÙŠØ©\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "import subprocess\n",
    "import shutil\n",
    "import os\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Ø¶Ø¨Ø· Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª Ù„Ø¶Ù…Ø§Ù† Ø§Ù„ØªÙˆØ§ÙÙ‚ Ù…Ø¹ WSL Ùˆ Windows\n",
    "base_path = \"/mnt/c/Users/ali/Desktop/Innovation_Hub_New/Full_Stack_Framework/Flower_Classification_Foundation_V1/\"\n",
    "req_file = os.path.join(base_path, \"requirements.txt\")\n",
    "env_file = os.path.join(base_path, \"environment.yaml\")\n",
    "comp_dir = os.path.join(base_path, \"comparisons\")\n",
    "\n",
    "# Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù…Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù† micromamba Ù…Ø«Ø¨ØªÙ‹Ø§\n",
    "micromamba_available = shutil.which(\"micromamba\") is not None\n",
    "conda_command = \"micromamba\" if micromamba_available else \"conda\"\n",
    "\n",
    "# Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¬Ù„Ø¯ Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø§Øª Ø¥Ù† Ù„Ù… ÙŠÙƒÙ† Ù…ÙˆØ¬ÙˆØ¯Ù‹Ø§\n",
    "if not os.path.exists(comp_dir):\n",
    "    os.makedirs(comp_dir)\n",
    "\n",
    "# ØªØ­Ø¯ÙŠØ¯ Ø±Ù‚Ù… Ù…Ù„Ù Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ø¬Ø¯ÙŠØ¯ Ø¨Ø¯Ù‚Ø©\n",
    "existing_files = [f for f in os.listdir(comp_dir) if f.startswith(\"comparison_\") and f.endswith(\".txt\")]\n",
    "file_numbers = sorted([int(f.split(\"_\")[1].split(\".\")[0]) for f in existing_files if f.split(\"_\")[1].split(\".\")[0].isdigit()])\n",
    "next_file_number = file_numbers[-1] + 1 if file_numbers else 1  # ØªØ£ÙƒØ¯ Ù…Ù† Ø§Ù„ØªØ³Ù„Ø³Ù„ Ø§Ù„ØµØ­ÙŠØ­\n",
    "comp_file = os.path.join(comp_dir, f\"comparison_{next_file_number}.txt\")\n",
    "\n",
    "# Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ù…ÙƒØªØ¨Ø© Ø¯Ø§Ø®Ù„ conda-forge\n",
    "def is_available_in_conda(package_name):\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            [conda_command, \"search\", package_name, \"-c\", \"conda-forge\"], \n",
    "            capture_output=True, text=True, timeout=240  # 4 Ø¯Ù‚Ø§Ø¦Ù‚ Ù…Ù‡Ù„Ø© Ø§Ù„Ø¨Ø­Ø« Ù„ÙƒÙ„ Ù…ÙƒØªØ¨Ø©\n",
    "        )\n",
    "        if not result.stdout:\n",
    "            print(f\"âš ï¸ {package_name} ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ conda-forge.\")\n",
    "            return False\n",
    "        return package_name in result.stdout\n",
    "    except subprocess.TimeoutExpired:\n",
    "        print(f\"âŒ Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† {package_name} Ø§Ø³ØªØºØ±Ù‚ 4 Ø¯Ù‚Ø§Ø¦Ù‚ Ø¯ÙˆÙ† Ù†ØªÙŠØ¬Ø©. Ø³ÙŠØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù… pip Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† Ø°Ù„Ùƒ.\")\n",
    "        return False\n",
    "\n",
    "try:\n",
    "    with open(req_file, \"r\") as f:\n",
    "        requirements = [line.strip() for line in f.readlines() if line.strip()]\n",
    "\n",
    "    conda_dependencies = []\n",
    "    pip_dependencies = []\n",
    "    python_version = None\n",
    "\n",
    "    for line in requirements:\n",
    "        parts = line.split()\n",
    "        package = parts[0]\n",
    "        version = f\"=={parts[1]}\" if len(parts) > 1 and \"==\" in parts[1] else \"\"\n",
    "        method = parts[-1] if len(parts) > 1 and parts[-1] in [\"conda\", \"pip\"] else None\n",
    "\n",
    "        if package.startswith(\"python\"):\n",
    "            python_version = package + version\n",
    "            continue\n",
    "        \n",
    "        if method == \"conda\" or (not method and is_available_in_conda(package)):\n",
    "            conda_dependencies.append(f\"{package}{version}\")\n",
    "        else:\n",
    "            pip_dependencies.append(f\"{package}{version}\")\n",
    "\n",
    "    yaml_data = {\n",
    "        \"name\": \"project_env\",\n",
    "        \"channels\": [\"conda-forge\"],\n",
    "        \"dependencies\": [\"python\" + python_version] if python_version else [\"python\"]\n",
    "    }\n",
    "\n",
    "    if conda_dependencies:\n",
    "        yaml_data[\"dependencies\"].extend(conda_dependencies)\n",
    "\n",
    "    if pip_dependencies:\n",
    "        yaml_data[\"dependencies\"].append(\"pip\")\n",
    "        yaml_data[\"dependencies\"].append({\"pip\": pip_dependencies})\n",
    "\n",
    "    # Ø­ÙØ¸ `environment.yaml` Ø¨Ø¹Ø¯ Ø§Ù„ØªØµØ­ÙŠØ­\n",
    "    with open(env_file, \"w\") as f:\n",
    "        yaml.dump(yaml_data, f, default_flow_style=False)\n",
    "\n",
    "    # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ù Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ø¬Ø¯ÙŠØ¯\n",
    "    with open(comp_file, \"w\") as comp_f:\n",
    "        comp_f.write(f\"ğŸ”¹ Ù…Ù‚Ø§Ø±Ù†Ø© ØªØ´ØºÙŠÙ„ Ø±Ù‚Ù… {next_file_number}\\n\")\n",
    "        comp_f.write(f\"â³ ÙˆÙ‚Øª Ø§Ù„ØªÙ†ÙÙŠØ°: {time.time() - start_time:.2f} Ø«Ø§Ù†ÙŠØ©\\n\")\n",
    "        comp_f.write(f\"ğŸ› ï¸ Ø¥ØµØ¯Ø§Ø± Conda Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…: {subprocess.run(['conda', '--version'], capture_output=True, text=True).stdout.strip()}\\n\")\n",
    "        if micromamba_available:\n",
    "            comp_f.write(f\"ğŸ› ï¸ Ø¥ØµØ¯Ø§Ø± Micromamba Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…: {subprocess.run(['micromamba', '--version'], capture_output=True, text=True).stdout.strip()}\\n\")\n",
    "        comp_f.write(\"\\nğŸ“œ Ù…Ø­ØªÙˆÙ‰ requirements.txt:\\n\")\n",
    "        comp_f.write(\"\\n\".join(requirements) + \"\\n\\n\")\n",
    "        comp_f.write(\"ğŸ“œ Ù…Ø­ØªÙˆÙ‰ environment.yaml:\\n\")\n",
    "        comp_f.write(\"\\n\".join(yaml_data[\"dependencies\"]) + \"\\n\")\n",
    "\n",
    "    print(f\"âœ… ØªÙ… ØªØ­Ø¯ÙŠØ« `environment.yaml` Ø¨Ù†Ø¬Ø§Ø­!\")\n",
    "    print(f\"ğŸ“‚ ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ `{comp_file}` Ù„Ø¹Ø±Ø¶ Ø§Ù„ÙØ±ÙˆÙ‚Ø§Øª Ø¨ÙŠÙ† Ø§Ù„Ù…Ù„ÙØ§Øª!\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"âŒ `{req_file}` ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ØŒ ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù…Ø³Ø§Ø±.\")\n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ ØªØ­Ø¯ÙŠØ« environment.yaml: {e}\")\n",
    "\n",
    "print(f\"â³ Ø§Ù†ØªÙ‡Ù‰ Ø§Ù„ØªÙ†ÙÙŠØ° Ø®Ù„Ø§Ù„ {time.time() - start_time:.2f} Ø«Ø§Ù†ÙŠØ©\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "51fb51d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ ØªØ­Ø¯ÙŠØ« environment.yaml: sequence item 4: expected str instance, dict found\n",
      "â³ Ø§Ù†ØªÙ‡Ù‰ Ø§Ù„ØªÙ†ÙÙŠØ° Ø®Ù„Ø§Ù„ 18.72 Ø«Ø§Ù†ÙŠØ©\n"
     ]
    }
   ],
   "source": [
    "%run /mnt/c/Users/ali/Desktop/Innovation_Hub_New/Full_Stack_Framework/Flower_Classification_Foundation_V1/update_yaml.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "02b35677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ØªÙ… Ø­ÙØ¸ Ø§Ù„ØªØ¹Ø¯ÙŠÙ„Ø§Øª Ø¯Ø§Ø®Ù„ update_yaml.py Ø¨Ù†Ø¬Ø§Ø­!\n"
     ]
    }
   ],
   "source": [
    "path = \"/mnt/c/Users/ali/Desktop/Innovation_Hub_New/Full_Stack_Framework/Flower_Classification_Foundation_V1/update_yaml.py\"\n",
    "\n",
    "content = \"\"\"import yaml\n",
    "import subprocess\n",
    "import shutil\n",
    "import os\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "base_path = \"/mnt/c/Users/ali/Desktop/Innovation_Hub_New/Full_Stack_Framework/Flower_Classification_Foundation_V1/\"\n",
    "req_file = os.path.join(base_path, \"requirements.txt\")\n",
    "env_file = os.path.join(base_path, \"environment.yaml\")\n",
    "comp_dir = os.path.join(base_path, \"comparisons\")\n",
    "\n",
    "micromamba_available = shutil.which(\"micromamba\") is not None\n",
    "conda_command = \"micromamba\" if micromamba_available else \"conda\"\n",
    "\n",
    "if not os.path.exists(comp_dir):\n",
    "    os.makedirs(comp_dir)\n",
    "\n",
    "existing_files = [f for f in os.listdir(comp_dir) if f.startswith(\"comparison_\") and f.endswith(\".txt\")]\n",
    "file_numbers = sorted([int(f.split(\"_\")[1].split(\".\")[0]) for f in existing_files if f.split(\"_\")[1].split(\".\")[0].isdigit()])\n",
    "next_file_number = file_numbers[-1] + 1 if file_numbers else 1\n",
    "comp_file = os.path.join(comp_dir, f\"comparison_{next_file_number}.txt\")\n",
    "\n",
    "def is_available_in_conda(package_name):\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            [conda_command, \"search\", package_name, \"-c\", \"conda-forge\"], \n",
    "            capture_output=True, text=True, timeout=240\n",
    "        )\n",
    "        if not result.stdout:\n",
    "            print(f\"{package_name} ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ conda-forge.\")\n",
    "            return False\n",
    "        return package_name in result.stdout\n",
    "    except subprocess.TimeoutExpired:\n",
    "        print(f\"Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† {package_name} Ø§Ø³ØªØºØ±Ù‚ ÙˆÙ‚ØªÙ‹Ø§ Ø·ÙˆÙŠÙ„Ø§Ù‹ØŒ Ø³ÙŠØªÙ… ØªØ«Ø¨ÙŠØªÙ‡ Ø¹Ø¨Ø± pip.\")\n",
    "        return False\n",
    "\n",
    "try:\n",
    "    with open(req_file, \"r\") as f:\n",
    "        requirements = [line.strip() for line in f.readlines() if line.strip()]\n",
    "\n",
    "    conda_dependencies = []\n",
    "    pip_dependencies = []\n",
    "    python_version = None\n",
    "\n",
    "    for line in requirements:\n",
    "        parts = line.split()\n",
    "        package = parts[0]\n",
    "        version = f\"=={parts[1]}\" if len(parts) > 1 and \"==\" in parts[1] else \"\"\n",
    "        method = parts[-1] if len(parts) > 1 and parts[-1] in [\"conda\", \"pip\"] else None\n",
    "\n",
    "        if package.startswith(\"python\"):\n",
    "            python_version = package + version\n",
    "            continue\n",
    "        \n",
    "        if method == \"conda\" or (not method and is_available_in_conda(package)):\n",
    "            conda_dependencies.append(f\"{package}{version}\")\n",
    "        else:\n",
    "            pip_dependencies.append(f\"{package}{version}\")\n",
    "\n",
    "    yaml_data = {\n",
    "        \"name\": \"project_env\",\n",
    "        \"channels\": [\"conda-forge\"],\n",
    "        \"dependencies\": [\"python\" + python_version] if python_version else [\"python\"]\n",
    "    }\n",
    "\n",
    "    if conda_dependencies:\n",
    "        yaml_data[\"dependencies\"].extend(conda_dependencies)\n",
    "\n",
    "    if pip_dependencies:\n",
    "        yaml_data[\"dependencies\"].append(\"pip\")\n",
    "        yaml_data[\"dependencies\"].append({\"pip\": pip_dependencies})\n",
    "\n",
    "    with open(env_file, \"w\") as f:\n",
    "        yaml.dump(yaml_data, f, default_flow_style=False)\n",
    "\n",
    "    with open(comp_file, \"w\") as comp_f:\n",
    "        comp_f.write(f\"Ù…Ù‚Ø§Ø±Ù†Ø© ØªØ´ØºÙŠÙ„ Ø±Ù‚Ù… {next_file_number}\\n\")\n",
    "        comp_f.write(f\"ÙˆÙ‚Øª Ø§Ù„ØªÙ†ÙÙŠØ°: {time.time() - start_time:.2f} Ø«Ø§Ù†ÙŠØ©\\n\")\n",
    "        comp_f.write(f\"Ø¥ØµØ¯Ø§Ø± Conda Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…: {subprocess.run(['conda', '--version'], capture_output=True, text=True).stdout.strip()}\\n\")\n",
    "        if micromamba_available:\n",
    "            comp_f.write(f\"Ø¥ØµØ¯Ø§Ø± Micromamba Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…: {subprocess.run(['micromamba', '--version'], capture_output=True, text=True).stdout.strip()}\\n\")\n",
    "        comp_f.write(\"\\nÙ…Ø­ØªÙˆÙ‰ requirements.txt:\\n\")\n",
    "        comp_f.write(\"\\n\".join(requirements) + \"\\n\\n\")\n",
    "        comp_f.write(\"Ù…Ø­ØªÙˆÙ‰ environment.yaml:\\n\")\n",
    "        comp_f.write(\"\\n\".join(yaml_data[\"dependencies\"]) + \"\\n\")\n",
    "\n",
    "    print(f\"ØªÙ… ØªØ­Ø¯ÙŠØ« environment.yaml Ø¨Ù†Ø¬Ø§Ø­!\")\n",
    "    print(f\"ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ {comp_file} Ù„Ø¹Ø±Ø¶ Ø§Ù„ÙØ±ÙˆÙ‚Ø§Øª Ø¨ÙŠÙ† Ø§Ù„Ù…Ù„ÙØ§Øª!\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"{req_file} ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ØŒ ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù…Ø³Ø§Ø±.\")\n",
    "except Exception as e:\n",
    "    print(f\"Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ ØªØ­Ø¯ÙŠØ« environment.yaml: {e}\")\n",
    "\n",
    "print(f\"Ø§Ù†ØªÙ‡Ù‰ Ø§Ù„ØªÙ†ÙÙŠØ° Ø®Ù„Ø§Ù„ {time.time() - start_time:.2f} Ø«Ø§Ù†ÙŠØ©\")\n",
    "\"\"\"\n",
    "\n",
    "with open(path, \"w\") as f:\n",
    "    f.write(content)\n",
    "\n",
    "print(\"ØªÙ… Ø­ÙØ¸ Ø§Ù„ØªØ¹Ø¯ÙŠÙ„Ø§Øª Ø¯Ø§Ø®Ù„ update_yaml.py Ø¨Ù†Ø¬Ø§Ø­!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "eae76381",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated f-string literal (detected at line 79) (update_yaml.py, line 79)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m/mnt/c/Users/ali/Desktop/Innovation_Hub_New/Full_Stack_Framework/Flower_Classification_Foundation_V1/update_yaml.py:79\u001b[0;36m\u001b[0m\n\u001b[0;31m    comp_f.write(f\"Ù…Ù‚Ø§Ø±Ù†Ø© ØªØ´ØºÙŠÙ„ Ø±Ù‚Ù… {next_file_number}\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated f-string literal (detected at line 79)\n"
     ]
    }
   ],
   "source": [
    "%run /mnt/c/Users/ali/Desktop/Innovation_Hub_New/Full_Stack_Framework/Flower_Classification_Foundation_V1/update_yaml.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "7588bdda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ØªÙ… Ø­ÙØ¸ Ø§Ù„ØªØ¹Ø¯ÙŠÙ„Ø§Øª Ø¯Ø§Ø®Ù„ update_yaml.py Ø¨Ù†Ø¬Ø§Ø­!\n"
     ]
    }
   ],
   "source": [
    "path = \"/mnt/c/Users/ali/Desktop/Innovation_Hub_New/Full_Stack_Framework/Flower_Classification_Foundation_V1/update_yaml.py\"\n",
    "\n",
    "content = '''import yaml\n",
    "import subprocess\n",
    "import shutil\n",
    "import os\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "base_path = \"/mnt/c/Users/ali/Desktop/Innovation_Hub_New/Full_Stack_Framework/Flower_Classification_Foundation_V1/\"\n",
    "req_file = os.path.join(base_path, \"requirements.txt\")\n",
    "env_file = os.path.join(base_path, \"environment.yaml\")\n",
    "comp_dir = os.path.join(base_path, \"comparisons\")\n",
    "\n",
    "micromamba_available = shutil.which(\"micromamba\") is not None\n",
    "conda_command = \"micromamba\" if micromamba_available else \"conda\"\n",
    "\n",
    "if not os.path.exists(comp_dir):\n",
    "    os.makedirs(comp_dir)\n",
    "\n",
    "existing_files = [f for f in os.listdir(comp_dir) if f.startswith(\"comparison_\") and f.endswith(\".txt\")]\n",
    "file_numbers = sorted([int(f.split(\"_\")[1].split(\".\")[0]) for f in existing_files if f.split(\"_\")[1].split(\".\")[0].isdigit()])\n",
    "next_file_number = file_numbers[-1] + 1 if file_numbers else 1\n",
    "comp_file = os.path.join(comp_dir, f\"comparison_{next_file_number}.txt\")\n",
    "\n",
    "def is_available_in_conda(package_name):\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            [conda_command, \"search\", package_name, \"-c\", \"conda-forge\"], \n",
    "            capture_output=True, text=True, timeout=240\n",
    "        )\n",
    "        if not result.stdout:\n",
    "            print(f\"{package_name} ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ conda-forge.\")\n",
    "            return False\n",
    "        return package_name in result.stdout\n",
    "    except subprocess.TimeoutExpired:\n",
    "        print(f\"Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† {package_name} Ø§Ø³ØªØºØ±Ù‚ ÙˆÙ‚ØªÙ‹Ø§ Ø·ÙˆÙŠÙ„Ø§Ù‹ØŒ Ø³ÙŠØªÙ… ØªØ«Ø¨ÙŠØªÙ‡ Ø¹Ø¨Ø± pip.\")\n",
    "        return False\n",
    "\n",
    "try:\n",
    "    with open(req_file, \"r\") as f:\n",
    "        requirements = [line.strip() for line in f.readlines() if line.strip()]\n",
    "\n",
    "    conda_dependencies = []\n",
    "    pip_dependencies = []\n",
    "    python_version = None\n",
    "\n",
    "    for line in requirements:\n",
    "        parts = line.split()\n",
    "        package = parts[0]\n",
    "        version = f\"=={parts[1]}\" if len(parts) > 1 and \"==\" in parts[1] else \"\"\n",
    "        method = parts[-1] if len(parts) > 1 and parts[-1] in [\"conda\", \"pip\"] else None\n",
    "\n",
    "        if package.startswith(\"python\"):\n",
    "            python_version = package + version\n",
    "            continue\n",
    "        \n",
    "        if method == \"conda\" or (not method and is_available_in_conda(package)):\n",
    "            conda_dependencies.append(f\"{package}{version}\")\n",
    "        else:\n",
    "            pip_dependencies.append(f\"{package}{version}\")\n",
    "\n",
    "    yaml_data = {\n",
    "        \"name\": \"project_env\",\n",
    "        \"channels\": [\"conda-forge\"],\n",
    "        \"dependencies\": [\"python\" + python_version] if python_version else [\"python\"]\n",
    "    }\n",
    "\n",
    "    if conda_dependencies:\n",
    "        yaml_data[\"dependencies\"].extend(conda_dependencies)\n",
    "\n",
    "    if pip_dependencies:\n",
    "        yaml_data[\"dependencies\"].append(\"pip\")\n",
    "        yaml_data[\"dependencies\"].append({\"pip\": pip_dependencies})\n",
    "\n",
    "    with open(env_file, \"w\") as f:\n",
    "        yaml.dump(yaml_data, f, default_flow_style=False)\n",
    "\n",
    "    with open(comp_file, \"w\") as comp_f:\n",
    "        comp_f.write(f\"Ù…Ù‚Ø§Ø±Ù†Ø© ØªØ´ØºÙŠÙ„ Ø±Ù‚Ù… {next_file_number}\\n\")\n",
    "        comp_f.write(f\"ÙˆÙ‚Øª Ø§Ù„ØªÙ†ÙÙŠØ°: {time.time() - start_time:.2f} Ø«Ø§Ù†ÙŠØ©\\n\")\n",
    "        comp_f.write(f\"Ø¥ØµØ¯Ø§Ø± Conda Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…: {subprocess.run(['conda', '--version'], capture_output=True, text=True).stdout.strip()}\\n\")\n",
    "        if micromamba_available:\n",
    "            comp_f.write(f\"Ø¥ØµØ¯Ø§Ø± Micromamba Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…: {subprocess.run(['micromamba', '--version'], capture_output=True, text=True).stdout.strip()}\\n\")\n",
    "        comp_f.write(\"\\nÙ…Ø­ØªÙˆÙ‰ requirements.txt:\\n\")\n",
    "        comp_f.write(\"\\n\".join(requirements) + \"\\n\\n\")\n",
    "        comp_f.write(\"Ù…Ø­ØªÙˆÙ‰ environment.yaml:\\n\")\n",
    "        comp_f.write(\"\\n\".join(yaml_data[\"dependencies\"]) + \"\\n\")\n",
    "\n",
    "    print(f\"ØªÙ… ØªØ­Ø¯ÙŠØ« environment.yaml Ø¨Ù†Ø¬Ø§Ø­!\")\n",
    "    print(f\"ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ {comp_file} Ù„Ø¹Ø±Ø¶ Ø§Ù„ÙØ±ÙˆÙ‚Ø§Øª Ø¨ÙŠÙ† Ø§Ù„Ù…Ù„ÙØ§Øª!\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"{req_file} ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ØŒ ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù…Ø³Ø§Ø±.\")\n",
    "except Exception as e:\n",
    "    print(f\"Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ ØªØ­Ø¯ÙŠØ« environment.yaml: {e}\")\n",
    "\n",
    "print(f\"Ø§Ù†ØªÙ‡Ù‰ Ø§Ù„ØªÙ†ÙÙŠØ° Ø®Ù„Ø§Ù„ {time.time() - start_time:.2f} Ø«Ø§Ù†ÙŠØ©\")\n",
    "'''\n",
    "\n",
    "with open(path, \"w\") as f:\n",
    "    f.write(content)\n",
    "\n",
    "print(\"ØªÙ… Ø­ÙØ¸ Ø§Ù„ØªØ¹Ø¯ÙŠÙ„Ø§Øª Ø¯Ø§Ø®Ù„ update_yaml.py Ø¨Ù†Ø¬Ø§Ø­!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "a8f7e9f5",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated f-string literal (detected at line 79) (update_yaml.py, line 79)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m/mnt/c/Users/ali/Desktop/Innovation_Hub_New/Full_Stack_Framework/Flower_Classification_Foundation_V1/update_yaml.py:79\u001b[0;36m\u001b[0m\n\u001b[0;31m    comp_f.write(f\"Ù…Ù‚Ø§Ø±Ù†Ø© ØªØ´ØºÙŠÙ„ Ø±Ù‚Ù… {next_file_number}\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated f-string literal (detected at line 79)\n"
     ]
    }
   ],
   "source": [
    "%run /mnt/c/Users/ali/Desktop/Innovation_Hub_New/Full_Stack_Framework/Flower_Classification_Foundation_V1/update_yaml.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "0280e70c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ `update_yaml.py` Ø¨Ù†Ø¬Ø§Ø­ Ø¯Ø§Ø®Ù„ Ø§Ù„Ù…Ø³Ø§Ø± Ø§Ù„Ù…Ø­Ø¯Ø¯!\n"
     ]
    }
   ],
   "source": [
    "file_path = \"/mnt/c/Users/ali/Desktop/Innovation_Hub_New/Full_Stack_Framework/Flower_Classification_Foundation_V1/update_yaml.py\"\n",
    "\n",
    "content = '''import yaml\n",
    "import subprocess\n",
    "import shutil\n",
    "import os\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "base_path = \"/mnt/c/Users/ali/Desktop/Innovation_Hub_New/Full_Stack_Framework/Flower_Classification_Foundation_V1/\"\n",
    "req_file = os.path.join(base_path, \"requirements.txt\")\n",
    "env_file = os.path.join(base_path, \"environment.yaml\")\n",
    "comp_dir = os.path.join(base_path, \"comparisons\")\n",
    "\n",
    "micromamba_available = shutil.which(\"micromamba\") is not None\n",
    "conda_command = \"micromamba\" if micromamba_available else \"conda\"\n",
    "\n",
    "if not os.path.exists(comp_dir):\n",
    "    os.makedirs(comp_dir)\n",
    "\n",
    "existing_files = [f for f in os.listdir(comp_dir) if f.startswith(\"comparison_\") and f.endswith(\".txt\")]\n",
    "file_numbers = sorted([int(f.split(\"_\")[1].split(\".\")[0]) for f in existing_files if f.split(\"_\")[1].split(\".\")[0].isdigit()])\n",
    "next_file_number = file_numbers[-1] + 1 if file_numbers else 1\n",
    "comp_file = os.path.join(comp_dir, f\"comparison_{next_file_number}.txt\")\n",
    "\n",
    "def is_available_in_conda(package_name):\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            [conda_command, \"search\", package_name, \"-c\", \"conda-forge\"], \n",
    "            capture_output=True, text=True, timeout=240\n",
    "        )\n",
    "        if not result.stdout:\n",
    "            print(f\"{package_name} ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ conda-forge.\")\n",
    "            return False\n",
    "        return package_name in result.stdout\n",
    "    except subprocess.TimeoutExpired:\n",
    "        print(f\"Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† {package_name} Ø§Ø³ØªØºØ±Ù‚ ÙˆÙ‚ØªÙ‹Ø§ Ø·ÙˆÙŠÙ„Ø§Ù‹ØŒ Ø³ÙŠØªÙ… ØªØ«Ø¨ÙŠØªÙ‡ Ø¹Ø¨Ø± pip.\")\n",
    "        return False\n",
    "\n",
    "try:\n",
    "    with open(req_file, \"r\") as f:\n",
    "        requirements = [line.strip() for line in f.readlines() if line.strip()]\n",
    "\n",
    "    conda_dependencies = []\n",
    "    pip_dependencies = []\n",
    "    python_version = None\n",
    "\n",
    "    for line in requirements:\n",
    "        parts = line.split()\n",
    "        package = parts[0]\n",
    "        version = f\"=={parts[1]}\" if len(parts) > 1 and \"==\" in parts[1] else \"\"\n",
    "        method = parts[-1] if len(parts) > 1 and parts[-1] in [\"conda\", \"pip\"] else None\n",
    "\n",
    "        if package.startswith(\"python\"):\n",
    "            python_version = package + version\n",
    "            continue\n",
    "        \n",
    "        if method == \"conda\" or (not method and is_available_in_conda(package)):\n",
    "            conda_dependencies.append(f\"{package}{version}\")\n",
    "        else:\n",
    "            pip_dependencies.append(f\"{package}{version}\")\n",
    "\n",
    "    yaml_data = {\n",
    "        \"name\": \"project_env\",\n",
    "        \"channels\": [\"conda-forge\"],\n",
    "        \"dependencies\": [\"python\" + python_version] if python_version else [\"python\"]\n",
    "    }\n",
    "\n",
    "    if conda_dependencies:\n",
    "        yaml_data[\"dependencies\"].extend(conda_dependencies)\n",
    "\n",
    "    if pip_dependencies:\n",
    "        yaml_data[\"dependencies\"].append(\"pip\")\n",
    "        yaml_data[\"dependencies\"].append({\"pip\": pip_dependencies})\n",
    "\n",
    "    with open(env_file, \"w\") as f:\n",
    "        yaml.dump(yaml_data, f, default_flow_style=False)\n",
    "\n",
    "    with open(comp_file, \"w\") as comp_f:\n",
    "        comp_f.write(f\"Ù…Ù‚Ø§Ø±Ù†Ø© ØªØ´ØºÙŠÙ„ Ø±Ù‚Ù… {next_file_number}\\n\")\n",
    "        comp_f.write(f\"ÙˆÙ‚Øª Ø§Ù„ØªÙ†ÙÙŠØ°: {time.time() - start_time:.2f} Ø«Ø§Ù†ÙŠØ©\\n\")\n",
    "        comp_f.write(f\"Ø¥ØµØ¯Ø§Ø± Conda Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…: {subprocess.run(['conda', '--version'], capture_output=True, text=True).stdout.strip()}\\n\")\n",
    "        if micromamba_available:\n",
    "            comp_f.write(f\"Ø¥ØµØ¯Ø§Ø± Micromamba Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…: {subprocess.run(['micromamba', '--version'], capture_output=True, text=True).stdout.strip()}\\n\")\n",
    "        comp_f.write(\"\\nÙ…Ø­ØªÙˆÙ‰ requirements.txt:\\n\")\n",
    "        comp_f.write(\"\\n\".join(requirements) + \"\\n\\n\")\n",
    "        comp_f.write(\"Ù…Ø­ØªÙˆÙ‰ environment.yaml:\\n\")\n",
    "        comp_f.write(\"\\n\".join(yaml_data[\"dependencies\"]) + \"\\n\")\n",
    "\n",
    "    print(f\"ØªÙ… ØªØ­Ø¯ÙŠØ« environment.yaml Ø¨Ù†Ø¬Ø§Ø­!\")\n",
    "    print(f\"ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ {comp_file} Ù„Ø¹Ø±Ø¶ Ø§Ù„ÙØ±ÙˆÙ‚Ø§Øª Ø¨ÙŠÙ† Ø§Ù„Ù…Ù„ÙØ§Øª!\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"{req_file} ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ØŒ ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù…Ø³Ø§Ø±.\")\n",
    "except Exception as e:\n",
    "    print(f\"Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ ØªØ­Ø¯ÙŠØ« environment.yaml: {e}\")\n",
    "\n",
    "print(f\"Ø§Ù†ØªÙ‡Ù‰ Ø§Ù„ØªÙ†ÙÙŠØ° Ø®Ù„Ø§Ù„ {time.time() - start_time:.2f} Ø«Ø§Ù†ÙŠØ©\")\n",
    "'''\n",
    "\n",
    "with open(file_path, \"w\") as f:\n",
    "    f.write(content)\n",
    "\n",
    "print(\"âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ `update_yaml.py` Ø¨Ù†Ø¬Ø§Ø­ Ø¯Ø§Ø®Ù„ Ø§Ù„Ù…Ø³Ø§Ø± Ø§Ù„Ù…Ø­Ø¯Ø¯!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "876a040c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ØªÙ… ØªØ­Ø¯ÙŠØ« environment.yaml Ø¨Ù†Ø¬Ø§Ø­!\n",
      "ğŸ“‚ ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ `/mnt/c/Users/ali/Desktop/Innovation_Hub_New/Full_Stack_Framework/Flower_Classification_Foundation_V1/comparisons/comparison_6.txt` Ù„Ø¹Ø±Ø¶ Ø§Ù„ÙØ±ÙˆÙ‚Ø§Øª Ø¨ÙŠÙ† Ø§Ù„Ù…Ù„ÙØ§Øª!\n",
      "â³ Ø§Ù†ØªÙ‡Ù‰ Ø§Ù„ØªÙ†ÙÙŠØ° Ø®Ù„Ø§Ù„ 27.00 Ø«Ø§Ù†ÙŠØ©\n"
     ]
    }
   ],
   "source": [
    "%run /mnt/c/Users/ali/Desktop/Innovation_Hub_New/Full_Stack_Framework/Flower_Classification_Foundation_V1/update_yaml.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "e04cafc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ØªÙ… ØªØ­Ø¯ÙŠØ« environment.yaml Ø¨Ù†Ø¬Ø§Ø­!\n",
      "ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ /mnt/c/Users/ali/Desktop/Innovation_Hub_New/Full_Stack_Framework/Flower_Classification_Foundation_V1/comparisons/comparison_10.txt Ù„Ø¹Ø±Ø¶ Ø§Ù„ÙØ±ÙˆÙ‚Ø§Øª Ø¨ÙŠÙ† Ø§Ù„Ù…Ù„ÙØ§Øª!\n",
      "Ø§Ù†ØªÙ‡Ù‰ Ø§Ù„ØªÙ†ÙÙŠØ° Ø®Ù„Ø§Ù„ 24.67 Ø«Ø§Ù†ÙŠØ©\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "import subprocess\n",
    "import shutil\n",
    "import os\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "base_path = \"/mnt/c/Users/ali/Desktop/Innovation_Hub_New/Full_Stack_Framework/Flower_Classification_Foundation_V1/\"\n",
    "req_file = os.path.join(base_path, \"requirements.txt\")\n",
    "env_file = os.path.join(base_path, \"environment.yaml\")\n",
    "comp_dir = os.path.join(base_path, \"comparisons\")\n",
    "\n",
    "micromamba_available = shutil.which(\"micromamba\") is not None\n",
    "conda_command = \"micromamba\" if micromamba_available else \"conda\"\n",
    "\n",
    "if not os.path.exists(comp_dir):\n",
    "    os.makedirs(comp_dir)\n",
    "\n",
    "existing_files = [f for f in os.listdir(comp_dir) if f.startswith(\"comparison_\") and f.endswith(\".txt\")]\n",
    "file_numbers = sorted([int(f.split(\"_\")[1].split(\".\")[0]) for f in existing_files if f.split(\"_\")[1].split(\".\")[0].isdigit()])\n",
    "next_file_number = file_numbers[-1] + 1 if file_numbers else 1\n",
    "comp_file = os.path.join(comp_dir, f\"comparison_{next_file_number}.txt\")\n",
    "\n",
    "def is_available_in_conda(package_name):\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            [conda_command, \"search\", package_name, \"-c\", \"conda-forge\"], \n",
    "            capture_output=True, text=True, timeout=240\n",
    "        )\n",
    "        return package_name in result.stdout if result.stdout else False\n",
    "    except subprocess.TimeoutExpired:\n",
    "        print(f\"Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† {package_name} Ø§Ø³ØªØºØ±Ù‚ ÙˆÙ‚ØªÙ‹Ø§ Ø·ÙˆÙŠÙ„Ø§Ù‹ØŒ Ø³ÙŠØªÙ… ØªØ«Ø¨ÙŠØªÙ‡ Ø¹Ø¨Ø± pip.\")\n",
    "        return False\n",
    "\n",
    "try:\n",
    "    with open(req_file, \"r\") as f:\n",
    "        requirements = [line.strip() for line in f.readlines() if line.strip()]\n",
    "\n",
    "    conda_dependencies = []\n",
    "    pip_dependencies = []\n",
    "    python_version = None\n",
    "\n",
    "    for line in requirements:\n",
    "        parts = line.split()\n",
    "        package = parts[0]\n",
    "        version = f\"=={parts[1]}\" if len(parts) > 1 and \"==\" in parts[1] else \"\"\n",
    "        method = parts[-1] if len(parts) > 1 and parts[-1] in [\"conda\", \"pip\"] else None\n",
    "\n",
    "        if package.startswith(\"python\"):\n",
    "            python_version = package + version\n",
    "            continue\n",
    "        \n",
    "        if method == \"conda\" or (not method and is_available_in_conda(package)):\n",
    "            conda_dependencies.append(f\"{package}{version}\")\n",
    "        else:\n",
    "            pip_dependencies.append(f\"{package}{version}\")\n",
    "\n",
    "    yaml_data = {\n",
    "        \"name\": \"project_env\",\n",
    "        \"channels\": [\"conda-forge\"],\n",
    "        \"dependencies\": [python_version if python_version else \"python\"]\n",
    "    }\n",
    "\n",
    "    if conda_dependencies:\n",
    "        yaml_data[\"dependencies\"].extend(conda_dependencies)\n",
    "\n",
    "    if pip_dependencies:\n",
    "        yaml_data[\"dependencies\"].append(\"pip\")\n",
    "        yaml_data[\"dependencies\"].extend(pip_dependencies)\n",
    "\n",
    "    with open(env_file, \"w\") as f:\n",
    "        yaml.dump(yaml_data, f, default_flow_style=False)\n",
    "\n",
    "    with open(comp_file, \"w\") as comp_f:\n",
    "        comp_f.write(f\"Ù…Ù‚Ø§Ø±Ù†Ø© ØªØ´ØºÙŠÙ„ Ø±Ù‚Ù… {next_file_number}\\n\")\n",
    "        comp_f.write(f\"ÙˆÙ‚Øª Ø§Ù„ØªÙ†ÙÙŠØ°: {time.time() - start_time:.2f} Ø«Ø§Ù†ÙŠØ©\\n\")\n",
    "        comp_f.write(f\"Ø¥ØµØ¯Ø§Ø± Conda Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…: {subprocess.run(['conda', '--version'], capture_output=True, text=True).stdout.strip()}\\n\")\n",
    "        if micromamba_available:\n",
    "            comp_f.write(f\"Ø¥ØµØ¯Ø§Ø± Micromamba Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…: {subprocess.run(['micromamba', '--version'], capture_output=True, text=True).stdout.strip()}\\n\")\n",
    "        comp_f.write(\"\\nÙ…Ø­ØªÙˆÙ‰ requirements.txt:\\n\")\n",
    "        comp_f.write(\"\\n\".join(requirements) + \"\\n\\n\")\n",
    "        comp_f.write(\"Ù…Ø­ØªÙˆÙ‰ environment.yaml:\\n\")\n",
    "        comp_f.write(\"\\n\".join(yaml_data[\"dependencies\"]) + \"\\n\")\n",
    "\n",
    "    print(f\"ØªÙ… ØªØ­Ø¯ÙŠØ« environment.yaml Ø¨Ù†Ø¬Ø§Ø­!\")\n",
    "    print(f\"ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ {comp_file} Ù„Ø¹Ø±Ø¶ Ø§Ù„ÙØ±ÙˆÙ‚Ø§Øª Ø¨ÙŠÙ† Ø§Ù„Ù…Ù„ÙØ§Øª!\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"{req_file} ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ØŒ ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù…Ø³Ø§Ø±.\")\n",
    "except Exception as e:\n",
    "    print(f\"Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ ØªØ­Ø¯ÙŠØ« environment.yaml: {e}\")\n",
    "\n",
    "print(f\"Ø§Ù†ØªÙ‡Ù‰ Ø§Ù„ØªÙ†ÙÙŠØ° Ø®Ù„Ø§Ù„ {time.time() - start_time:.2f} Ø«Ø§Ù†ÙŠØ©\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "71b311ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/python3: No module named pip\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    " pip show tensorflow-hub scipy tf-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "7ba5fbd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ØªÙ… ØªØµØ­ÙŠØ­ Ø§Ù„ØªØ¨Ø§Ø¹Ø¯ Ø¯Ø§Ø®Ù„ update_yaml.py!\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "\n",
    "# ØªØ­Ù…ÙŠÙ„ Ù…Ø­ØªÙˆÙ‰ update_yaml.py ÙˆØ¥ØµÙ„Ø§Ø­ Ø§Ù„ØªØ¨Ø§Ø¹Ø¯\n",
    "script_path = \"/mnt/c/Users/ali/Desktop/Innovation_Hub_New/Full_Stack_Framework/Flower_Classification_Foundation_V1/update_yaml.py\"\n",
    "\n",
    "with open(script_path, \"r\") as f:\n",
    "    script_lines = f.readlines()\n",
    "\n",
    "# Ø¥ØµÙ„Ø§Ø­ Ø§Ù„ØªØ¨Ø§Ø¹Ø¯ Ù„Ù„ÙƒØªÙ„Ø© Ø§Ù„Ø®Ø§Ø·Ø¦Ø©\n",
    "for i, line in enumerate(script_lines):\n",
    "    if \"if pip_dependencies:\" in line:\n",
    "        script_lines[i + 1] = \"    yaml_data[\\\"dependencies\\\"].append(\\\"pip\\\")\\n\"\n",
    "        script_lines[i + 2] = \"    yaml_data[\\\"dependencies\\\"].append({\\\"pip\\\": pip_dependencies})\\n\"\n",
    "\n",
    "# Ø­ÙØ¸ Ø§Ù„ØªØ¹Ø¯ÙŠÙ„Ø§Øª\n",
    "with open(script_path, \"w\") as f:\n",
    "    f.writelines(script_lines)\n",
    "\n",
    "print(\"âœ… ØªÙ… ØªØµØ­ÙŠØ­ Ø§Ù„ØªØ¨Ø§Ø¹Ø¯ Ø¯Ø§Ø®Ù„ update_yaml.py!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "197ff997",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'python' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[114], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpython\u001b[49m \u001b[38;5;241m/\u001b[39mmnt\u001b[38;5;241m/\u001b[39mc\u001b[38;5;241m/\u001b[39mUsers\u001b[38;5;241m/\u001b[39mali\u001b[38;5;241m/\u001b[39mDesktop\u001b[38;5;241m/\u001b[39mInnovation_Hub_New\u001b[38;5;241m/\u001b[39mFull_Stack_Framework\u001b[38;5;241m/\u001b[39mFlower_Classification_Foundation_V1\u001b[38;5;241m/\u001b[39mupdate_yaml\u001b[38;5;241m.\u001b[39mpy\n",
      "\u001b[0;31mNameError\u001b[0m: name 'python' is not defined"
     ]
    }
   ],
   "source": [
    "python /mnt/c/Users/ali/Desktop/Innovation_Hub_New/Full_Stack_Framework/Flower_Classification_Foundation_V1/update_yaml.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "c0517e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  File \"/mnt/c/Users/ali/Desktop/Innovation_Hub_New/Full_Stack_Framework/Flower_Classification_Foundation_V1/update_yaml.py\", line 69\r\n",
      "    yaml_data[\"dependencies\"].append(\"pip\")\r\n",
      "    ^\r\n",
      "IndentationError: expected an indented block after 'if' statement on line 68\r\n"
     ]
    }
   ],
   "source": [
    "!python /mnt/c/Users/ali/Desktop/Innovation_Hub_New/Full_Stack_Framework/Flower_Classification_Foundation_V1/update_yaml.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "596267ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ ØªØ­Ø¯ÙŠØ« environment.yaml: sequence item 4: expected str instance, dict found\n",
      "â³ Ø§Ù†ØªÙ‡Ù‰ Ø§Ù„ØªÙ†ÙÙŠØ° Ø®Ù„Ø§Ù„ 17.32 Ø«Ø§Ù†ÙŠØ©\n"
     ]
    }
   ],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "0f4f7dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ØªÙ… ØªØ­Ø¯ÙŠØ« environment.yaml Ø¨Ù†Ø¬Ø§Ø­!\r\n",
      "ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ /mnt/c/Users/ali/Desktop/Innovation_Hub_New/Full_Stack_Framework/Flower_Classification_Foundation_V1/comparisons/comparison_13.txt Ù„Ø¹Ø±Ø¶ Ø§Ù„ÙØ±ÙˆÙ‚Ø§Øª Ø¨ÙŠÙ† Ø§Ù„Ù…Ù„ÙØ§Øª!\r\n",
      "Ø§Ù†ØªÙ‡Ù‰ Ø§Ù„ØªÙ†ÙÙŠØ° Ø®Ù„Ø§Ù„ 13.63 Ø«Ø§Ù†ÙŠØ©\r\n"
     ]
    }
   ],
   "source": [
    "!python /mnt/c/Users/ali/Desktop/Innovation_Hub_New/Full_Stack_Framework/Flower_Classification_Foundation_V1/update_yaml.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "12ba0087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "channels:\r\n",
      "- conda-forge\r\n",
      "dependencies:\r\n",
      "- python==3.10\r\n",
      "- tensorflow-datasets==4.9.4\r\n",
      "- edx-dl\r\n",
      "- pip\r\n",
      "- tensorflow-hub==0.16.1\r\n",
      "- scipy==1.12.0\r\n",
      "- tf-keras==2.16.0\r\n",
      "name: project_env\r\n"
     ]
    }
   ],
   "source": [
    "cat /mnt/c/Users/ali/Desktop/Innovation_Hub_New/Full_Stack_Framework/Flower_Classification_Foundation_V1/environment.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "925182ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ /mnt/c/Users/ali/Desktop/Innovation_Hub_New/Full_Stack_Framework/Flower_Classification_Foundation_V1/fix_environment.yaml Ù„Ù„ØªØµØ­ÙŠØ­!\n",
      "Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ ØªØ­Ø¯ÙŠØ« environment.yaml: sequence item 4: expected str instance, dict found\n",
      "Ø§Ù†ØªÙ‡Ù‰ Ø§Ù„ØªÙ†ÙÙŠØ° Ø®Ù„Ø§Ù„ 15.98 Ø«Ø§Ù†ÙŠØ©\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "import os\n",
    "import subprocess\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "base_path = \"/mnt/c/Users/ali/Desktop/Innovation_Hub_New/Full_Stack_Framework/Flower_Classification_Foundation_V1/\"\n",
    "req_file = os.path.join(base_path, \"requirements.txt\")\n",
    "env_file = os.path.join(base_path, \"environment.yaml\")\n",
    "fix_env_file = os.path.join(base_path, \"fix_environment.yaml\")\n",
    "comp_dir = os.path.join(base_path, \"comparisons\")\n",
    "\n",
    "micromamba_available = shutil.which(\"micromamba\") is not None\n",
    "conda_command = \"micromamba\" if micromamba_available else \"conda\"\n",
    "\n",
    "if not os.path.exists(comp_dir):\n",
    "    os.makedirs(comp_dir)\n",
    "\n",
    "existing_files = [f for f in os.listdir(comp_dir) if f.startswith(\"comparison_\") and f.endswith(\".txt\")]\n",
    "file_numbers = sorted([int(f.split(\"_\")[1].split(\".\")[0]) for f in existing_files if f.split(\"_\")[1].split(\".\")[0].isdigit()])\n",
    "next_file_number = file_numbers[-1] + 1 if file_numbers else 1\n",
    "comp_file = os.path.join(comp_dir, f\"comparison_{next_file_number}.txt\")\n",
    "\n",
    "def is_available_in_conda(package_name):\n",
    "    try:\n",
    "        result = subprocess.run([conda_command, \"search\", package_name, \"-c\", \"conda-forge\"], capture_output=True, text=True, timeout=240)\n",
    "        return package_name in result.stdout if result.stdout else False\n",
    "    except subprocess.TimeoutExpired:\n",
    "        return False\n",
    "\n",
    "try:\n",
    "    with open(req_file, \"r\") as f:\n",
    "        requirements = [line.strip() for line in f.readlines() if line.strip()]\n",
    "\n",
    "    conda_dependencies = []\n",
    "    pip_dependencies = []\n",
    "    python_version = None\n",
    "\n",
    "    for line in requirements:\n",
    "        parts = line.split()\n",
    "        package = parts[0]\n",
    "        version = f\"=={parts[1]}\" if len(parts) > 1 and \"==\" in parts[1] else \"\"\n",
    "        method = parts[-1] if len(parts) > 1 and parts[-1] in [\"conda\", \"pip\"] else None\n",
    "\n",
    "        if package.startswith(\"python\"):\n",
    "            python_version = package + version\n",
    "            continue\n",
    "\n",
    "        if method == \"conda\" or (not method and is_available_in_conda(package)):\n",
    "            conda_dependencies.append(f\"{package}{version}\")\n",
    "        else:\n",
    "            pip_dependencies.append(f\"{package}{version}\")\n",
    "\n",
    "    yaml_data = {\n",
    "        \"name\": \"project_env\",\n",
    "        \"channels\": [\"conda-forge\"],\n",
    "        \"dependencies\": [python_version if python_version else \"python\"]\n",
    "    }\n",
    "\n",
    "    if conda_dependencies:\n",
    "        yaml_data[\"dependencies\"].extend(conda_dependencies)\n",
    "\n",
    "    if pip_dependencies:\n",
    "        yaml_data[\"dependencies\"].append(\"pip\")\n",
    "        yaml_data[\"dependencies\"].append({\"pip\": pip_dependencies})\n",
    "\n",
    "    with open(env_file, \"w\") as f:\n",
    "        yaml.dump(yaml_data, f, default_flow_style=False)\n",
    "\n",
    "    if not os.path.exists(fix_env_file):  # Ø¥Ù†Ø´Ø§Ø¡ `fix_environment.yaml` ÙÙ‚Ø· Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ù…ÙˆØ¬ÙˆØ¯Ù‹Ø§ Ù…Ø³Ø¨Ù‚Ù‹Ø§\n",
    "        fixed_yaml_data = yaml_data.copy()\n",
    "        if pip_dependencies:\n",
    "            fixed_yaml_data[\"dependencies\"].append(\"pip\")\n",
    "            fixed_yaml_data[\"dependencies\"].append({\"pip\": pip_dependencies})\n",
    "\n",
    "        with open(fix_env_file, \"w\") as f:\n",
    "            yaml.dump(fixed_yaml_data, f, default_flow_style=False)\n",
    "        print(f\"ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ {fix_env_file} Ù„Ù„ØªØµØ­ÙŠØ­!\")\n",
    "\n",
    "    with open(comp_file, \"w\") as comp_f:\n",
    "        comp_f.write(f\"Ù…Ù‚Ø§Ø±Ù†Ø© ØªØ´ØºÙŠÙ„ Ø±Ù‚Ù… {next_file_number}\\n\")\n",
    "        comp_f.write(f\"ÙˆÙ‚Øª Ø§Ù„ØªÙ†ÙÙŠØ°: {time.time() - start_time:.2f} Ø«Ø§Ù†ÙŠØ©\\n\")\n",
    "        comp_f.write(f\"Ø¥ØµØ¯Ø§Ø± Conda Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…: {subprocess.run(['conda', '--version'], capture_output=True, text=True).stdout.strip()}\\n\")\n",
    "        if micromamba_available:\n",
    "            comp_f.write(f\"Ø¥ØµØ¯Ø§Ø± Micromamba Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…: {subprocess.run(['micromamba', '--version'], capture_output=True, text=True).stdout.strip()}\\n\")\n",
    "        comp_f.write(\"\\nÙ…Ø­ØªÙˆÙ‰ requirements.txt:\\n\")\n",
    "        comp_f.write(\"\\n\".join(requirements) + \"\\n\\n\")\n",
    "        comp_f.write(\"Ù…Ø­ØªÙˆÙ‰ environment.yaml:\\n\")\n",
    "        comp_f.write(\"\\n\".join(yaml_data[\"dependencies\"]) + \"\\n\")\n",
    "\n",
    "    print(\"ØªÙ… ØªØ­Ø¯ÙŠØ« environment.yaml Ø¨Ù†Ø¬Ø§Ø­!\")\n",
    "    print(f\"ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ {comp_file} Ù„Ø¹Ø±Ø¶ Ø§Ù„ÙØ±ÙˆÙ‚Ø§Øª Ø¨ÙŠÙ† Ø§Ù„Ù…Ù„ÙØ§Øª!\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"{req_file} ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ØŒ ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù…Ø³Ø§Ø±.\")\n",
    "except Exception as e:\n",
    "    print(f\"Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ ØªØ­Ø¯ÙŠØ« environment.yaml: {e}\")\n",
    "\n",
    "print(f\"Ø§Ù†ØªÙ‡Ù‰ Ø§Ù„ØªÙ†ÙÙŠØ° Ø®Ù„Ø§Ù„ {time.time() - start_time:.2f} Ø«Ø§Ù†ÙŠØ©\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "330694a0",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:/Users/ali/Downloads/@1.html'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m/usr/lib/python3.12/shutil.py:886\u001b[0m, in \u001b[0;36mmove\u001b[0;34m(src, dst, copy_function)\u001b[0m\n\u001b[1;32m    885\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 886\u001b[0m     \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrename\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreal_dst\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    887\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:/Users/ali/Downloads/@1.html' -> 'C:/Users/ali/Desktop/Innovation_Hub_New/Full_Stack_Framework/index.html'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[121], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m new_filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex.html\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Ù†Ù‚Ù„ Ø§Ù„Ù…Ù„Ù ÙˆØ¥Ø¹Ø§Ø¯Ø© ØªØ³Ù…ÙŠØªÙ‡\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[43mshutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmove\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdestination_dir\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mnew_filename\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mâœ… ØªÙ… Ù†Ù‚Ù„ Ø§Ù„Ù…Ù„Ù ÙˆØ¥Ø¹Ø§Ø¯Ø© ØªØ³Ù…ÙŠØªÙ‡ Ø¥Ù„Ù‰ \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdestination_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnew_filename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/lib/python3.12/shutil.py:906\u001b[0m, in \u001b[0;36mmove\u001b[0;34m(src, dst, copy_function)\u001b[0m\n\u001b[1;32m    904\u001b[0m         rmtree(src)\n\u001b[1;32m    905\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 906\u001b[0m         \u001b[43mcopy_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreal_dst\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    907\u001b[0m         os\u001b[38;5;241m.\u001b[39munlink(src)\n\u001b[1;32m    908\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m real_dst\n",
      "File \u001b[0;32m/usr/lib/python3.12/shutil.py:475\u001b[0m, in \u001b[0;36mcopy2\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    472\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    473\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m--> 475\u001b[0m \u001b[43mcopyfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfollow_symlinks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_symlinks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    476\u001b[0m copystat(src, dst, follow_symlinks\u001b[38;5;241m=\u001b[39mfollow_symlinks)\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dst\n",
      "File \u001b[0;32m/usr/lib/python3.12/shutil.py:260\u001b[0m, in \u001b[0;36mcopyfile\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    258\u001b[0m     os\u001b[38;5;241m.\u001b[39msymlink(os\u001b[38;5;241m.\u001b[39mreadlink(src), dst)\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 260\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m fsrc:\n\u001b[1;32m    261\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    262\u001b[0m             \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(dst, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fdst:\n\u001b[1;32m    263\u001b[0m                 \u001b[38;5;66;03m# macOS\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:/Users/ali/Downloads/@1.html'"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "# ØªØ¹Ø±ÙŠÙ Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª\n",
    "source_file = \"C:/Users/ali/Downloads/@1.html\"\n",
    "destination_dir = \"C:/Users/ali/Desktop/Innovation_Hub_New/Full_Stack_Framework\"\n",
    "new_filename = \"index.html\"\n",
    "\n",
    "# Ù†Ù‚Ù„ Ø§Ù„Ù…Ù„Ù ÙˆØ¥Ø¹Ø§Ø¯Ø© ØªØ³Ù…ÙŠØªÙ‡\n",
    "shutil.move(source_file, f\"{destination_dir}/{new_filename}\")\n",
    "\n",
    "print(f\"âœ… ØªÙ… Ù†Ù‚Ù„ Ø§Ù„Ù…Ù„Ù ÙˆØ¥Ø¹Ø§Ø¯Ø© ØªØ³Ù…ÙŠØªÙ‡ Ø¥Ù„Ù‰ {destination_dir}/{new_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "5e469871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ØªÙ… Ù†Ù‚Ù„ Ø§Ù„Ù…Ù„Ù ÙˆØ¥Ø¹Ø§Ø¯Ø© ØªØ³Ù…ÙŠØªÙ‡ Ø¥Ù„Ù‰ /mnt/c/Users/ali/Desktop/Innovation_Hub_New/Full_Stack_Framework/index.html\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "# ØªØ¹Ø±ÙŠÙ Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª Ù…Ø¹ Ø§Ø³ØªØ®Ø¯Ø§Ù… `/mnt/c/`\n",
    "source_file = \"/mnt/c/Users/ali/Downloads/@1.html\"\n",
    "destination_dir = \"/mnt/c/Users/ali/Desktop/Innovation_Hub_New/Full_Stack_Framework\"\n",
    "new_filename = \"index.html\"\n",
    "\n",
    "# Ù†Ù‚Ù„ Ø§Ù„Ù…Ù„Ù ÙˆØ¥Ø¹Ø§Ø¯Ø© ØªØ³Ù…ÙŠØªÙ‡\n",
    "shutil.move(source_file, f\"{destination_dir}/{new_filename}\")\n",
    "\n",
    "print(f\"âœ… ØªÙ… Ù†Ù‚Ù„ Ø§Ù„Ù…Ù„Ù ÙˆØ¥Ø¹Ø§Ø¯Ø© ØªØ³Ù…ÙŠØªÙ‡ Ø¥Ù„Ù‰ {destination_dir}/{new_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "468c0178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archived_Content\n",
      "desktop.ini\n",
      "Full_Stack_Framework\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# ØªØ¹Ø±ÙŠÙ Ø§Ù„Ù…Ø³Ø§Ø± Ù„Ù„Ù…Ø³ØªÙˆØ¯Ø¹ Ø§Ù„Ù…Ø­Ù„ÙŠ\n",
    "repo_path = \"/mnt/c/Users/ali/Desktop/Innovation_Hub_New\"\n",
    "\n",
    "# Ø¹Ø±Ø¶ Ø§Ù„Ù…Ù„ÙØ§Øª ÙˆØ§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª\n",
    "files = os.listdir(repo_path)\n",
    "for file in files:\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "329c1d37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ØªÙ… Ù†Ù‚Ù„ Ø§Ù„Ù…Ù„Ù Ø¥Ù„Ù‰ /mnt/c/Users/ali/Desktop/Innovation_Hub_New/index.html\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "# ØªØ¹Ø±ÙŠÙ Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª\n",
    "source_file = \"/mnt/c/Users/ali/Desktop/Innovation_Hub_New/Full_Stack_Framework/index.html\"\n",
    "destination_dir = \"/mnt/c/Users/ali/Desktop/Innovation_Hub_New\"\n",
    "\n",
    "# Ù†Ù‚Ù„ Ø§Ù„Ù…Ù„Ù Ø¥Ù„Ù‰ Ø§Ù„Ø¬Ø°Ø±\n",
    "shutil.move(source_file, f\"{destination_dir}/index.html\")\n",
    "\n",
    "print(f\"âœ… ØªÙ… Ù†Ù‚Ù„ Ø§Ù„Ù…Ù„Ù Ø¥Ù„Ù‰ {destination_dir}/index.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "d3d4b5b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‚ Ù‡ÙŠÙƒÙ„ÙŠØ© Ø§Ù„Ù…Ø³ØªÙˆØ¯Ø¹ Ø¨Ø¹Ø¯ Ø§Ù„ØªØ¹Ø¯ÙŠÙ„:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# ØªØ­Ø¯ÙŠØ¯ Ù…Ø³Ø§Ø± Ø§Ù„Ù…Ø³ØªÙˆØ¯Ø¹\n",
    "repo_path = \"C:/Users/ali/Desktop/Innovation_Hub_New\"\n",
    "\n",
    "# Ø¹Ø±Ø¶ Ø§Ù„Ù…Ù„ÙØ§Øª ÙˆØ§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª Ø¨Ø¹Ø¯ Ø§Ù„Ø­Ø°Ù\n",
    "print(\"ğŸ“‚ Ù‡ÙŠÙƒÙ„ÙŠØ© Ø§Ù„Ù…Ø³ØªÙˆØ¯Ø¹ Ø¨Ø¹Ø¯ Ø§Ù„ØªØ¹Ø¯ÙŠÙ„:\\n\")\n",
    "for root, dirs, files in os.walk(repo_path):\n",
    "    level = root.replace(repo_path, \"\").count(os.sep)\n",
    "    indent = \" \" * 4 * level\n",
    "    print(f\"{indent}ğŸ“ {os.path.basename(root)}\")\n",
    "    for file in files:\n",
    "        print(f\"{indent}    ğŸ“„ {file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "3534215f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‚ Ù‡ÙŠÙƒÙ„ÙŠØ© Ø§Ù„Ù…Ø³ØªÙˆØ¯Ø¹ Ø¨Ø¹Ø¯ Ø§Ù„Ø­Ø°Ù:\n",
      "\n",
      "Innovation_Hub_New\n",
      "    desktop.ini\n",
      "    index.html\n",
      "    Archived_Content\n",
      "        .gitignore\n",
      "        desktop.ini\n",
      "        Level_1_DataPreparation.ipynb\n",
      "        LICENSE\n",
      "        README_Major.md\n",
      "        README_Mid.md\n",
      "        Untitled.ipynb\n",
      "        .git\n",
      "            AUTO_MERGE\n",
      "            COMMIT_EDITMSG\n",
      "            config\n",
      "            description\n",
      "            FETCH_HEAD\n",
      "            HEAD\n",
      "            index\n",
      "            ORIG_HEAD\n",
      "            packed-refs\n",
      "            branches\n",
      "            hooks\n",
      "                applypatch-msg.sample\n",
      "                commit-msg.sample\n",
      "                fsmonitor-watchman.sample\n",
      "                post-update.sample\n",
      "                pre-applypatch.sample\n",
      "                pre-commit.sample\n",
      "                pre-merge-commit.sample\n",
      "                pre-push.sample\n",
      "                pre-rebase.sample\n",
      "                pre-receive.sample\n",
      "                prepare-commit-msg.sample\n",
      "                push-to-checkout.sample\n",
      "                sendemail-validate.sample\n",
      "                update.sample\n",
      "            info\n",
      "                exclude\n",
      "            logs\n",
      "                HEAD\n",
      "                refs\n",
      "                    stash\n",
      "                    heads\n",
      "                        main\n",
      "                    remotes\n",
      "                        origin\n",
      "                            HEAD\n",
      "                            main\n",
      "            objects\n",
      "                23\n",
      "                    be334c97e1773f60ac7c5c352e033a61828012\n",
      "                24\n",
      "                    5720872dccc14e1002e2e9e2707e4dc2af9283\n",
      "                33\n",
      "                    817bb0b6f930a27cc9cff7fd5b345fa5e43de0\n",
      "                36\n",
      "                    3fcab7ed6e9634e198cf5555ceb88932c9a245\n",
      "                3e\n",
      "                    de596c30564b391a8c831eee5871d9986103ac\n",
      "                4f\n",
      "                    2f9dc855e2b451680620183d70697348998a55\n",
      "                56\n",
      "                    0edf1c88730de2ab06c285e0ef73148edbbf0e\n",
      "                58\n",
      "                    f4f3b57e888fb4e37c2406298798f917ca1b74\n",
      "                6f\n",
      "                    0bb415d8b5158540f5fc972fba47e34d1d6d64\n",
      "                7c\n",
      "                    07afda37499dd6eddec462a64d978ac6d8ec99\n",
      "                81\n",
      "                    c53efd9b737ae5009499b9f8069cc25fa2cb19\n",
      "                92\n",
      "                    298b318c6c84518ea843f478b8e6cc91646596\n",
      "                a3\n",
      "                    c162b8d248093447a4787dbe4f8b12ada6969f\n",
      "                a7\n",
      "                    6025e21191161b30c3505205684d67999bc3f2\n",
      "                b9\n",
      "                    3c7d33507a2b4969776ded3cfbd797b9778d23\n",
      "                c0\n",
      "                    b95b76665c0ba141ece9884c4eab6abf253082\n",
      "                c2\n",
      "                    a4e3175ec53e644a9e02efac59b3e7d20ea9e0\n",
      "                cb\n",
      "                    7791fc033aaffd4264aec03dba25c96904b572\n",
      "                e5\n",
      "                    27df9ea30b6117156ac550bf8631714c3e2284\n",
      "                e6\n",
      "                    befeff7c4a10bd58e617b2210b6e04099a9157\n",
      "                ee\n",
      "                    5a8c941b6cdc4134a9723c5d2da2f0a938d97e\n",
      "                fb\n",
      "                    27eb92c17086e9c7ae8a0f7e7daf1aac7ffa97\n",
      "                info\n",
      "                pack\n",
      "                    pack-f38fdce70c4c9438c37fa89b78def08de390f7f4.idx\n",
      "                    pack-f38fdce70c4c9438c37fa89b78def08de390f7f4.pack\n",
      "                    pack-f38fdce70c4c9438c37fa89b78def08de390f7f4.rev\n",
      "            refs\n",
      "                stash\n",
      "                heads\n",
      "                    main\n",
      "                remotes\n",
      "                    origin\n",
      "                        HEAD\n",
      "                        main\n",
      "                tags\n",
      "        .ipynb_checkpoints\n",
      "            Untitled-checkpoint.ipynb\n",
      "        Integration_Expansion\n",
      "        Level_1_Flower_Classification_Foundation\n",
      "            create_readme.py\n",
      "            Mid_ModifyReadme.py\n",
      "            README.md\n",
      "            scripts_manager\n",
      "                README.md\n",
      "                scripts\n",
      "        Level_2_Vegetable_Fruit_Classification\n",
      "            create_readme.py\n",
      "            Mid_ModifyReadme.py\n",
      "            README.md\n",
      "            scripts_manager\n",
      "                README.md\n",
      "                scripts\n",
      "        Level_3_Food_Analysis\n",
      "            Mid_ModifyReadme.py\n",
      "        Level_4_Mobile_App_Deployment\n",
      "            Mid_ModifyReadme.py\n",
      "        Major_SuperCodes\n",
      "            major_code_backup.py\n",
      "            Major_CreateScripts.py\n",
      "    Full_Stack_Framework\n",
      "        AI_Model_Training.ipynb\n",
      "        Automation_Scripts.ipynb\n",
      "        Data_Integration.ipynb\n",
      "        dependency_log.txt\n",
      "        Dev_Structure_Manager.ipynb\n",
      "        Market_Expansion_Strategies.ipynb\n",
      "        Project Update Monitor.ipynb\n",
      "        requirements.txt\n",
      "        Sustainability_Metrics.ipynb\n",
      "        Untitled.ipynb\n",
      "        User_Behavior_Insights.ipynb\n",
      "        .git\n",
      "            config\n",
      "            description\n",
      "            HEAD\n",
      "            branches\n",
      "            hooks\n",
      "                applypatch-msg.sample\n",
      "                commit-msg.sample\n",
      "                fsmonitor-watchman.sample\n",
      "                post-update.sample\n",
      "                pre-applypatch.sample\n",
      "                pre-commit\n",
      "                pre-commit.sample\n",
      "                pre-merge-commit.sample\n",
      "                pre-push.sample\n",
      "                pre-rebase.sample\n",
      "                pre-receive.sample\n",
      "                prepare-commit-msg.sample\n",
      "                push-to-checkout.sample\n",
      "                sendemail-validate.sample\n",
      "                update.sample\n",
      "            info\n",
      "                exclude\n",
      "            objects\n",
      "                info\n",
      "                pack\n",
      "            refs\n",
      "                heads\n",
      "                tags\n",
      "        .ipynb_checkpoints\n",
      "            AI_Model_Training-checkpoint.ipynb\n",
      "            Automation_Scripts-checkpoint.ipynb\n",
      "            Data_Integration-checkpoint.ipynb\n",
      "            Dev_Structure_Manager-checkpoint.ipynb\n",
      "            Market_Expansion_Strategies-checkpoint.ipynb\n",
      "            Project Update Monitor-checkpoint.ipynb\n",
      "            Sustainability_Metrics-checkpoint.ipynb\n",
      "            Untitled-checkpoint.ipynb\n",
      "            User_Behavior_Insights-checkpoint.ipynb\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# ØªØ­Ø¯ÙŠØ¯ Ù…Ø³Ø§Ø± Ø§Ù„Ù…Ø³ØªÙˆØ¯Ø¹\n",
    "repo_path = \"/mnt/c/Users/ali/Desktop/Innovation_Hub_New\"\n",
    "\n",
    "# Ø¹Ø±Ø¶ Ø§Ù„Ù…Ù„ÙØ§Øª ÙˆØ§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª Ø¨Ø¹Ø¯ Ø§Ù„ØªØ¹Ø¯ÙŠÙ„\n",
    "print(\"ğŸ“‚ Ù‡ÙŠÙƒÙ„ÙŠØ© Ø§Ù„Ù…Ø³ØªÙˆØ¯Ø¹ Ø¨Ø¹Ø¯ Ø§Ù„Ø­Ø°Ù:\\n\")\n",
    "for root, dirs, files in os.walk(repo_path):\n",
    "    level = root.replace(repo_path, \"\").count(os.sep)\n",
    "    indent = \" \" * 4 * level\n",
    "    print(f\"{indent}{os.path.basename(root)}\")\n",
    "    for file in files:\n",
    "        print(f\"{indent}    {file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "f63213c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‚ Ù‡ÙŠÙƒÙ„ÙŠØ© Ø§Ù„Ù…Ø³ØªÙˆØ¯Ø¹ Ø¨Ø¹Ø¯ Ø§Ù„Ø­Ø°Ù:\n",
      "\n",
      "Innovation_Hub_New\n",
      "    desktop.ini\n",
      "    index.html\n",
      "    Full_Stack_Framework\n",
      "        AI_Model_Training.ipynb\n",
      "        Automation_Scripts.ipynb\n",
      "        Data_Integration.ipynb\n",
      "        Dev_Structure_Manager.ipynb\n",
      "        Market_Expansion_Strategies.ipynb\n",
      "        Project Update Monitor.ipynb\n",
      "        Sustainability_Metrics.ipynb\n",
      "        Untitled.ipynb\n",
      "        User_Behavior_Insights.ipynb\n",
      "        .git\n",
      "            config\n",
      "            description\n",
      "            HEAD\n",
      "            branches\n",
      "            hooks\n",
      "                applypatch-msg.sample\n",
      "                commit-msg.sample\n",
      "                fsmonitor-watchman.sample\n",
      "                post-update.sample\n",
      "                pre-applypatch.sample\n",
      "                pre-commit\n",
      "                pre-commit.sample\n",
      "                pre-merge-commit.sample\n",
      "                pre-push.sample\n",
      "                pre-rebase.sample\n",
      "                pre-receive.sample\n",
      "                prepare-commit-msg.sample\n",
      "                push-to-checkout.sample\n",
      "                sendemail-validate.sample\n",
      "                update.sample\n",
      "            info\n",
      "                exclude\n",
      "            objects\n",
      "                info\n",
      "                pack\n",
      "            refs\n",
      "                heads\n",
      "                tags\n",
      "        .ipynb_checkpoints\n",
      "            AI_Model_Training-checkpoint.ipynb\n",
      "            Automation_Scripts-checkpoint.ipynb\n",
      "            Data_Integration-checkpoint.ipynb\n",
      "            Dev_Structure_Manager-checkpoint.ipynb\n",
      "            Market_Expansion_Strategies-checkpoint.ipynb\n",
      "            Project Update Monitor-checkpoint.ipynb\n",
      "            Sustainability_Metrics-checkpoint.ipynb\n",
      "            Untitled-checkpoint.ipynb\n",
      "            User_Behavior_Insights-checkpoint.ipynb\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# ØªØ­Ø¯ÙŠØ¯ Ù…Ø³Ø§Ø± Ø§Ù„Ù…Ø³ØªÙˆØ¯Ø¹\n",
    "repo_path = \"/mnt/c/Users/ali/Desktop/Innovation_Hub_New\"\n",
    "\n",
    "# Ø¹Ø±Ø¶ Ø§Ù„Ù…Ù„ÙØ§Øª ÙˆØ§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª Ø¨Ø¹Ø¯ Ø§Ù„ØªØ¹Ø¯ÙŠÙ„\n",
    "print(\"ğŸ“‚ Ù‡ÙŠÙƒÙ„ÙŠØ© Ø§Ù„Ù…Ø³ØªÙˆØ¯Ø¹ Ø¨Ø¹Ø¯ Ø§Ù„Ø­Ø°Ù:\\n\")\n",
    "for root, dirs, files in os.walk(repo_path):\n",
    "    level = root.replace(repo_path, \"\").count(os.sep)\n",
    "    indent = \" \" * 4 * level\n",
    "    print(f\"{indent}{os.path.basename(root)}\")\n",
    "    for file in files:\n",
    "        print(f\"{indent}    {file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "036e050b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ø¬Ù„Ø¯: /mnt/c/Users/ali/Desktop/Innovation_Hub_New/Private\n",
      "âœ… ØªÙ… ØªØ­Ø¯ÙŠØ« .gitignore Ù„Ø­Ø¬Ø¨ Ø§Ù„Ù…Ø¬Ù„Ø¯ Ø¹Ù† GitHub.\n",
      "ğŸš€ ØªÙ… ØªÙ†ÙÙŠØ° Ø­Ø¯Ø« Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¬Ù„Ø¯ Private ÙˆÙ…Ù†Ø¹Ù‡ Ù…Ù† Ø§Ù„Ø±ÙØ¹ Ø¨Ù†Ø¬Ø§Ø­!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# ØªØ­Ø¯ÙŠØ¯ Ù…Ø³Ø§Ø± Ø§Ù„Ù…Ø³ØªÙˆØ¯Ø¹\n",
    "repo_path = \"/mnt/c/Users/ali/Desktop/Innovation_Hub_New\"\n",
    "\n",
    "# ØªØ­Ø¯ÙŠØ¯ Ø§Ø³Ù… Ø§Ù„Ù…Ø¬Ù„Ø¯ Ø§Ù„Ø®Ø§Øµ\n",
    "private_folder = os.path.join(repo_path, \"Private\")\n",
    "\n",
    "# Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ø¬Ù„Ø¯ Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ù…ÙˆØ¬ÙˆØ¯Ù‹Ø§ Ø¨Ø§Ù„ÙØ¹Ù„\n",
    "if not os.path.exists(private_folder):\n",
    "    os.makedirs(private_folder)\n",
    "    print(f\"âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ø¬Ù„Ø¯: {private_folder}\")\n",
    "else:\n",
    "    print(f\"âš ï¸ Ø§Ù„Ù…Ø¬Ù„Ø¯ Ù…ÙˆØ¬ÙˆØ¯ Ø¨Ø§Ù„ÙØ¹Ù„: {private_folder}\")\n",
    "\n",
    "# Ø¥Ø¶Ø§ÙØ© Ø³Ø·Ø± Ù„Ù…Ù†Ø¹ Ø§Ù„Ù…Ø¬Ù„Ø¯ Ù…Ù† Ø§Ù„Ø±ÙØ¹ Ø¥Ù„Ù‰ .gitignore\n",
    "gitignore_path = os.path.join(repo_path, \".gitignore\")\n",
    "with open(gitignore_path, \"a\") as gitignore:\n",
    "    gitignore.write(\"\\nPrivate/\")\n",
    "print(\"âœ… ØªÙ… ØªØ­Ø¯ÙŠØ« .gitignore Ù„Ø­Ø¬Ø¨ Ø§Ù„Ù…Ø¬Ù„Ø¯ Ø¹Ù† GitHub.\")\n",
    "\n",
    "# ØªØ£ÙƒÙŠØ¯ Ù†Ø¬Ø§Ø­ Ø§Ù„Ø¹Ù…Ù„ÙŠØ© Ø¹Ø¨Ø± Ø­Ø¯Ø«\n",
    "def on_create_private_folder():\n",
    "    print(f\"ğŸš€ ØªÙ… ØªÙ†ÙÙŠØ° Ø­Ø¯Ø« Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¬Ù„Ø¯ Private ÙˆÙ…Ù†Ø¹Ù‡ Ù…Ù† Ø§Ù„Ø±ÙØ¹ Ø¨Ù†Ø¬Ø§Ø­!\")\n",
    "\n",
    "# ØªØ´ØºÙŠÙ„ Ø§Ù„Ø­Ø¯Ø« Ø¨Ø¹Ø¯ ØªÙ†ÙÙŠØ° Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª\n",
    "on_create_private_folder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "459d21a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ø¬Ù„Ø¯: /mnt/c/Users/ali/Desktop/Innovation_Hub_New/Private\n",
      "ØªÙ… ØªØ­Ø¯ÙŠØ« .gitignore Ù„Ø­Ø¬Ø¨ Ø§Ù„Ù…Ø¬Ù„Ø¯ Ø¹Ù† GitHub.\n",
      "ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ø¬Ù„Ø¯ Ø§Ù„Ø®Ø§Øµ ÙˆØ­Ø¬Ø¨Ù‡ Ø¹Ù† GitHub Ø¨Ù†Ø¬Ø§Ø­.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù…Ø³Ø§Ø± Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ Ù„Ù„Ù…Ø³ØªÙˆØ¯Ø¹\n",
    "repo_path = \"/mnt/c/Users/ali/Desktop/Innovation_Hub_New\"\n",
    "\n",
    "# Ø§Ø³Ù… Ø§Ù„Ù…Ø¬Ù„Ø¯ Ø§Ù„Ø®Ø§Øµ Ø§Ù„Ø°ÙŠ Ø³ÙŠØªÙ… Ø¥Ù†Ø´Ø§Ø¤Ù‡\n",
    "private_folder = os.path.join(repo_path, \"Private\")\n",
    "\n",
    "# Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ø¬Ù„Ø¯ Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ù…ÙˆØ¬ÙˆØ¯Ù‹Ø§\n",
    "if not os.path.exists(private_folder):\n",
    "    os.makedirs(private_folder)\n",
    "    print(\"ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ø¬Ù„Ø¯:\", private_folder)\n",
    "else:\n",
    "    print(\"Ø§Ù„Ù…Ø¬Ù„Ø¯ Ù…ÙˆØ¬ÙˆØ¯ Ø¨Ø§Ù„ÙØ¹Ù„:\", private_folder)\n",
    "\n",
    "# ØªØ­Ø¯ÙŠØ« Ù…Ù„Ù .gitignore Ù„Ù…Ù†Ø¹ Ø±ÙØ¹ Ø§Ù„Ù…Ø¬Ù„Ø¯ Ø¥Ù„Ù‰ Ø§Ù„Ù…Ø³ØªÙˆØ¯Ø¹\n",
    "gitignore_path = os.path.join(repo_path, \".gitignore\")\n",
    "with open(gitignore_path, \"a\") as gitignore:\n",
    "    gitignore.write(\"\\nPrivate/\")\n",
    "print(\"ØªÙ… ØªØ­Ø¯ÙŠØ« .gitignore Ù„Ø­Ø¬Ø¨ Ø§Ù„Ù…Ø¬Ù„Ø¯ Ø¹Ù† GitHub.\")\n",
    "\n",
    "# ØªÙ†ÙÙŠØ° Ø¥Ø¬Ø±Ø§Ø¡ ØªØ£ÙƒÙŠØ¯ÙŠ Ø¨Ø¹Ø¯ Ø§Ù„Ø¹Ù…Ù„ÙŠØ©\n",
    "def ØªØ£ÙƒÙŠØ¯_Ø¥Ù†Ø´Ø§Ø¡_Ø§Ù„Ù…Ø¬Ù„Ø¯():\n",
    "    print(\"ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ø¬Ù„Ø¯ Ø§Ù„Ø®Ø§Øµ ÙˆØ­Ø¬Ø¨Ù‡ Ø¹Ù† GitHub Ø¨Ù†Ø¬Ø§Ø­.\")\n",
    "\n",
    "# ØªØ´ØºÙŠÙ„ Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡ Ø§Ù„ØªØ£ÙƒÙŠØ¯ÙŠ\n",
    "ØªØ£ÙƒÙŠØ¯_Ø¥Ù†Ø´Ø§Ø¡_Ø§Ù„Ù…Ø¬Ù„Ø¯()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "19b46a9b",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1241241244.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[135], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    Ø§Ù„Ø§Ù† Ø§Ø¹Ø¹ÙƒÙ†ÙŠ Ø§Ø³Ù… Ø§Ù„Ø¯ÙØªØ± Ø§Ù„Ø®Ø§Øµ\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb865344",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
